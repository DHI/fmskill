# metrics { #modelskill.metrics }

`metrics`

The `metrics` module contains different skill metrics for evaluating the 
difference between a model and an observation. 

* [bias][modelskill.metrics.bias]
* [max_error][modelskill.metrics.max_error]
* [root_mean_squared_error (rmse)][modelskill.metrics.root_mean_squared_error]    
* [urmse][modelskill.metrics.urmse]
* [mean_absolute_error (mae)][modelskill.metrics.mean_absolute_error]
* [mean_absolute_percentage_error (mape)][modelskill.metrics.mean_absolute_percentage_error]
* [kling_gupta_efficiency (kge)][modelskill.metrics.kling_gupta_efficiency]
* [nash_sutcliffe_efficiency (nse)][modelskill.metrics.nash_sutcliffe_efficiency]
* [r2 (r2=nse)][modelskill.metrics.r2]
* [model_efficiency_factor (mef)][modelskill.metrics.model_efficiency_factor]
* [wilmott][modelskill.metrics.willmott]
* [scatter_index (si)][modelskill.metrics.scatter_index]
* [scatter_index2][modelskill.metrics.scatter_index2]
* [corrcoef (cc)][modelskill.metrics.corrcoef]
* [spearmanr (rho)][modelskill.metrics.spearmanr]
* [lin_slope][modelskill.metrics.lin_slope]
* [hit_ratio][modelskill.metrics.hit_ratio]
* [explained_variance (ev)][modelskill.metrics.explained_variance]
* [peak_ratio (pr)][modelskill.metrics.peak_ratio]

Circular metrics (for directional data with units in degrees):

* [c_bias][modelskill.metrics.c_bias]
* [c_max_error][modelskill.metrics.c_max_error]
* [c_mean_absolute_error (c_mae)][modelskill.metrics.c_mean_absolute_error]
* [c_root_mean_squared_error (c_rmse)][modelskill.metrics.c_root_mean_squared_error]
* [c_unbiased_root_mean_squared_error (c_urmse)][modelskill.metrics.c_unbiased_root_mean_squared_error]

The names in parentheses are shorthand aliases for the different metrics.

## Examples

```python
>>> obs = np.array([0.3, 2.1, -1.0])
>>> mod = np.array([0.0, 2.3, 1.0])
>>> bias(obs, mod)
0.6333333333333332
>>> max_error(obs, mod)
2.0
>>> rmse(obs, mod)
1.173314393786536
>>> urmse(obs, mod)
0.9877021593352702
>>> mae(obs, mod)
0.8333333333333331
>>> mape(obs, mod)
103.17460317460316
>>> nse(obs, mod)
0.14786795048143053
>>> r2(obs, mod)
0.14786795048143053
>>> mef(obs, mod)
0.9231099877688299
>>> si(obs, mod)
0.8715019052958266
>>> spearmanr(obs, mod)
0.5
>>> willmott(obs, mod)
0.7484604452865941
>>> hit_ratio(obs, mod, a=0.5)
0.6666666666666666
>>> ev(obs, mod)
0.39614855570839064
```

## Functions

| Name | Description |
| --- | --- |
| [add_metric](#modelskill.metrics.add_metric) | Adds a metric to the metric list. Useful for custom metrics. |
| [bias](#modelskill.metrics.bias) | Bias (mean error) |
| [c_bias](#modelskill.metrics.c_bias) | Circular bias (mean error) |
| [c_mae](#modelskill.metrics.c_mae) | alias for circular mean absolute error |
| [c_max_error](#modelskill.metrics.c_max_error) | Circular max error |
| [c_mean_absolute_error](#modelskill.metrics.c_mean_absolute_error) | Circular mean absolute error |
| [c_rmse](#modelskill.metrics.c_rmse) | alias for circular root mean squared error |
| [c_root_mean_squared_error](#modelskill.metrics.c_root_mean_squared_error) | Circular root mean squared error |
| [c_unbiased_root_mean_squared_error](#modelskill.metrics.c_unbiased_root_mean_squared_error) | Circular unbiased root mean squared error |
| [c_urmse](#modelskill.metrics.c_urmse) | alias for circular unbiased root mean squared error |
| [cc](#modelskill.metrics.cc) | alias for corrcoef |
| [corrcoef](#modelskill.metrics.corrcoef) | Pearson’s Correlation coefficient (CC) |
| [ev](#modelskill.metrics.ev) | alias for explained_variance |
| [explained_variance](#modelskill.metrics.explained_variance) | EV: Explained variance |
| [hit_ratio](#modelskill.metrics.hit_ratio) | Fraction within obs ± acceptable deviation |
| [kge](#modelskill.metrics.kge) | alias for kling_gupta_efficiency |
| [kling_gupta_efficiency](#modelskill.metrics.kling_gupta_efficiency) | Kling-Gupta Efficiency (KGE) |
| [lin_slope](#modelskill.metrics.lin_slope) | Slope of the regression line. |
| [mae](#modelskill.metrics.mae) | alias for mean_absolute_error |
| [mape](#modelskill.metrics.mape) | alias for mean_absolute_percentage_error |
| [max_error](#modelskill.metrics.max_error) | Max (absolute) error |
| [mean_absolute_error](#modelskill.metrics.mean_absolute_error) | Mean Absolute Error (MAE) |
| [mean_absolute_percentage_error](#modelskill.metrics.mean_absolute_percentage_error) | Mean Absolute Percentage Error (MAPE) |
| [mef](#modelskill.metrics.mef) | alias for model_efficiency_factor |
| [metric_has_units](#modelskill.metrics.metric_has_units) | Check if a metric has units (dimension). |
| [model_efficiency_factor](#modelskill.metrics.model_efficiency_factor) | Model Efficiency Factor (MEF) |
| [nash_sutcliffe_efficiency](#modelskill.metrics.nash_sutcliffe_efficiency) | Nash-Sutcliffe Efficiency (NSE) |
| [nse](#modelskill.metrics.nse) | alias for nash_sutcliffe_efficiency |
| [peak_ratio](#modelskill.metrics.peak_ratio) | Peak Ratio |
| [pr](#modelskill.metrics.pr) | alias for peak_ratio |
| [r2](#modelskill.metrics.r2) | Coefficient of determination (R2) |
| [rho](#modelskill.metrics.rho) | alias for spearmanr |
| [rmse](#modelskill.metrics.rmse) | alias for root_mean_squared_error |
| [root_mean_squared_error](#modelskill.metrics.root_mean_squared_error) | Root Mean Squared Error (RMSE) |
| [scatter_index](#modelskill.metrics.scatter_index) | Scatter index (SI) |
| [scatter_index2](#modelskill.metrics.scatter_index2) | Alternative formulation of the scatter index (SI) |
| [si](#modelskill.metrics.si) | alias for scatter_index |
| [spearmanr](#modelskill.metrics.spearmanr) | Spearman rank correlation coefficient |
| [urmse](#modelskill.metrics.urmse) | Unbiased Root Mean Squared Error (uRMSE) |
| [willmott](#modelskill.metrics.willmott) | Willmott's Index of Agreement |

### add_metric { #modelskill.metrics.add_metric }

`metrics.add_metric(metric, has_units=False)`

Adds a metric to the metric list. Useful for custom metrics.

Some metrics are dimensionless, others have the same dimension as the observations.

#### Parameters

| Name        | Type            | Description                                                    | Default    |
|-------------|-----------------|----------------------------------------------------------------|------------|
| `metric`    | str or callable | Metric name or function                                        | _required_ |
| `has_units` | bool            | True if metric has a dimension, False otherwise. Default:False | `False`    |

#### Returns

| Type   | Description   |
|--------|---------------|
| None   |               |

#### Examples

```python
>>> add_metric(hit_ratio)
>>> add_metric(rmse,True)
```

### bias { #modelskill.metrics.bias }

`metrics.bias(obs, model)`

Bias (mean error)

$$
bias=\frac{1}{n}\sum_{i=1}^n (model_i - obs_i)
$$

Range: $(-\infty, \infty)$; Best: 0

### c_bias { #modelskill.metrics.c_bias }

`metrics.c_bias(obs, model)`

Circular bias (mean error)

#### Parameters

| Name    | Type                | Description                     | Default    |
|---------|---------------------|---------------------------------|------------|
| `obs`   | numpy.numpy.ndarray | Observation in degrees (0, 360) | _required_ |
| `model` | numpy.numpy.ndarray | Model in degrees (0, 360)       | _required_ |

#### Notes

Range: $[-180., 180.]$; Best: 0.

#### Returns

| Type   | Description   |
|--------|---------------|
| float  | Circular bias |

#### Examples

```python
>>> obs = np.array([10., 355., 170.])
>>> mod = np.array([20., 5., -180.])
>>> c_bias(obs, mod)
10.0
```

### c_mae { #modelskill.metrics.c_mae }

`metrics.c_mae(obs, model, weights=None)`

alias for circular mean absolute error

### c_max_error { #modelskill.metrics.c_max_error }

`metrics.c_max_error(obs, model)`

Circular max error

#### Parameters

| Name    | Type                | Description                     | Default    |
|---------|---------------------|---------------------------------|------------|
| `obs`   | numpy.numpy.ndarray | Observation in degrees (0, 360) | _required_ |
| `model` | numpy.numpy.ndarray | Model in degrees (0, 360)       | _required_ |

#### Notes

Range: $[0, \infty)$; Best: 0

#### Returns

| Type   | Description        |
|--------|--------------------|
| float  | Circular max error |

#### Examples

```python
>>> obs = np.array([10., 350., 10.])
>>> mod = np.array([20., 10., 350.])
>>> c_max_error(obs, mod)
20.0
```

### c_mean_absolute_error { #modelskill.metrics.c_mean_absolute_error }

`metrics.c_mean_absolute_error(obs, model, weights=None)`

Circular mean absolute error

#### Parameters

| Name      | Type                | Description                     | Default    |
|-----------|---------------------|---------------------------------|------------|
| `obs`     | numpy.numpy.ndarray | Observation in degrees (0, 360) | _required_ |
| `model`   | numpy.numpy.ndarray | Model in degrees (0, 360)       | _required_ |
| `weights` | numpy.numpy.ndarray | Weights, by default None        | `None`     |

#### Notes

Range: [0, 180]; Best: 0

#### Returns

| Type   | Description                  |
|--------|------------------------------|
| float  | Circular mean absolute error |

### c_rmse { #modelskill.metrics.c_rmse }

`metrics.c_rmse(obs, model, weights=None)`

alias for circular root mean squared error

### c_root_mean_squared_error { #modelskill.metrics.c_root_mean_squared_error }

`metrics.c_root_mean_squared_error(obs, model, weights=None)`

Circular root mean squared error

#### Parameters

| Name      | Type                | Description                     | Default    |
|-----------|---------------------|---------------------------------|------------|
| `obs`     | numpy.numpy.ndarray | Observation in degrees (0, 360) | _required_ |
| `model`   | numpy.numpy.ndarray | Model in degrees (0, 360)       | _required_ |
| `weights` | numpy.numpy.ndarray | Weights, by default None        | `None`     |

#### Notes

Range: [0, 180]; Best: 0

#### Returns

| Type   | Description                      |
|--------|----------------------------------|
| float  | Circular root mean squared error |

### c_unbiased_root_mean_squared_error { #modelskill.metrics.c_unbiased_root_mean_squared_error }

`metrics.c_unbiased_root_mean_squared_error(obs, model, weights=None)`

Circular unbiased root mean squared error

#### Parameters

| Name      | Type                | Description                     | Default    |
|-----------|---------------------|---------------------------------|------------|
| `obs`     | numpy.numpy.ndarray | Observation in degrees (0, 360) | _required_ |
| `model`   | numpy.numpy.ndarray | Model in degrees (0, 360)       | _required_ |
| `weights` | numpy.numpy.ndarray | Weights, by default None        | `None`     |

#### Notes

Range: [0, 180]; Best: 0

#### Returns

| Type   | Description                               |
|--------|-------------------------------------------|
| float  | Circular unbiased root mean squared error |

### c_urmse { #modelskill.metrics.c_urmse }

`metrics.c_urmse(obs, model, weights=None)`

alias for circular unbiased root mean squared error

### cc { #modelskill.metrics.cc }

`metrics.cc(obs, model, weights=None)`

alias for corrcoef

### corrcoef { #modelskill.metrics.corrcoef }

`metrics.corrcoef(obs, model, weights=None)`

Pearson’s Correlation coefficient (CC)

$$
CC = \frac{\sum_{i=1}^n (model_i - \overline{model})(obs_i - \overline{obs}) }
               {\sqrt{\sum_{i=1}^n (model_i - \overline{model})^2}
                \sqrt{\sum_{i=1}^n (obs_i - \overline{obs})^2} }
$$

Range: [-1, 1]; Best: 1



#### See Also

spearmanr
np.corrcoef

### ev { #modelskill.metrics.ev }

`metrics.ev(obs, model)`

alias for explained_variance

### explained_variance { #modelskill.metrics.explained_variance }

`metrics.explained_variance(obs, model)`

EV: Explained variance

 EV is the explained variance and measures the proportion
 [0 - 1] to which the model accounts for the variation
 (dispersion) of the observations.

 In cases with no bias, EV is equal to r2

$$
\frac{ \sum_{i=1}^n (obs_i - \overline{obs})^2 -
\sum_{i=1}^n \left( (obs_i - \overline{obs}) -
(model_i - \overline{model}) \right)^2}{\sum_{i=1}^n
(obs_i - \overline{obs})^2}
$$

Range: [0, 1]; Best: 1



#### See Also

r2

### hit_ratio { #modelskill.metrics.hit_ratio }

`metrics.hit_ratio(obs, model, a=0.1)`

Fraction within obs ± acceptable deviation

$$
HR = \frac{1}{n}\sum_{i=1}^n I_{|(model_i - obs_i)|} < a
$$

Range: [0, 1]; Best: 1

#### Examples

```python
>>> obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])
>>> model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])
>>> hit_ratio(obs, model, a=0.05)
0.2857142857142857
>>> hit_ratio(obs, model, a=0.1)
0.8571428571428571
>>> hit_ratio(obs, model, a=0.15)
1.0
```

### kge { #modelskill.metrics.kge }

`metrics.kge(obs, model)`

alias for kling_gupta_efficiency

### kling_gupta_efficiency { #modelskill.metrics.kling_gupta_efficiency }

`metrics.kling_gupta_efficiency(obs, model)`

Kling-Gupta Efficiency (KGE)

$$
KGE = 1 - \sqrt{(r-1)^2 + \left(\frac{\sigma_{mod}}{\sigma_{obs}} - 1\right)^2 +
                            \left(\frac{\mu_{mod}}{\mu_{obs}} - 1\right)^2 }
$$

where $r$ is the pearson correlation coefficient, $\mu_{obs},\mu_{mod}$ and $\sigma_{obs},\sigma_{mod}$ is the mean and standard deviation of observations and model.

Range: $(-\infty, 1]$; Best: 1



#### References

Gupta, H. V., Kling, H., Yilmaz, K. K. and Martinez, G. F., (2009), Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling, J. Hydrol., 377(1-2), 80-91 <https://doi.org/10.1016/j.jhydrol.2009.08.003>

Knoben, W. J. M., Freer, J. E., and Woods, R. A. (2019) Technical note: Inherent benchmark or not? Comparing Nash–Sutcliffe and Kling–Gupta efficiency scores, Hydrol. Earth Syst. Sci., 23, 4323-4331 <https://doi.org/10.5194/hess-23-4323-2019>

### lin_slope { #modelskill.metrics.lin_slope }

`metrics.lin_slope(obs, model, reg_method='ols')`

Slope of the regression line.

$$
slope = \frac{\sum_{i=1}^n (model_i - \overline {model})(obs_i - \overline {obs})}
                {\sum_{i=1}^n (obs_i - \overline {obs})^2}
$$

Range: $(-\infty, \infty )$; Best: 1

### mae { #modelskill.metrics.mae }

`metrics.mae(obs, model, weights=None)`

alias for mean_absolute_error

### mape { #modelskill.metrics.mape }

`metrics.mape(obs, model)`

alias for mean_absolute_percentage_error

### max_error { #modelskill.metrics.max_error }

`metrics.max_error(obs, model)`

Max (absolute) error

$$
max_{error} = max(|model_i - obs_i|)
$$

Range: $[0, \infty)$; Best: 0

### mean_absolute_error { #modelskill.metrics.mean_absolute_error }

`metrics.mean_absolute_error(obs, model, weights=None)`

Mean Absolute Error (MAE)

$$
MAE=\frac{1}{n}\sum_{i=1}^n|model_i - obs_i|
$$

Range: $[0, \infty)$; Best: 0

### mean_absolute_percentage_error { #modelskill.metrics.mean_absolute_percentage_error }

`metrics.mean_absolute_percentage_error(obs, model)`

Mean Absolute Percentage Error (MAPE)

$$
MAPE=\frac{1}{n}\sum_{i=1}^n\frac{|model_i - obs_i|}{obs_i}*100
$$

Range: $[0, \infty)$; Best: 0

### mef { #modelskill.metrics.mef }

`metrics.mef(obs, model)`

alias for model_efficiency_factor

### metric_has_units { #modelskill.metrics.metric_has_units }

`metrics.metric_has_units(metric)`

Check if a metric has units (dimension).

Some metrics are dimensionless, others have the same dimension as the observations.

#### Parameters

| Name     | Type            | Description             | Default    |
|----------|-----------------|-------------------------|------------|
| `metric` | str or callable | Metric name or function | _required_ |

#### Returns

| Type   | Description                                     |
|--------|-------------------------------------------------|
| bool   | True if metric has a dimension, False otherwise |

#### Examples

```python
>>> metric_has_units("rmse")
True
>>> metric_has_units("kge")
False
```

### model_efficiency_factor { #modelskill.metrics.model_efficiency_factor }

`metrics.model_efficiency_factor(obs, model)`

Model Efficiency Factor (MEF)

Scale independent RMSE, standardized by Stdev of observations

$$
MEF = \frac{RMSE}{STDEV}=\frac{\sqrt{\frac{1}{n} \sum_{i=1}^n(model_i - obs_i)^2}}
                                {\sqrt{\frac{1}{n} \sum_{i=1}^n(obs_i - \overline{obs})^2}}=\sqrt{1-NSE}
$$

Range: $[0, \infty)$; Best: 0



#### See Also

nash_sutcliffe_efficiency
root_mean_squared_error

### nash_sutcliffe_efficiency { #modelskill.metrics.nash_sutcliffe_efficiency }

`metrics.nash_sutcliffe_efficiency(obs, model)`

Nash-Sutcliffe Efficiency (NSE)

$$
NSE = 1 - \frac {\sum _{i=1}^{n}\left(model_{i} - obs_{i}\right)^{2}}
                {\sum_{i=1}^{n}\left(obs_{i} - {\overline{obs}}\right)^{2}}
$$

Range: $(-\infty, 1]$; Best: 1



#### Note

r2 = nash_sutcliffe_efficiency(nse)



#### References

Nash, J. E.; Sutcliffe, J. V. (1970). "River flow forecasting through conceptual models part I — A discussion of principles". Journal of Hydrology. 10 (3): 282–290. <https://doi.org/10.1016/0022-1694(70)90255-6>

### nse { #modelskill.metrics.nse }

`metrics.nse(obs, model)`

alias for nash_sutcliffe_efficiency

### peak_ratio { #modelskill.metrics.peak_ratio }

`metrics.peak_ratio(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')`

Peak Ratio

PR is the mean of the individual ratios of identified peaks in the
model / identified peaks in the measurements. PR is calculated only for the joint-events,
ie, events that ocurr simulateneously within a window +/- 0.5*inter_event_time.

#### Parameters

| Name                | Type   | Description                                                                   | Default   |
|---------------------|--------|-------------------------------------------------------------------------------|-----------|
| `inter_event_level` | float  | Inter-event level threshold (default: 0.7).                                   | `0.7`     |
| `AAP`               | int    | Average Annual Peaks (ie, Number of peaks per year, on average). (default: 2) | `2`       |
| `inter_event_time`  |        | Maximum time interval between peaks (default: 36 hours).                      | `'36h'`   |

#### Notes

$\frac{\sum_{i=1}^{N_{joint-peaks}} (\frac{Peak_{model_i}}{Peak_{obs_i}} )}{N_{joint-peaks}}$

Range: $[0, \infty)$; Best: 1.0

### pr { #modelskill.metrics.pr }

`metrics.pr(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')`

alias for peak_ratio

### r2 { #modelskill.metrics.r2 }

`metrics.r2(obs, model)`

Coefficient of determination (R2)

Pronounced 'R-squared'; the proportion of the variation in the dependent variable that is predictable from the independent variable(s), i.e. the proportion of explained variance.

$$
R^2 = 1 - \frac{\sum_{i=1}^n (model_i - obs_i)^2}
                {\sum_{i=1}^n (obs_i - \overline {obs})^2}
$$

Range: $(-\infty, 1]$; Best: 1



#### Note

r2 = nash_sutcliffe_efficiency(nse)

#### Examples

```python
>>> obs = np.array([1.0,1.1,1.2,1.3,1.4])
>>> model = np.array([1.09, 1.16, 1.3 , 1.38, 1.49])
>>> r2(obs,model)
0.6379999999999998
```

### rho { #modelskill.metrics.rho }

`metrics.rho(obs, model)`

alias for spearmanr

### rmse { #modelskill.metrics.rmse }

`metrics.rmse(obs, model, weights=None, unbiased=False)`

alias for root_mean_squared_error

### root_mean_squared_error { #modelskill.metrics.root_mean_squared_error }

`metrics.root_mean_squared_error(obs, model, weights=None, unbiased=False)`

Root Mean Squared Error (RMSE)

$$
res_i = model_i - obs_i
$$

$$
RMSE=\sqrt{\frac{1}{n} \sum_{i=1}^n res_i^2}
$$

Unbiased version:

$$
res_{u,i} = res_i - \overline {res}
$$

$$
uRMSE=\sqrt{\frac{1}{n} \sum_{i=1}^n res_{u,i}^2}
$$

Range: $[0, \infty)$; Best: 0

### scatter_index { #modelskill.metrics.scatter_index }

`metrics.scatter_index(obs, model)`

Scatter index (SI)

Which is the same as the unbiased-RMSE normalized by the absolute mean of the observations.

$$
\frac{ \sqrt{ \frac{1}{n} \sum_{i=1}^n \left( (model_i - \overline {model}) - (obs_i - \overline {obs}) \right)^2} }
{\frac{1}{n} \sum_{i=1}^n | obs_i | }
$$

Range: $[0, \infty)$; Best: 0

### scatter_index2 { #modelskill.metrics.scatter_index2 }

`metrics.scatter_index2(obs, model)`

Alternative formulation of the scatter index (SI)

$$
\sqrt {\frac{\sum_{i=1}^n \left( (model_i - \overline {model}) - (obs_i - \overline {obs}) \right)^2}
{\sum_{i=1}^n obs_i^2}}
$$

Range: [0, 100]; Best: 0

### si { #modelskill.metrics.si }

`metrics.si(obs, model)`

alias for scatter_index

### spearmanr { #modelskill.metrics.spearmanr }

`metrics.spearmanr(obs, model)`

Spearman rank correlation coefficient

The rank correlation coefficient is similar to the Pearson correlation coefficient but
applied to ranked quantities and is useful to quantify a monotonous relationship

$$
\rho = \frac{\sum_{i=1}^n (rmodel_i - \overline{rmodel})(robs_i - \overline{robs}) }
                {\sqrt{\sum_{i=1}^n (rmodel_i - \overline{rmodel})^2}
                \sqrt{\sum_{i=1}^n (robs_i - \overline{robs})^2} }
$$

Range: [-1, 1]; Best: 1

#### Examples

```python
>>> obs = np.linspace(-20, 20, 100)
>>> mod = np.tanh(obs)
>>> rho(obs, mod)
0.9999759973116955
>>> spearmanr(obs, mod)
0.9999759973116955
```




#### See Also

corrcoef

### urmse { #modelskill.metrics.urmse }

`metrics.urmse(obs, model, weights=None)`

Unbiased Root Mean Squared Error (uRMSE)

$$
res_i = model_i - obs_i
$$

$$
res_{u,i} = res_i - \overline {res}
$$

$$
uRMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n res_{u,i}^2}
$$

Range: $[0, \infty)$; Best: 0



#### See Also

root_mean_squared_error

### willmott { #modelskill.metrics.willmott }

`metrics.willmott(obs, model)`

Willmott's Index of Agreement

A scaled representation of the predictive accuracy of the model against observations. A value of 1 indicates a perfect match, and 0 indicates no agreement at all.

$$
willmott = 1 - \frac{\frac{1}{n} \sum_{i=1}^n(model_i - obs_i)^2}
                    {\frac{1}{n} \sum_{i=1}^n(|model_i - \overline{obs}| + |obs_i - \overline{obs}|)^2}
$$

Range: [0, 1]; Best: 1

#### Examples

```python
>>> obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])
>>> model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])
>>> willmott(obs, model)
0.9501403174479723
```




#### References

Willmott, C. J. 1981. "On the validation of models". Physical Geography, 2, 184–194.
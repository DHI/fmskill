{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#modelskill-assess-the-skill-of-your-mike-model","title":"ModelSkill: Assess the skill of your MIKE model","text":"<p>Compare results from MIKE simulations with observations. ModelSkill would like to be your companion during the different phases of a MIKE modelling workflow.</p>"},{"location":"#installation","title":"Installation","text":"<p>ModelSkill is available as open-source on PyPI and can be installed with pip:</p> <pre><code>$ pip install modelskill\n</code></pre> <p>ModelSkill is compatible with Python 3.8 and later versions on Windows and Linux.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>Are your observations and model results already matched? </p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.from_matched(\"matched_data.dfs0\", obs_item=\"obs_WL\", mod_item=\"WL\")\n&gt;&gt;&gt; cmp.skill()\n...\n</code></pre> <p>Or do you need to match the observations and results first?</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o = ms.PointObservation(\"obs.dfs0\", item=\"obs_WL\")\n&gt;&gt;&gt; mr = ms.PointModelResult(\"model.dfs0\", item=\"WL\")\n&gt;&gt;&gt; cmp = ms.match(o, mr)[0]\n&gt;&gt;&gt; cmp.skill()\n...\n</code></pre> <p>Read more in the Getting started guide or in the overview of the package.</p>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Documentation (this site)</li> <li>Getting started guide</li> <li>Example notebooks</li> <li>PyPI</li> <li>Source code</li> </ul>"},{"location":"getting-started/","title":"Getting started","text":"<p>This page describes the typical ModelSkill workflow for comparing model results and observations. </p>"},{"location":"getting-started/#workflow","title":"Workflow","text":"<p>The typical ModelSkill workflow consists of these five steps:</p> <ol> <li>Define ModelResults</li> <li>Define Observations</li> <li>Match observations and ModelResults in space and time</li> <li>Do analysis, plotting, etc with a Comparer</li> </ol>"},{"location":"getting-started/#1-define-modelresults","title":"1. Define ModelResults","text":"<p>The result of a MIKE 21/3 simulation is stored in one or more dfs files. The most common formats are .dfsu for distributed data and .dfs0 for time series point data. A ModelSkill ModelResult is defined by the result file path and a name:</p> <pre><code>import modelskill as ms\nmr = ms.DfsuModelResult(\"SW/HKZN_local_2017_DutchCoast.dfsu\", name='HKZN_local', item=\"Sign. Wave Height\")\n</code></pre> <p>Currently, ModelResult supports .dfs0 and .dfsu files and pandas DataFrame. Only the file header is read when the ModelResult object is created. The data will be read later.</p>"},{"location":"getting-started/#2-define-observations","title":"2. Define Observations","text":"<p>The next step is to define the measurements to be used for the skill assessment. Two types of observation are available:</p> <ul> <li>PointObservation</li> <li>TrackObservation</li> </ul> <p>Let\\'s assume that we have one PointObservation and one TrackObservation:</p> <pre><code>hkna = ms.PointObservation(\"HKNA_Hm0.dfs0\", item=0, x=4.2420, y=52.6887, name=\"HKNA\")\nc2 = ms.TrackObservation(\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\n</code></pre> <p>In this case both observations are provided as .dfs0 files but pandas dataframes are also supported in case data are stored in another file format.</p> <p>Both PointObservation and TrackObservation need the path of the data file, the item number (or item name) and a name. A PointObservation further needs to be initialized with it\\'s x-, y-position.</p>"},{"location":"getting-started/#3-connect-observations-and-modelresults","title":"3. Connect observations and ModelResults","text":"<pre><code>cc = ms.match([hkna, c2], mr)\n</code></pre> <p>This method returns a ComparerCollection for further analysis and plotting.</p>"},{"location":"getting-started/#4-do-analysis-plotting-etc-with-a-comparer","title":"4. Do analysis, plotting, etc with a Comparer","text":"<p>The object returned by the <code>match()</code> method is a Comparer/ComparerCollection. It holds the matched observation and model data and has methods for plotting and skill assessment.</p> <p>The primary comparer methods are:</p> <ul> <li>skill()   which returns a table with the skill scores</li> <li>various plot methods of the comparer objects<ul> <li><code>plot.scatter()</code></li> <li><code>plot.timeseries()</code></li> <li><code>plot.kde()</code></li> <li><code>plot.qq()</code></li> <li><code>plot.hist()</code></li> </ul> </li> </ul>"},{"location":"getting-started/#save-load-the-comparercollection","title":"Save / load the ComparerCollection","text":"<p>It can be useful to save the comparer collection for later use. This can be done using the <code>save()</code> method:</p> <pre><code>cc.save(\"my_comparer_collection.msk\")\n</code></pre> <p>The comparer collection can be loaded again from disk, using the <code>load()</code> method:</p> <pre><code>cc = ms.load(\"my_comparer_collection.msk\")\n</code></pre>"},{"location":"getting-started/#filtering","title":"Filtering","text":"<p>In order to select only a subset of the data for analysis, the comparer has a <code>sel()</code> method which returns a new comparer with the selected data. </p> <p>This method allow filtering of the data in several ways:</p> <ul> <li>on <code>observation</code> by specifying name or id of one or more     observations</li> <li>on <code>model</code> (if more than one is compared) by giving name or id</li> <li>temporal using the <code>time</code> (or <code>start</code> and <code>end</code>) arguments</li> <li>spatial using the <code>area</code> argument given as a bounding box or a     polygon</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>ModelSkill compares model results with observations. The workflow can be split in two phases:</p> <ol> <li>Matching - making sure that observations and model results are in the same space and time</li> <li>Analysis - plots and statistics of the matched data</li> </ol> <p>If the observations and model results are already matched (i.e. are stored in the same data source),  the <code>from_matched()</code> function can be used to go directly to the analysis phase.  If not, the <code>match()</code> function can be used to match the observations and model results in space and time.</p>"},{"location":"overview/#matching","title":"Matching","text":"<p>If the observations and model results are not in the same data source (e.g. dfs0 file),  they will need to be defined and then matched in space and time with the <code>match()</code> function.  In simple cases, observations and model results can be defined directly in the <code>match()</code> function: </p> <pre><code>import modelskill as ms\ncmp = ms.match(\"obs.dfs0\", \"model.dfs0\", obs_item=\"obs_WL\", mod_item=\"WL\")\n</code></pre> <p>But in most cases, the observations and model results will need to be defined separately first.</p>"},{"location":"overview/#define-observations","title":"Define observations","text":"<p>The observations can be defined as either a <code>PointObservation</code> or a <code>TrackObservation</code> (a moving point). </p> <pre><code>o1 = ms.PointObservation(\"stn1.dfs0\", item=\"obs_WL\")\no2 = ms.PointObservation(\"stn2.dfs0\", item=\"obs_WL\")\n</code></pre> <p>The <code>item</code> needs to be specified as either the item number or the item name if the input file contains multiple items. Several other parameters can be specified, such as the name of the observation, the x- and y-position, and the quantity type and unit of the observation. </p>"},{"location":"overview/#define-model-results","title":"Define model results","text":"<p>A model result will either be a simple point/track like the observations, or spatial field (e.g. 2d dfsu file) from which the model results will be extracted at the observation positions. The following types are available:</p> <ul> <li><code>PointModelResult</code> - a point result from a dfs0/nc file or a DataFrame</li> <li><code>TrackModelResult</code> - a track result from a dfs0/nc file or a DataFrame</li> <li><code>GridModelResult</code> - a spatial field from a dfs2/nc file or a Xarray Dataset</li> <li><code>DfsuModelResult</code> - a spatial field from a dfsu file</li> </ul> <pre><code>mr1 = ms.PointModelResult(\"model.dfs0\", item=\"WL_stn1\")\nmr2 = ms.PointModelResult(\"model.dfs0\", item=\"WL_stn2\")\n</code></pre>"},{"location":"overview/#match-observations-and-model-results","title":"Match observations and model results","text":"<p>The <code>match()</code> function will interpolate the model results to the time (and space) of the observations and return a collection of <code>Comparer</code> objects that can be used for analysis. </p> <pre><code>cc1 = ms.match(o1, mr1)\ncc2 = ms.match(o2, mr2)\ncc = cc1 + cc2\n</code></pre>"},{"location":"overview/#analysis","title":"Analysis","text":"<p>Once the observations and model results are matched, the <code>Comparer</code> object can be used for analysis and plotting. </p>"},{"location":"terminology/","title":"Terminology","text":"<p><code>ModelSkill</code> is a library for assessing the skill of numerical models. It provides tools for comparing model results with observations, plotting the results and calculating validation metrics. This page defines some of the key terms used in the documentation.</p>"},{"location":"terminology/#general-terminology","title":"General terminology","text":""},{"location":"terminology/#skill","title":"Skill","text":"<p>Skill refers to the ability of a numerical model to accurately represent the real-world phenomenon it aims to simulate. It is a measure of how well the model performs in reproducing the observed system. Skill can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In <code>ModelSkill</code>, <code>skill</code> is also a specific method on Comparer objects that returns a skill table with aggregated skill scores per observation and model for a list of selected metrics. </p>"},{"location":"terminology/#validation","title":"Validation","text":"<p>Validation is the process of assessing the model's performance by comparing its output to real-world observations or data collected from the system being modeled. It helps ensure that the model accurately represents the system it simulates. Validation is typically performed before the model is used for prediction or decision-making.</p>"},{"location":"terminology/#calibration","title":"Calibration","text":"<p>Calibration is the process of adjusting the model's parameters or settings to improve its performance. It involves fine-tuning the model to better match observed data. Calibration aims to reduce discrepancies between model predictions and actual measurements. At the end of the calibration process, the calibrated model should be validated with independent data.</p>"},{"location":"terminology/#performance","title":"Performance","text":"<p>Performance is a measure of how well a numerical model operates in reproducing the observed system. It can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In this context, performance is synonymous with skill.</p>"},{"location":"terminology/#timeseries","title":"Timeseries","text":"<p>A timeseries is a sequence of data points in time. In <code>ModelSkill</code>, The data can either be from observations or model results. Timeseries can univariate or multivariate; ModelSkill primarily supports univariate timeseries. Multivariate timeseries can be assessed one variable at a time. Timeseries can also have different spatial dimensions, such as point, track, line, or area.</p>"},{"location":"terminology/#observation","title":"Observation","text":"<p>An observation refers to real-world data or measurements collected from the system you are modeling. Observations serve as a reference for assessing the model's performance. These data points are used to compare with the model's predictions during validation and calibration. Observations are usually based on field measurements or laboratory experiments, but for the purposes of model validation, they can also be derived from other models (e.g. a reference model). <code>ModelSkill</code> supports point and track observation types.</p>"},{"location":"terminology/#measurement","title":"Measurement","text":"<p>A measurement is called observation in <code>ModelSkill</code>.</p>"},{"location":"terminology/#model-result","title":"Model result","text":"<p>A model result is the output of any type of numerical model. It is the data generated by the model during a simulation. Model results can be compared with observations to assess the model's performance. In the context of validation, the term \"model result\" is often used interchangeably with \"model output\" or \"model prediction\". <code>ModelSkill</code> supports point, track, dfsu and grid model result types.</p>"},{"location":"terminology/#metric","title":"Metric","text":"<p>A metric is a quantitative measure (a mathematical expression) used to evaluate the performance of a numerical model. Metrics provide a standardized way to assess the model's accuracy, precision, and other attributes. A metric aggregates the skill of a model into a single number. See list of metrics supported by <code>ModelSkill</code>.</p>"},{"location":"terminology/#score","title":"Score","text":"<p>A score is a numerical value that summarizes the model's performance based on chosen metrics. Scores can be used to rank or compare different models or model configurations. In the context of validation, the \"skill score\" or \"validation score\" often quantifies the model's overall performance. The score of a model is a single number, calculated as a weighted average for all time-steps, observations and variables. If you want to perform automated calibration, you can use the score as the objective function. In <code>ModelSkill</code>, <code>score</code> is also a specific method on Comparer objects that returns a single number aggregated score using a specific metric. </p>"},{"location":"terminology/#modelskill-specific-terminology","title":"ModelSkill-specific terminology","text":""},{"location":"terminology/#matched-data","title":"matched data","text":"<p>In ModelSkill, observations and model results are matched when they refer to the same positions in space and time. If the observations and model results are already matched, the <code>from_matched</code> function can be used to create a Comparer directly. Otherwise, the compare function can be used to match the observations and model results in space and time. </p>"},{"location":"terminology/#match","title":"match","text":"<p>The function <code>match</code> is used to match a model result with observations. It returns a <code>Comparer</code> object or a <code>ComparerCollection</code> object.</p>"},{"location":"terminology/#comparer","title":"Comparer","text":"<p>A Comparer is an object that compares a model result with observations. It is used to calculate validation metrics and generate plots. A Comparer can be created using the <code>compare</code> function (will return a ComparerCollection). </p>"},{"location":"terminology/#comparercollection","title":"ComparerCollection","text":"<p>A ComparerCollection is a collection of Comparers. It is used to compare multiple model results with multiple observations. A ComparerCollection can be created using the <code>compare</code> function. </p>"},{"location":"terminology/#connector","title":"Connector","text":"<p>In past versions of FMSkill/ModelSkill, the Connector class was used to connect observations and model results. This class has been deprecated and is no longer in use. </p>"},{"location":"vision/","title":"Vision","text":"<p>ModelSkill would like to be your modelling companion. It should be indispensable good such that you want to use it every time you do a MIKE simulation.</p>"},{"location":"vision/#objective","title":"Objective","text":"<p>We want ModelSkill to make it easy to</p> <ul> <li>assess the skill of a model by comparing with measurements</li> <li>assess model skill also when result is split on several files (2d,     3d, yearly, ...)</li> <li>compare the skill of different calibration runs</li> <li>compare your model with other models</li> <li>use a wide range of common evaluation metrics</li> <li>create common plots such as time series, scatter and taylor     diagrams</li> <li>do aggregations - assess for all observations, geographic areas,     monthly, ...</li> <li>do filtering - assess for a subset of observations, geographic     areas, ...</li> <li>make fast comparisons (optimized code)</li> </ul> <p>And it should be</p> <ul> <li>Difficult to make mistakes by verifying input</li> <li>Trustworthy by having &gt;95% test coverage</li> <li>Easy to install (<code>$ pip install modelskill</code>)</li> <li>Easy to get started by providing many notebook examples and     documentation</li> </ul>"},{"location":"vision/#scope","title":"Scope","text":"<p>ModelSkill wants to balance general and specific needs:</p> <ul> <li> <p>It should be general enough to cover &gt;90% of MIKE simulations</p> </li> <li> <p>It should be general enough to cover generic modelling irrespective     of software.</p> </li> <li> <p>But specific enough to be useful</p> <ul> <li>Support dfs files (using mikeio)</li> <li>Handle circular variables such as wave direction</li> </ul> </li> </ul>"},{"location":"vision/#limitations","title":"Limitations","text":"<p>ModelSkill does not wish to cover</p> <ul> <li>Extreme value analysis</li> <li>Deterministic wave analysis such as crossing analysis</li> <li>Rare alternative file types</li> <li>Rarely used model result types</li> <li>Rare observation types</li> <li>Anything project specific</li> </ul>"},{"location":"vision/#future","title":"Future","text":""},{"location":"vision/#forecast-skill","title":"Forecast skill","text":"<p>It should be possible to compare forecasts with observations using  forecast lead time as a dimension. Planned 2024. </p>"},{"location":"vision/#better-support-for-3d-data","title":"Better support for 3D data","text":"<p>Currently 3D data is supported only as point data and only if data has  already been extracted from model result files. It should be possible to extract  date from 3D files directly. Furthermore, vertical columns data should be supported as an observation type with z as a dimension. Planned 2024.</p>"},{"location":"vision/#web-app","title":"Web app","text":"<p>Create a web app that wraps this library. </p>"},{"location":"vision/#automatic-reports","title":"Automatic reports","text":"<p>Both static as markdown, docx, pptx and interactive as html. </p>"},{"location":"api/","title":"API Documentation","text":"<p>Obtain a comparer object in one of the following ways: </p> <ul> <li>From matched data with from_matched()</li> <li>After defining observations and model results using the match() function.</li> <li>From a config file with from_config()</li> </ul> <p>Do analysis and plotting with the returned Comparer (a single observation) or ComparerCollection (multiple observations):</p> <ul> <li>skill() - returns a SkillTable with the skill scores</li> <li>plot using the various plot methods of the comparer objects<ul> <li><code>plot.scatter()</code></li> <li><code>plot.timeseries()</code></li> <li><code>plot.kde()</code></li> <li><code>plot.qq()</code></li> <li><code>plot.hist()</code></li> </ul> </li> </ul>"},{"location":"api/comparer/","title":"Comparer","text":"<p>The <code>Comparer</code> class is the main class of the ModelSkill package. It holds the matched observation and model data for a single observation and has methods for plotting and skill assessment.</p> <p>Main functionality:</p> <ul> <li>selecting/filtering data<ul> <li><code>sel()</code></li> <li><code>query()</code></li> </ul> </li> <li>skill assessment<ul> <li><code>skill()</code></li> <li><code>gridded_skill()</code> (for track observations)</li> </ul> </li> <li>plotting<ul> <li><code>plot.timeseries()</code></li> <li><code>plot.scatter()</code></li> <li><code>plot.kde()</code></li> <li><code>plot.qq()</code></li> <li><code>plot.hist()</code></li> <li><code>plot.box()</code></li> </ul> </li> <li>load/save/export data<ul> <li><code>load()</code></li> <li><code>save()</code></li> <li><code>to_dataframe()</code></li> </ul> </li> </ul>"},{"location":"api/comparer/#modelskill.Comparer","title":"<code>modelskill.Comparer</code>","text":"<p>             Bases: <code>Scoreable</code></p> <p>Comparer class for comparing model and observation data.</p> <p>Typically, the Comparer is part of a ComparerCollection, created with the <code>match</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>matched_data</code> <code>Dataset</code> <p>Matched data</p> required <code>raw_mod_data</code> <code>dict of modelskill.TimeSeries</code> <p>Raw model data. If None, observation and modeldata must be provided.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp1 = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp2 = ms.from_matched(matched_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer--see-also","title":"See Also","text":"<p>modelskill.match, modelskill.from_matched</p> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>class Comparer(Scoreable):\n    \"\"\"\n    Comparer class for comparing model and observation data.\n\n    Typically, the Comparer is part of a ComparerCollection,\n    created with the `match` function.\n\n    Parameters\n    ----------\n    matched_data : xr.Dataset\n        Matched data\n    raw_mod_data : dict of modelskill.TimeSeries, optional\n        Raw model data. If None, observation and modeldata must be provided.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cmp1 = ms.match(observation, modeldata)\n    &gt;&gt;&gt; cmp2 = ms.from_matched(matched_data)\n\n    See Also\n    --------\n    modelskill.match, modelskill.from_matched\n    \"\"\"\n\n    data: xr.Dataset\n    raw_mod_data: Dict[str, TimeSeries]\n    _obs_str = \"Observation\"\n    plotter = ComparerPlotter\n\n    def __init__(\n        self,\n        matched_data: xr.Dataset,\n        raw_mod_data: Optional[Dict[str, TimeSeries]] = None,\n    ) -&gt; None:\n        self.data = _parse_dataset(matched_data)\n        self.raw_mod_data = (\n            raw_mod_data\n            if raw_mod_data is not None\n            else {\n                # key: ModelResult(value, gtype=self.data.gtype, name=key, x=self.x, y=self.y)\n                key: TimeSeries(self.data[[key]])\n                for key, value in matched_data.data_vars.items()\n                if value.attrs[\"kind\"] == \"model\"\n            }\n        )\n        # TODO: validate that the names in raw_mod_data are the same as in matched_data\n        assert isinstance(self.raw_mod_data, dict)\n        for k in self.raw_mod_data.keys():\n            v = self.raw_mod_data[k]\n            if not isinstance(v, TimeSeries):\n                try:\n                    self.raw_mod_data[k] = TimeSeries(v)\n                except Exception:\n                    raise ValueError(\n                        f\"raw_mod_data[{k}] could not be converted to a TimeSeries object\"\n                    )\n            else:\n                assert isinstance(\n                    v, TimeSeries\n                ), f\"raw_mod_data[{k}] must be a TimeSeries object\"\n\n        self.plot = Comparer.plotter(self)\n\n    @staticmethod\n    def from_matched_data(\n        data: xr.Dataset | pd.DataFrame,\n        raw_mod_data: Optional[Dict[str, TimeSeries]] = None,\n        obs_item: str | int | None = None,\n        mod_items: Optional[Iterable[str | int]] = None,\n        aux_items: Optional[Iterable[str | int]] = None,\n        name: Optional[str] = None,\n        weight: float = 1.0,\n        x: Optional[float] = None,\n        y: Optional[float] = None,\n        z: Optional[float] = None,\n        quantity: Optional[Quantity] = None,\n    ) -&gt; \"Comparer\":\n        \"\"\"Initialize from compared data\"\"\"\n        if not isinstance(data, xr.Dataset):\n            # TODO: handle raw_mod_data by accessing data.attrs[\"kind\"] and only remove nan after\n            data = _matched_data_to_xarray(\n                data,\n                obs_item=obs_item,\n                mod_items=mod_items,\n                aux_items=aux_items,\n                name=name,\n                x=x,\n                y=y,\n                z=z,\n                quantity=quantity,\n            )\n            data.attrs[\"weight\"] = weight\n        return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n\n    def __repr__(self):\n        out = [\n            f\"&lt;{type(self).__name__}&gt;\",\n            f\"Quantity: {self.quantity}\",\n            f\"Observation: {self.name}, n_points={self.n_points}\",\n        ]\n        for model in self.mod_names:\n            out.append(f\" Model: {model}, rmse={self.score()[model]:.3f}\")\n\n        for var in self.aux_names:\n            out.append(f\" Auxiliary: {var}\")\n        return str.join(\"\\n\", out)\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of comparer (=name of observation)\"\"\"\n        return self.data.attrs[\"name\"]\n\n    @property\n    def gtype(self) -&gt; str:\n        \"\"\"Geometry type\"\"\"\n        return self.data.attrs[\"gtype\"]\n\n    @property\n    def quantity(self) -&gt; Quantity:\n        \"\"\"Quantity object\"\"\"\n        return Quantity(\n            name=self.data[self._obs_str].attrs[\"long_name\"],\n            unit=self.data[self._obs_str].attrs[\"units\"],\n            is_directional=bool(\n                self.data[self._obs_str].attrs.get(\"is_directional\", False)\n            ),\n        )\n\n    @quantity.setter\n    def quantity(self, quantity: Quantity) -&gt; None:\n        assert isinstance(quantity, Quantity), \"value must be a Quantity object\"\n        self.data[self._obs_str].attrs[\"long_name\"] = quantity.name\n        self.data[self._obs_str].attrs[\"units\"] = quantity.unit\n        self.data[self._obs_str].attrs[\"is_directional\"] = int(quantity.is_directional)\n\n    @property\n    def n_points(self) -&gt; int:\n        \"\"\"number of compared points\"\"\"\n        return len(self.data[self._obs_str]) if self.data else 0\n\n    @property\n    def time(self) -&gt; pd.DatetimeIndex:\n        \"\"\"time of compared data as pandas DatetimeIndex\"\"\"\n        return self.data.time.to_index()\n\n    # TODO: Should we keep these? (renamed to start_time and end_time)\n    # @property\n    # def start(self) -&gt; pd.Timestamp:\n    #     \"\"\"start pd.Timestamp of compared data\"\"\"\n    #     return self.time[0]\n\n    # @property\n    # def end(self) -&gt; pd.Timestamp:\n    #     \"\"\"end pd.Timestamp of compared data\"\"\"\n    #     return self.time[-1]\n\n    @property\n    def x(self):\n        \"\"\"x-coordinate\"\"\"\n        return self._coordinate_values(\"x\")\n\n    @property\n    def y(self):\n        \"\"\"y-coordinate\"\"\"\n        return self._coordinate_values(\"y\")\n\n    @property\n    def z(self):\n        \"\"\"z-coordinate\"\"\"\n        return self._coordinate_values(\"z\")\n\n    def _coordinate_values(self, coord):\n        vals = self.data[coord].values\n        return np.atleast_1d(vals)[0] if vals.ndim == 0 else vals\n\n    @property\n    def n_models(self) -&gt; int:\n        \"\"\"Number of model results\"\"\"\n        return len(self.mod_names)\n\n    @property\n    def mod_names(self) -&gt; Sequence[str]:\n        \"\"\"List of model result names\"\"\"\n        return list(self.raw_mod_data.keys())\n\n    @property\n    def aux_names(self) -&gt; Sequence[str]:\n        \"\"\"List of auxiliary data names\"\"\"\n        return list(\n            [\n                k\n                for k, v in self.data.data_vars.items()\n                if v.attrs[\"kind\"] not in [\"observation\", \"model\"]\n            ]\n        )\n\n    # TODO: always \"Observation\", necessary to have this property?\n    @property\n    def _obs_name(self) -&gt; str:\n        return self._obs_str\n\n    @property\n    def weight(self) -&gt; float:\n        \"\"\"Weight of observation (used in ComparerCollection score() and mean_skill())\"\"\"\n        return self.data.attrs[\"weight\"]\n\n    @weight.setter\n    def weight(self, value: float) -&gt; None:\n        self.data.attrs[\"weight\"] = value\n\n    @property\n    def unit_text(self) -&gt; str:\n        \"\"\"Quantity name and unit as text suitable for plot labels\"\"\"\n        return f\"{self.quantity.name} [{self.quantity.unit}]\"\n\n    @property\n    def metrics(self):\n        if self.quantity.is_directional:\n            # TODO define default circular metrics elsewhere\n            return [mtr.c_bias, mtr.c_rmse, mtr.c_urmse, mtr.c_max_error]\n        else:\n            return options.metrics.list\n\n    @metrics.setter\n    def metrics(self, values) -&gt; None:\n        if values is None:\n            reset_option(\"metrics.list\")\n        else:\n            options.metrics.list = _parse_metric(values, self.metrics)\n\n    def _model_to_frame(self, mod_name: str) -&gt; pd.DataFrame:\n        \"\"\"Convert single model data to pandas DataFrame\"\"\"\n\n        df = self.data.drop_vars([\"z\"]).to_dataframe().copy()\n        other_models = [m for m in self.mod_names if m is not mod_name]\n        df = df.drop(columns=other_models)\n        df = df.rename(columns={mod_name: \"mod_val\", self._obs_str: \"obs_val\"})\n        df[\"model\"] = mod_name\n        df[\"observation\"] = self.name\n\n        return df\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert to pandas DataFrame with all model data concatenated\"\"\"\n\n        # TODO is this needed?, comment out for now\n        # df = df.sort_index()\n        df = pd.concat([self._model_to_frame(name) for name in self.mod_names])\n        df[\"model\"] = df[\"model\"].astype(\"category\")\n        df[\"observation\"] = df[\"observation\"].astype(\"category\")\n        return df\n\n    # TODO: is this the best way to copy (self.data.copy.. )\n    def __copy__(self):\n        return deepcopy(self)\n\n    def copy(self):\n        return self.__copy__()\n\n    def rename(self, mapping: Mapping[str, str]) -&gt; \"Comparer\":\n        \"\"\"Rename model or auxiliary data\n\n        Parameters\n        ----------\n        mapping : dict\n            mapping of old names to new names\n\n        Returns\n        -------\n        Comparer\n\n        Examples\n        --------\n        &gt;&gt;&gt; cmp = ms.match(observation, modeldata)\n        &gt;&gt;&gt; cmp.mod_names\n        ['model1']\n        &gt;&gt;&gt; cmp2 = cmp.rename({'model1': 'model2'})\n        &gt;&gt;&gt; cmp2.mod_names\n        ['model2']\n        \"\"\"\n        data = self.data.rename(mapping)\n        raw_mod_data = {mapping.get(k, k): v for k, v in self.raw_mod_data.items()}\n\n        return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n\n    def save(self, filename: Union[str, Path]) -&gt; None:\n        \"\"\"Save to netcdf file\n\n        Parameters\n        ----------\n        filename : str or Path\n            filename\n        \"\"\"\n        ds = self.data\n\n        # add self.raw_mod_data to ds with prefix 'raw_' to avoid name conflicts\n        # an alternative strategy would be to use NetCDF groups\n        # https://docs.xarray.dev/en/stable/user-guide/io.html#groups\n\n        # There is no need to save raw data for track data, since it is identical to the matched data\n        if self.gtype == \"point\":\n            ds = self.data.copy()  # copy needed to avoid modifying self.data\n\n            for key, ts_mod in self.raw_mod_data.items():\n                ts_mod = ts_mod.copy()\n                #  rename time to unique name\n                ts_mod.data = ts_mod.data.rename({\"time\": \"_time_raw_\" + key})\n                # da = ds_mod.to_xarray()[key]\n                ds[\"_raw_\" + key] = ts_mod.data[key]\n\n        ds.to_netcdf(filename)\n\n    @staticmethod\n    def load(filename: Union[str, Path]) -&gt; \"Comparer\":\n        \"\"\"Load from netcdf file\n\n        Parameters\n        ----------\n        filename : str or Path\n            filename\n\n        Returns\n        -------\n        Comparer\n        \"\"\"\n        with xr.open_dataset(filename) as ds:\n            data = ds.load()\n\n        if data.gtype == \"track\":\n            return Comparer(matched_data=data)\n\n        if data.gtype == \"point\":\n            raw_mod_data: Dict[str, TimeSeries] = {}\n\n            for var in data.data_vars:\n                var_name = str(var)\n                if var_name[:5] == \"_raw_\":\n                    new_key = var_name[5:]  # remove prefix '_raw_'\n                    ds = data[[var_name]].rename(\n                        {\"_time_raw_\" + new_key: \"time\", var_name: new_key}\n                    )\n                    ts = PointObservation(data=ds, name=new_key)\n                    # TODO: name of time?\n                    # ts.name = new_key\n                    # df = (\n                    #     data[var_name]\n                    #     .to_dataframe()\n                    #     .rename(\n                    #         columns={\"_time_raw_\" + new_key: \"time\", var_name: new_key}\n                    #     )\n                    # )\n                    raw_mod_data[new_key] = ts\n\n                    # data = data.drop(var_name).drop(\"_time_raw_\" + new_key)\n\n            # filter variables, only keep the ones with a 'time' dimension\n            data = data[[v for v in data.data_vars if \"time\" in data[v].dims]]\n\n            return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n\n        else:\n            raise NotImplementedError(f\"Unknown gtype: {data.gtype}\")\n\n    def _to_observation(self) -&gt; PointObservation | TrackObservation:\n        \"\"\"Convert to Observation\"\"\"\n        if self.gtype == \"point\":\n            df = self.data.drop_vars([\"x\", \"y\", \"z\"])[self._obs_str].to_dataframe()\n            return PointObservation(\n                data=df,\n                name=self.name,\n                x=self.x,\n                y=self.y,\n                z=self.z,\n                quantity=self.quantity,\n                # TODO: add attrs\n            )\n        elif self.gtype == \"track\":\n            df = self.data.drop_vars([\"z\"])[[self._obs_str]].to_dataframe()\n            return TrackObservation(\n                data=df,\n                item=0,\n                x_item=1,\n                y_item=2,\n                name=self.name,\n                quantity=self.quantity,\n                # TODO: add attrs\n            )\n        else:\n            raise NotImplementedError(f\"Unknown gtype: {self.gtype}\")\n\n    def __add__(\n        self, other: Union[\"Comparer\", \"ComparerCollection\"]\n    ) -&gt; \"ComparerCollection\":\n        from ._collection import ComparerCollection\n        from ..matching import match_space_time\n\n        if not isinstance(other, (Comparer, ComparerCollection)):\n            raise TypeError(f\"Cannot add {type(other)} to {type(self)}\")\n\n        if isinstance(other, Comparer) and (self.name == other.name):\n            assert type(self) == type(other), \"Must be same type!\"\n            missing_models = set(self.mod_names) - set(other.mod_names)\n            if len(missing_models) == 0:\n                # same obs name and same model names\n                cmp = self.copy()\n                cmp.data = xr.concat([cmp.data, other.data], dim=\"time\")\n                # cc.data = cc.data[\n                #    ~cc.data.time.to_index().duplicated(keep=\"last\")\n                # ]  # 'first'\n                _, index = np.unique(cmp.data[\"time\"], return_index=True)\n                cmp.data = cmp.data.isel(time=index)\n\n            else:\n                raw_mod_data = self.raw_mod_data.copy()\n                raw_mod_data.update(other.raw_mod_data)  # TODO!\n                matched = match_space_time(\n                    observation=self._to_observation(), raw_mod_data=raw_mod_data  # type: ignore\n                )\n                cmp = Comparer(matched_data=matched, raw_mod_data=raw_mod_data)\n\n            return cmp\n        else:\n            if isinstance(other, Comparer):\n                return ComparerCollection([self, other])\n            elif isinstance(other, ComparerCollection):\n                return ComparerCollection([self, *other])\n\n    def sel(\n        self,\n        model: Optional[IdOrNameTypes] = None,\n        start: Optional[TimeTypes] = None,\n        end: Optional[TimeTypes] = None,\n        time: Optional[TimeTypes] = None,\n        area: Optional[List[float]] = None,\n    ) -&gt; \"Comparer\":\n        \"\"\"Select data based on model, time and/or area.\n\n        Parameters\n        ----------\n        model : str or int or list of str or list of int, optional\n            Model name or index. If None, all models are selected.\n        start : str or datetime, optional\n            Start time. If None, all times are selected.\n        end : str or datetime, optional\n            End time. If None, all times are selected.\n        time : str or datetime, optional\n            Time. If None, all times are selected.\n        area : list of float, optional\n            bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\n\n        Returns\n        -------\n        Comparer\n            New Comparer with selected data.\n        \"\"\"\n        if (time is not None) and ((start is not None) or (end is not None)):\n            raise ValueError(\"Cannot use both time and start/end\")\n\n        d = self.data\n        raw_mod_data = self.raw_mod_data\n        if model is not None:\n            if isinstance(model, (str, int)):\n                models = [model]\n            else:\n                models = list(model)\n            mod_names: List[str] = [_get_name(m, self.mod_names) for m in models]\n            dropped_models = [m for m in self.mod_names if m not in mod_names]\n            d = d.drop_vars(dropped_models)\n            raw_mod_data = {m: raw_mod_data[m] for m in mod_names}\n        if (start is not None) or (end is not None):\n            # TODO: can this be done without to_index? (simplify)\n            d = d.sel(time=d.time.to_index().to_frame().loc[start:end].index)  # type: ignore\n\n            # Note: if user asks for a specific time, we also filter raw\n            raw_mod_data = {k: v.sel(time=slice(start, end)) for k, v in raw_mod_data.items()}  # type: ignore\n        if time is not None:\n            d = d.sel(time=time)\n\n            # Note: if user asks for a specific time, we also filter raw\n            raw_mod_data = {k: v.sel(time=time) for k, v in raw_mod_data.items()}\n        if area is not None:\n            if _area_is_bbox(area):\n                x0, y0, x1, y1 = area\n                mask = (d.x &gt; x0) &amp; (d.x &lt; x1) &amp; (d.y &gt; y0) &amp; (d.y &lt; y1)\n            elif _area_is_polygon(area):\n                polygon = np.array(area)\n                xy = np.column_stack((d.x, d.y))\n                mask = _inside_polygon(polygon, xy)\n            else:\n                raise ValueError(\"area supports bbox [x0,y0,x1,y1] and closed polygon\")\n            if self.gtype == \"point\":\n                # if False, return empty data\n                d = d if mask else d.isel(time=slice(None, 0))\n            else:\n                d = d.isel(time=mask)\n        return Comparer.from_matched_data(data=d, raw_mod_data=raw_mod_data)\n\n    def where(\n        self,\n        cond: Union[bool, np.ndarray, xr.DataArray],\n    ) -&gt; \"Comparer\":\n        \"\"\"Return a new Comparer with values where cond is True\n\n        Parameters\n        ----------\n        cond : bool, np.ndarray, xr.DataArray\n            This selects the values to return.\n\n        Returns\n        -------\n        Comparer\n            New Comparer with values where cond is True and other otherwise.\n\n        Examples\n        --------\n        &gt;&gt;&gt; c2 = c.where(c.data.Observation &gt; 0)\n        \"\"\"\n        d = self.data.where(cond, other=np.nan)\n        d = d.dropna(dim=\"time\", how=\"all\")\n        return Comparer.from_matched_data(d, self.raw_mod_data)\n\n    def query(self, query: str) -&gt; \"Comparer\":\n        \"\"\"Return a new Comparer with values where query cond is True\n\n        Parameters\n        ----------\n        query : str\n            Query string, see pandas.DataFrame.query\n\n        Returns\n        -------\n        Comparer\n            New Comparer with values where cond is True and other otherwise.\n\n        Examples\n        --------\n        &gt;&gt;&gt; c2 = c.query(\"Observation &gt; 0\")\n        \"\"\"\n        d = self.data.query({\"time\": query})\n        d = d.dropna(dim=\"time\", how=\"all\")\n        return Comparer.from_matched_data(d, self.raw_mod_data)\n\n    def skill(\n        self,\n        by: Optional[Union[str, List[str]]] = None,\n        metrics: Optional[list] = None,\n        **kwargs,\n    ) -&gt; SkillTable:\n        \"\"\"Skill assessment of model(s)\n\n        Parameters\n        ----------\n        by : (str, List[str]), optional\n            group by column name or by temporal bin via the freq-argument\n            (using pandas pd.Grouper(freq)),\n            e.g.: 'freq:M' = monthly; 'freq:D' daily\n            by default [\"model\"]\n        metrics : list, optional\n            list of modelskill.metrics, by default modelskill.options.metrics.list\n\n        Returns\n        -------\n        SkillTable\n            skill assessment object\n\n        See also\n        --------\n        sel\n            a method for filtering/selecting data\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cc = ms.match(c2, mod)\n        &gt;&gt;&gt; cc['c2'].skill().round(2)\n                       n  bias  rmse  urmse   mae    cc    si    r2\n        observation\n        c2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n\n        &gt;&gt;&gt; cc['c2'].skill(by='freq:D').round(2)\n                     n  bias  rmse  urmse   mae    cc    si    r2\n        2017-10-27  72 -0.19  0.31   0.25  0.26  0.48  0.12  0.98\n        2017-10-28   0   NaN   NaN    NaN   NaN   NaN   NaN   NaN\n        2017-10-29  41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n        \"\"\"\n        metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        cmp = self.sel(\n            model=model,\n            start=start,\n            end=end,\n            area=area,\n        )\n        if cmp.n_points == 0:\n            raise ValueError(\"No data selected for skill assessment\")\n\n        by = _parse_groupby(by, cmp.n_models, n_obs=1, n_var=1)\n\n        df = cmp.to_dataframe()\n        res = _groupby_df(df, by, metrics)\n        res[\"x\"] = df.groupby(by=by, observed=False).x.first()\n        res[\"y\"] = df.groupby(by=by, observed=False).y.first()\n        # TODO: set x,y to NaN if TrackObservation\n        res = self._add_as_col_if_not_in_index(df, skilldf=res)\n        return SkillTable(res)\n\n    def _add_as_col_if_not_in_index(self, df, skilldf):\n        \"\"\"Add a field to skilldf if unique in df\"\"\"\n        FIELDS = (\"observation\", \"model\")\n\n        for field in FIELDS:\n            if (field == \"model\") and (self.n_models &lt;= 1):\n                continue\n            if field not in skilldf.index.names:\n                unames = df[field].unique()\n                if len(unames) == 1:\n                    skilldf.insert(loc=0, column=field, value=unames[0])\n        return skilldf\n\n    def score(\n        self,\n        metric: str | Callable = mtr.rmse,\n        **kwargs,\n    ) -&gt; Dict[str, float]:\n        \"\"\"Model skill score\n\n        Parameters\n        ----------\n        metric : list, optional\n            a single metric from modelskill.metrics, by default rmse\n\n        Returns\n        -------\n        float\n            skill score as a single number (for each model)\n\n        See also\n        --------\n        skill\n            a method for skill assessment returning a pd.DataFrame\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cmp = ms.match(c2, mod)\n        &gt;&gt;&gt; cmp.score()\n        0.3517964910888918\n\n        &gt;&gt;&gt; cmp.score(metric=ms.metrics.mape)\n        11.567399646108198\n        \"\"\"\n        metric = _parse_metric(metric, self.metrics)\n        if not (callable(metric) or isinstance(metric, str)):\n            raise ValueError(\"metric must be a string or a function\")\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        s = self.skill(\n            by=[\"model\", \"observation\"],\n            metrics=[metric],\n            model=model,  # deprecated\n            start=start,  # deprecated\n            end=end,  # deprecated\n            area=area,  # deprecated\n        )\n        df = s.to_dataframe()\n\n        metric_name = metric if isinstance(metric, str) else metric.__name__\n\n        return (\n            df.reset_index()\n            .groupby(\"model\", observed=True)[metric_name]\n            .mean()\n            .to_dict()\n        )\n\n    def spatial_skill(\n        self,\n        bins=5,\n        binsize=None,\n        by=None,\n        metrics=None,\n        n_min=None,\n        **kwargs,\n    ):\n        # deprecated\n        warnings.warn(\n            \"spatial_skill is deprecated, use gridded_skill instead\", FutureWarning\n        )\n        return self.gridded_skill(\n            bins=bins,\n            binsize=binsize,\n            by=by,\n            metrics=metrics,\n            n_min=n_min,\n            **kwargs,\n        )\n\n    def gridded_skill(\n        self,\n        bins=5,\n        binsize: Optional[float] = None,\n        by: Optional[Union[str, List[str]]] = None,\n        metrics: Optional[list] = None,\n        n_min: Optional[int] = None,\n        **kwargs,\n    ):\n        \"\"\"Aggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n        Parameters\n        ----------\n        bins: int, list of scalars, or IntervalIndex, or tuple of, optional\n            criteria to bin x and y by, argument bins to pd.cut(), default 5\n            define different bins for x and y a tuple\n            e.g.: bins = 5, bins = (5,[2,3,5])\n        binsize : float, optional\n            bin size for x and y dimension, overwrites bins\n            creates bins with reference to round(mean(x)), round(mean(y))\n        by : (str, List[str]), optional\n            group by column name or by temporal bin via the freq-argument\n            (using pandas pd.Grouper(freq)),\n            e.g.: 'freq:M' = monthly; 'freq:D' daily\n            by default [\"model\",\"observation\"]\n        metrics : list, optional\n            list of modelskill.metrics, by default modelskill.options.metrics.list\n        n_min : int, optional\n            minimum number of observations in a grid cell;\n            cells with fewer observations get a score of `np.nan`\n\n        Returns\n        -------\n        xr.Dataset\n            skill assessment as a dataset\n\n        See also\n        --------\n        skill\n            a method for aggregated skill assessment\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cmp = ms.match(c2, mod)   # satellite altimeter vs. model\n        &gt;&gt;&gt; cmp.gridded_skill(metrics='bias')\n        &lt;xarray.Dataset&gt;\n        Dimensions:      (x: 5, y: 5)\n        Coordinates:\n            observation   'alti'\n        * x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n        * y            (y) float64 50.6 51.66 52.7 53.75 54.8\n        Data variables:\n            n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n            bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n\n        &gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n        &gt;&gt;&gt; ds.coords\n        Coordinates:\n            observation   'alti'\n        * x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n        * y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n        \"\"\"\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        cmp = self.sel(\n            model=model,\n            start=start,\n            end=end,\n            area=area,\n        )\n\n        metrics = _parse_metric(metrics, self.metrics, return_list=True)\n        if cmp.n_points == 0:\n            raise ValueError(\"No data to compare\")\n\n        df = cmp.to_dataframe()\n        df = _add_spatial_grid_to_df(df=df, bins=bins, binsize=binsize)\n\n        # n_models = len(df.model.unique())\n        # n_obs = len(df.observation.unique())\n\n        # n_obs=1 because we only have one observation (**SingleObsComparer**)\n        by = _parse_groupby(by=by, n_models=cmp.n_models, n_obs=1)\n        if isinstance(by, str) or (not isinstance(by, Iterable)):\n            by = [by]  # type: ignore\n        if \"x\" not in by:  # type: ignore\n            by.insert(0, \"x\")  # type: ignore\n        if \"y\" not in by:  # type: ignore\n            by.insert(0, \"y\")  # type: ignore\n\n        df = df.drop(columns=[\"x\", \"y\"]).rename(columns=dict(xBin=\"x\", yBin=\"y\"))\n        res = _groupby_df(df, by, metrics, n_min)\n        ds = res.to_xarray().squeeze()\n\n        # change categorial index to coordinates\n        for dim in (\"x\", \"y\"):\n            ds[dim] = ds[dim].astype(float)\n\n        return SkillGrid(ds)\n\n    @property\n    def residual(self):\n        df = self.data.drop_vars([\"x\", \"y\", \"z\"]).to_dataframe()\n        obs = df[self._obs_str].values\n        mod = df[self.mod_names].values\n        return mod - np.vstack(obs)\n\n    def remove_bias(self, correct=\"Model\") -&gt; Comparer:\n        cmp = self.copy()\n\n        bias = cmp.residual.mean(axis=0)\n        if correct == \"Model\":\n            for j in range(cmp.n_models):\n                mod_name = cmp.mod_names[j]\n                mod_ts = cmp.raw_mod_data[mod_name]\n                with xr.set_options(keep_attrs=True):\n                    mod_ts.data[mod_name].values = mod_ts.values - bias[j]\n                    cmp.data[mod_name].values = cmp.data[mod_name].values - bias[j]\n        elif correct == \"Observation\":\n            # what if multiple models?\n            with xr.set_options(keep_attrs=True):\n                cmp.data[cmp._obs_str].values = cmp.data[cmp._obs_str].values + bias\n        else:\n            raise ValueError(\n                f\"Unknown correct={correct}. Only know 'Model' and 'Observation'\"\n            )\n        return cmp\n\n    # TODO remove plotting methods in v1.1\n    def scatter(\n        self,\n        *,\n        bins=120,\n        quantiles=None,\n        fit_to_quantiles=False,\n        show_points=None,\n        show_hist=None,\n        show_density=None,\n        norm=None,\n        backend=\"matplotlib\",\n        figsize=(8, 8),\n        xlim=None,\n        ylim=None,\n        reg_method=\"ols\",\n        title=None,\n        xlabel=None,\n        ylabel=None,\n        skill_table=None,\n        **kwargs,\n    ):\n        warnings.warn(\n            \"This method is deprecated, use plot.scatter instead\", FutureWarning\n        )\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n\n        # self.plot.scatter(\n        self.sel(\n            model=model,\n            start=start,\n            end=end,\n            area=area,\n        ).plot.scatter(\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            norm=norm,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            **kwargs,\n        )\n\n    def taylor(\n        self,\n        normalize_std=False,\n        figsize=(7, 7),\n        marker=\"o\",\n        marker_size=6.0,\n        title=\"Taylor diagram\",\n        **kwargs,\n    ):\n        warnings.warn(\"taylor is deprecated, use plot.taylor instead\", FutureWarning)\n\n        self.plot.taylor(\n            normalize_std=normalize_std,\n            figsize=figsize,\n            marker=marker,\n            marker_size=marker_size,\n            title=title,\n            **kwargs,\n        )\n\n    def hist(\n        self, *, model=None, bins=100, title=None, density=True, alpha=0.5, **kwargs\n    ):\n        warnings.warn(\"hist is deprecated. Use plot.hist instead.\", FutureWarning)\n        return self.plot.hist(\n            model=model, bins=bins, title=title, density=density, alpha=alpha, **kwargs\n        )\n\n    def kde(self, ax=None, **kwargs) -&gt; Axes:\n        warnings.warn(\"kde is deprecated. Use plot.kde instead.\", FutureWarning)\n\n        return self.plot.kde(ax=ax, **kwargs)\n\n    def plot_timeseries(\n        self, title=None, *, ylim=None, figsize=None, backend=\"matplotlib\", **kwargs\n    ):\n        warnings.warn(\n            \"plot_timeseries is deprecated. Use plot.timeseries instead.\", FutureWarning\n        )\n\n        return self.plot.timeseries(\n            title=title, ylim=ylim, figsize=figsize, backend=backend, **kwargs\n        )\n\n    def residual_hist(self, bins=100, title=None, color=None, **kwargs):\n        warnings.warn(\n            \"residual_hist is deprecated. Use plot.residual_hist instead.\",\n            FutureWarning,\n        )\n\n        return self.plot.residual_hist(bins=bins, title=title, color=color, **kwargs)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.aux_names","title":"<code>aux_names: Sequence[str]</code>  <code>property</code>","text":"<p>List of auxiliary data names</p>"},{"location":"api/comparer/#modelskill.Comparer.gtype","title":"<code>gtype: str</code>  <code>property</code>","text":"<p>Geometry type</p>"},{"location":"api/comparer/#modelskill.Comparer.mod_names","title":"<code>mod_names: Sequence[str]</code>  <code>property</code>","text":"<p>List of model result names</p>"},{"location":"api/comparer/#modelskill.Comparer.n_models","title":"<code>n_models: int</code>  <code>property</code>","text":"<p>Number of model results</p>"},{"location":"api/comparer/#modelskill.Comparer.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>number of compared points</p>"},{"location":"api/comparer/#modelskill.Comparer.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Name of comparer (=name of observation)</p>"},{"location":"api/comparer/#modelskill.Comparer.quantity","title":"<code>quantity: Quantity</code>  <code>property</code> <code>writable</code>","text":"<p>Quantity object</p>"},{"location":"api/comparer/#modelskill.Comparer.time","title":"<code>time: pd.DatetimeIndex</code>  <code>property</code>","text":"<p>time of compared data as pandas DatetimeIndex</p>"},{"location":"api/comparer/#modelskill.Comparer.unit_text","title":"<code>unit_text: str</code>  <code>property</code>","text":"<p>Quantity name and unit as text suitable for plot labels</p>"},{"location":"api/comparer/#modelskill.Comparer.weight","title":"<code>weight: float</code>  <code>property</code> <code>writable</code>","text":"<p>Weight of observation (used in ComparerCollection score() and mean_skill())</p>"},{"location":"api/comparer/#modelskill.Comparer.x","title":"<code>x</code>  <code>property</code>","text":"<p>x-coordinate</p>"},{"location":"api/comparer/#modelskill.Comparer.y","title":"<code>y</code>  <code>property</code>","text":"<p>y-coordinate</p>"},{"location":"api/comparer/#modelskill.Comparer.z","title":"<code>z</code>  <code>property</code>","text":"<p>z-coordinate</p>"},{"location":"api/comparer/#modelskill.Comparer.from_matched_data","title":"<code>from_matched_data(data, raw_mod_data=None, obs_item=None, mod_items=None, aux_items=None, name=None, weight=1.0, x=None, y=None, z=None, quantity=None)</code>  <code>staticmethod</code>","text":"<p>Initialize from compared data</p> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>@staticmethod\ndef from_matched_data(\n    data: xr.Dataset | pd.DataFrame,\n    raw_mod_data: Optional[Dict[str, TimeSeries]] = None,\n    obs_item: str | int | None = None,\n    mod_items: Optional[Iterable[str | int]] = None,\n    aux_items: Optional[Iterable[str | int]] = None,\n    name: Optional[str] = None,\n    weight: float = 1.0,\n    x: Optional[float] = None,\n    y: Optional[float] = None,\n    z: Optional[float] = None,\n    quantity: Optional[Quantity] = None,\n) -&gt; \"Comparer\":\n    \"\"\"Initialize from compared data\"\"\"\n    if not isinstance(data, xr.Dataset):\n        # TODO: handle raw_mod_data by accessing data.attrs[\"kind\"] and only remove nan after\n        data = _matched_data_to_xarray(\n            data,\n            obs_item=obs_item,\n            mod_items=mod_items,\n            aux_items=aux_items,\n            name=name,\n            x=x,\n            y=y,\n            z=z,\n            quantity=quantity,\n        )\n        data.attrs[\"weight\"] = weight\n    return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.gridded_skill","title":"<code>gridded_skill(bins=5, binsize=None, by=None, metrics=None, n_min=None, **kwargs)</code>","text":"<p>Aggregated spatial skill assessment of model(s) on a regular spatial grid.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <p>criteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])</p> <code>5</code> <code>binsize</code> <code>float</code> <p>bin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))</p> <code>None</code> <code>by</code> <code>(str, List[str])</code> <p>group by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: 'freq:M' = monthly; 'freq:D' daily by default [\"model\",\"observation\"]</p> <code>None</code> <code>metrics</code> <code>list</code> <p>list of modelskill.metrics, by default modelskill.options.metrics.list</p> <code>None</code> <code>n_min</code> <code>int</code> <p>minimum number of observations in a grid cell; cells with fewer observations get a score of <code>np.nan</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>skill assessment as a dataset</p>"},{"location":"api/comparer/#modelskill.Comparer.gridded_skill--see-also","title":"See also","text":"<p>skill     a method for aggregated skill assessment</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)   # satellite altimeter vs. model\n&gt;&gt;&gt; cmp.gridded_skill(metrics='bias')\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n</code></pre> <pre><code>&gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; ds.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def gridded_skill(\n    self,\n    bins=5,\n    binsize: Optional[float] = None,\n    by: Optional[Union[str, List[str]]] = None,\n    metrics: Optional[list] = None,\n    n_min: Optional[int] = None,\n    **kwargs,\n):\n    \"\"\"Aggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n    Parameters\n    ----------\n    bins: int, list of scalars, or IntervalIndex, or tuple of, optional\n        criteria to bin x and y by, argument bins to pd.cut(), default 5\n        define different bins for x and y a tuple\n        e.g.: bins = 5, bins = (5,[2,3,5])\n    binsize : float, optional\n        bin size for x and y dimension, overwrites bins\n        creates bins with reference to round(mean(x)), round(mean(y))\n    by : (str, List[str]), optional\n        group by column name or by temporal bin via the freq-argument\n        (using pandas pd.Grouper(freq)),\n        e.g.: 'freq:M' = monthly; 'freq:D' daily\n        by default [\"model\",\"observation\"]\n    metrics : list, optional\n        list of modelskill.metrics, by default modelskill.options.metrics.list\n    n_min : int, optional\n        minimum number of observations in a grid cell;\n        cells with fewer observations get a score of `np.nan`\n\n    Returns\n    -------\n    xr.Dataset\n        skill assessment as a dataset\n\n    See also\n    --------\n    skill\n        a method for aggregated skill assessment\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cmp = ms.match(c2, mod)   # satellite altimeter vs. model\n    &gt;&gt;&gt; cmp.gridded_skill(metrics='bias')\n    &lt;xarray.Dataset&gt;\n    Dimensions:      (x: 5, y: 5)\n    Coordinates:\n        observation   'alti'\n    * x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n    * y            (y) float64 50.6 51.66 52.7 53.75 54.8\n    Data variables:\n        n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n        bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n\n    &gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n    &gt;&gt;&gt; ds.coords\n    Coordinates:\n        observation   'alti'\n    * x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n    * y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n    \"\"\"\n\n    # TODO remove in v1.1\n    model, start, end, area = _get_deprecated_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    cmp = self.sel(\n        model=model,\n        start=start,\n        end=end,\n        area=area,\n    )\n\n    metrics = _parse_metric(metrics, self.metrics, return_list=True)\n    if cmp.n_points == 0:\n        raise ValueError(\"No data to compare\")\n\n    df = cmp.to_dataframe()\n    df = _add_spatial_grid_to_df(df=df, bins=bins, binsize=binsize)\n\n    # n_models = len(df.model.unique())\n    # n_obs = len(df.observation.unique())\n\n    # n_obs=1 because we only have one observation (**SingleObsComparer**)\n    by = _parse_groupby(by=by, n_models=cmp.n_models, n_obs=1)\n    if isinstance(by, str) or (not isinstance(by, Iterable)):\n        by = [by]  # type: ignore\n    if \"x\" not in by:  # type: ignore\n        by.insert(0, \"x\")  # type: ignore\n    if \"y\" not in by:  # type: ignore\n        by.insert(0, \"y\")  # type: ignore\n\n    df = df.drop(columns=[\"x\", \"y\"]).rename(columns=dict(xBin=\"x\", yBin=\"y\"))\n    res = _groupby_df(df, by, metrics, n_min)\n    ds = res.to_xarray().squeeze()\n\n    # change categorial index to coordinates\n    for dim in (\"x\", \"y\"):\n        ds[dim] = ds[dim].astype(float)\n\n    return SkillGrid(ds)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.load","title":"<code>load(filename)</code>  <code>staticmethod</code>","text":"<p>Load from netcdf file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str or Path</code> <p>filename</p> required <p>Returns:</p> Type Description <code>Comparer</code> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>@staticmethod\ndef load(filename: Union[str, Path]) -&gt; \"Comparer\":\n    \"\"\"Load from netcdf file\n\n    Parameters\n    ----------\n    filename : str or Path\n        filename\n\n    Returns\n    -------\n    Comparer\n    \"\"\"\n    with xr.open_dataset(filename) as ds:\n        data = ds.load()\n\n    if data.gtype == \"track\":\n        return Comparer(matched_data=data)\n\n    if data.gtype == \"point\":\n        raw_mod_data: Dict[str, TimeSeries] = {}\n\n        for var in data.data_vars:\n            var_name = str(var)\n            if var_name[:5] == \"_raw_\":\n                new_key = var_name[5:]  # remove prefix '_raw_'\n                ds = data[[var_name]].rename(\n                    {\"_time_raw_\" + new_key: \"time\", var_name: new_key}\n                )\n                ts = PointObservation(data=ds, name=new_key)\n                # TODO: name of time?\n                # ts.name = new_key\n                # df = (\n                #     data[var_name]\n                #     .to_dataframe()\n                #     .rename(\n                #         columns={\"_time_raw_\" + new_key: \"time\", var_name: new_key}\n                #     )\n                # )\n                raw_mod_data[new_key] = ts\n\n                # data = data.drop(var_name).drop(\"_time_raw_\" + new_key)\n\n        # filter variables, only keep the ones with a 'time' dimension\n        data = data[[v for v in data.data_vars if \"time\" in data[v].dims]]\n\n        return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n\n    else:\n        raise NotImplementedError(f\"Unknown gtype: {data.gtype}\")\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.query","title":"<code>query(query)</code>","text":"<p>Return a new Comparer with values where query cond is True</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string, see pandas.DataFrame.query</p> required <p>Returns:</p> Type Description <code>Comparer</code> <p>New Comparer with values where cond is True and other otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; c2 = c.query(\"Observation &gt; 0\")\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def query(self, query: str) -&gt; \"Comparer\":\n    \"\"\"Return a new Comparer with values where query cond is True\n\n    Parameters\n    ----------\n    query : str\n        Query string, see pandas.DataFrame.query\n\n    Returns\n    -------\n    Comparer\n        New Comparer with values where cond is True and other otherwise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; c2 = c.query(\"Observation &gt; 0\")\n    \"\"\"\n    d = self.data.query({\"time\": query})\n    d = d.dropna(dim=\"time\", how=\"all\")\n    return Comparer.from_matched_data(d, self.raw_mod_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.rename","title":"<code>rename(mapping)</code>","text":"<p>Rename model or auxiliary data</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>dict</code> <p>mapping of old names to new names</p> required <p>Returns:</p> Type Description <code>Comparer</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cmp = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp.mod_names\n['model1']\n&gt;&gt;&gt; cmp2 = cmp.rename({'model1': 'model2'})\n&gt;&gt;&gt; cmp2.mod_names\n['model2']\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def rename(self, mapping: Mapping[str, str]) -&gt; \"Comparer\":\n    \"\"\"Rename model or auxiliary data\n\n    Parameters\n    ----------\n    mapping : dict\n        mapping of old names to new names\n\n    Returns\n    -------\n    Comparer\n\n    Examples\n    --------\n    &gt;&gt;&gt; cmp = ms.match(observation, modeldata)\n    &gt;&gt;&gt; cmp.mod_names\n    ['model1']\n    &gt;&gt;&gt; cmp2 = cmp.rename({'model1': 'model2'})\n    &gt;&gt;&gt; cmp2.mod_names\n    ['model2']\n    \"\"\"\n    data = self.data.rename(mapping)\n    raw_mod_data = {mapping.get(k, k): v for k, v in self.raw_mod_data.items()}\n\n    return Comparer(matched_data=data, raw_mod_data=raw_mod_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.save","title":"<code>save(filename)</code>","text":"<p>Save to netcdf file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str or Path</code> <p>filename</p> required Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def save(self, filename: Union[str, Path]) -&gt; None:\n    \"\"\"Save to netcdf file\n\n    Parameters\n    ----------\n    filename : str or Path\n        filename\n    \"\"\"\n    ds = self.data\n\n    # add self.raw_mod_data to ds with prefix 'raw_' to avoid name conflicts\n    # an alternative strategy would be to use NetCDF groups\n    # https://docs.xarray.dev/en/stable/user-guide/io.html#groups\n\n    # There is no need to save raw data for track data, since it is identical to the matched data\n    if self.gtype == \"point\":\n        ds = self.data.copy()  # copy needed to avoid modifying self.data\n\n        for key, ts_mod in self.raw_mod_data.items():\n            ts_mod = ts_mod.copy()\n            #  rename time to unique name\n            ts_mod.data = ts_mod.data.rename({\"time\": \"_time_raw_\" + key})\n            # da = ds_mod.to_xarray()[key]\n            ds[\"_raw_\" + key] = ts_mod.data[key]\n\n    ds.to_netcdf(filename)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.score","title":"<code>score(metric=mtr.rmse, **kwargs)</code>","text":"<p>Model skill score</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>list</code> <p>a single metric from modelskill.metrics, by default rmse</p> <code>rmse</code> <p>Returns:</p> Type Description <code>float</code> <p>skill score as a single number (for each model)</p>"},{"location":"api/comparer/#modelskill.Comparer.score--see-also","title":"See also","text":"<p>skill     a method for skill assessment returning a pd.DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)\n&gt;&gt;&gt; cmp.score()\n0.3517964910888918\n</code></pre> <pre><code>&gt;&gt;&gt; cmp.score(metric=ms.metrics.mape)\n11.567399646108198\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def score(\n    self,\n    metric: str | Callable = mtr.rmse,\n    **kwargs,\n) -&gt; Dict[str, float]:\n    \"\"\"Model skill score\n\n    Parameters\n    ----------\n    metric : list, optional\n        a single metric from modelskill.metrics, by default rmse\n\n    Returns\n    -------\n    float\n        skill score as a single number (for each model)\n\n    See also\n    --------\n    skill\n        a method for skill assessment returning a pd.DataFrame\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cmp = ms.match(c2, mod)\n    &gt;&gt;&gt; cmp.score()\n    0.3517964910888918\n\n    &gt;&gt;&gt; cmp.score(metric=ms.metrics.mape)\n    11.567399646108198\n    \"\"\"\n    metric = _parse_metric(metric, self.metrics)\n    if not (callable(metric) or isinstance(metric, str)):\n        raise ValueError(\"metric must be a string or a function\")\n\n    # TODO remove in v1.1\n    model, start, end, area = _get_deprecated_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    s = self.skill(\n        by=[\"model\", \"observation\"],\n        metrics=[metric],\n        model=model,  # deprecated\n        start=start,  # deprecated\n        end=end,  # deprecated\n        area=area,  # deprecated\n    )\n    df = s.to_dataframe()\n\n    metric_name = metric if isinstance(metric, str) else metric.__name__\n\n    return (\n        df.reset_index()\n        .groupby(\"model\", observed=True)[metric_name]\n        .mean()\n        .to_dict()\n    )\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.sel","title":"<code>sel(model=None, start=None, end=None, time=None, area=None)</code>","text":"<p>Select data based on model, time and/or area.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str or int or list of str or list of int</code> <p>Model name or index. If None, all models are selected.</p> <code>None</code> <code>start</code> <code>str or datetime</code> <p>Start time. If None, all times are selected.</p> <code>None</code> <code>end</code> <code>str or datetime</code> <p>End time. If None, all times are selected.</p> <code>None</code> <code>time</code> <code>str or datetime</code> <p>Time. If None, all times are selected.</p> <code>None</code> <code>area</code> <code>list of float</code> <p>bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.</p> <code>None</code> <p>Returns:</p> Type Description <code>Comparer</code> <p>New Comparer with selected data.</p> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def sel(\n    self,\n    model: Optional[IdOrNameTypes] = None,\n    start: Optional[TimeTypes] = None,\n    end: Optional[TimeTypes] = None,\n    time: Optional[TimeTypes] = None,\n    area: Optional[List[float]] = None,\n) -&gt; \"Comparer\":\n    \"\"\"Select data based on model, time and/or area.\n\n    Parameters\n    ----------\n    model : str or int or list of str or list of int, optional\n        Model name or index. If None, all models are selected.\n    start : str or datetime, optional\n        Start time. If None, all times are selected.\n    end : str or datetime, optional\n        End time. If None, all times are selected.\n    time : str or datetime, optional\n        Time. If None, all times are selected.\n    area : list of float, optional\n        bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\n\n    Returns\n    -------\n    Comparer\n        New Comparer with selected data.\n    \"\"\"\n    if (time is not None) and ((start is not None) or (end is not None)):\n        raise ValueError(\"Cannot use both time and start/end\")\n\n    d = self.data\n    raw_mod_data = self.raw_mod_data\n    if model is not None:\n        if isinstance(model, (str, int)):\n            models = [model]\n        else:\n            models = list(model)\n        mod_names: List[str] = [_get_name(m, self.mod_names) for m in models]\n        dropped_models = [m for m in self.mod_names if m not in mod_names]\n        d = d.drop_vars(dropped_models)\n        raw_mod_data = {m: raw_mod_data[m] for m in mod_names}\n    if (start is not None) or (end is not None):\n        # TODO: can this be done without to_index? (simplify)\n        d = d.sel(time=d.time.to_index().to_frame().loc[start:end].index)  # type: ignore\n\n        # Note: if user asks for a specific time, we also filter raw\n        raw_mod_data = {k: v.sel(time=slice(start, end)) for k, v in raw_mod_data.items()}  # type: ignore\n    if time is not None:\n        d = d.sel(time=time)\n\n        # Note: if user asks for a specific time, we also filter raw\n        raw_mod_data = {k: v.sel(time=time) for k, v in raw_mod_data.items()}\n    if area is not None:\n        if _area_is_bbox(area):\n            x0, y0, x1, y1 = area\n            mask = (d.x &gt; x0) &amp; (d.x &lt; x1) &amp; (d.y &gt; y0) &amp; (d.y &lt; y1)\n        elif _area_is_polygon(area):\n            polygon = np.array(area)\n            xy = np.column_stack((d.x, d.y))\n            mask = _inside_polygon(polygon, xy)\n        else:\n            raise ValueError(\"area supports bbox [x0,y0,x1,y1] and closed polygon\")\n        if self.gtype == \"point\":\n            # if False, return empty data\n            d = d if mask else d.isel(time=slice(None, 0))\n        else:\n            d = d.isel(time=mask)\n    return Comparer.from_matched_data(data=d, raw_mod_data=raw_mod_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.skill","title":"<code>skill(by=None, metrics=None, **kwargs)</code>","text":"<p>Skill assessment of model(s)</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>(str, List[str])</code> <p>group by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: 'freq:M' = monthly; 'freq:D' daily by default [\"model\"]</p> <code>None</code> <code>metrics</code> <code>list</code> <p>list of modelskill.metrics, by default modelskill.options.metrics.list</p> <code>None</code> <p>Returns:</p> Type Description <code>SkillTable</code> <p>skill assessment object</p>"},{"location":"api/comparer/#modelskill.Comparer.skill--see-also","title":"See also","text":"<p>sel     a method for filtering/selecting data</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match(c2, mod)\n&gt;&gt;&gt; cc['c2'].skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n</code></pre> <pre><code>&gt;&gt;&gt; cc['c2'].skill(by='freq:D').round(2)\n             n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  72 -0.19  0.31   0.25  0.26  0.48  0.12  0.98\n2017-10-28   0   NaN   NaN    NaN   NaN   NaN   NaN   NaN\n2017-10-29  41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def skill(\n    self,\n    by: Optional[Union[str, List[str]]] = None,\n    metrics: Optional[list] = None,\n    **kwargs,\n) -&gt; SkillTable:\n    \"\"\"Skill assessment of model(s)\n\n    Parameters\n    ----------\n    by : (str, List[str]), optional\n        group by column name or by temporal bin via the freq-argument\n        (using pandas pd.Grouper(freq)),\n        e.g.: 'freq:M' = monthly; 'freq:D' daily\n        by default [\"model\"]\n    metrics : list, optional\n        list of modelskill.metrics, by default modelskill.options.metrics.list\n\n    Returns\n    -------\n    SkillTable\n        skill assessment object\n\n    See also\n    --------\n    sel\n        a method for filtering/selecting data\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cc = ms.match(c2, mod)\n    &gt;&gt;&gt; cc['c2'].skill().round(2)\n                   n  bias  rmse  urmse   mae    cc    si    r2\n    observation\n    c2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n\n    &gt;&gt;&gt; cc['c2'].skill(by='freq:D').round(2)\n                 n  bias  rmse  urmse   mae    cc    si    r2\n    2017-10-27  72 -0.19  0.31   0.25  0.26  0.48  0.12  0.98\n    2017-10-28   0   NaN   NaN    NaN   NaN   NaN   NaN   NaN\n    2017-10-29  41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n    \"\"\"\n    metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n    # TODO remove in v1.1\n    model, start, end, area = _get_deprecated_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    cmp = self.sel(\n        model=model,\n        start=start,\n        end=end,\n        area=area,\n    )\n    if cmp.n_points == 0:\n        raise ValueError(\"No data selected for skill assessment\")\n\n    by = _parse_groupby(by, cmp.n_models, n_obs=1, n_var=1)\n\n    df = cmp.to_dataframe()\n    res = _groupby_df(df, by, metrics)\n    res[\"x\"] = df.groupby(by=by, observed=False).x.first()\n    res[\"y\"] = df.groupby(by=by, observed=False).y.first()\n    # TODO: set x,y to NaN if TrackObservation\n    res = self._add_as_col_if_not_in_index(df, skilldf=res)\n    return SkillTable(res)\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert to pandas DataFrame with all model data concatenated</p> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert to pandas DataFrame with all model data concatenated\"\"\"\n\n    # TODO is this needed?, comment out for now\n    # df = df.sort_index()\n    df = pd.concat([self._model_to_frame(name) for name in self.mod_names])\n    df[\"model\"] = df[\"model\"].astype(\"category\")\n    df[\"observation\"] = df[\"observation\"].astype(\"category\")\n    return df\n</code></pre>"},{"location":"api/comparer/#modelskill.Comparer.where","title":"<code>where(cond)</code>","text":"<p>Return a new Comparer with values where cond is True</p> <p>Parameters:</p> Name Type Description Default <code>cond</code> <code>(bool, ndarray, DataArray)</code> <p>This selects the values to return.</p> required <p>Returns:</p> Type Description <code>Comparer</code> <p>New Comparer with values where cond is True and other otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; c2 = c.where(c.data.Observation &gt; 0)\n</code></pre> Source code in <code>modelskill/comparison/_comparison.py</code> <pre><code>def where(\n    self,\n    cond: Union[bool, np.ndarray, xr.DataArray],\n) -&gt; \"Comparer\":\n    \"\"\"Return a new Comparer with values where cond is True\n\n    Parameters\n    ----------\n    cond : bool, np.ndarray, xr.DataArray\n        This selects the values to return.\n\n    Returns\n    -------\n    Comparer\n        New Comparer with values where cond is True and other otherwise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; c2 = c.where(c.data.Observation &gt; 0)\n    \"\"\"\n    d = self.data.where(cond, other=np.nan)\n    d = d.dropna(dim=\"time\", how=\"all\")\n    return Comparer.from_matched_data(d, self.raw_mod_data)\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter","title":"<code>modelskill.comparison._comparer_plotter.ComparerPlotter</code>","text":"<p>Plotter class for Comparer</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>class ComparerPlotter:\n    \"\"\"Plotter class for Comparer\"\"\"\n\n    def __init__(self, comparer: Comparer):\n        self.comparer = comparer\n        self.is_directional = comparer.quantity.is_directional\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Plot scatter plot of modelled vs observed data\"\"\"\n        return self.scatter(*args, **kwargs)\n\n    def timeseries(\n        self,\n        *,\n        title: str | None = None,\n        ylim: Tuple[float, float] | None = None,\n        ax=None,\n        figsize: Tuple[float, float] | None = None,\n        backend: str = \"matplotlib\",\n        **kwargs,\n    ):\n        \"\"\"Timeseries plot showing compared data: observation vs modelled\n\n        Parameters\n        ----------\n        title : str, optional\n            plot title, by default None\n        ylim : (float, float), optional\n            plot range for the model (ymin, ymax), by default None\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        figsize : (float, float), optional\n            figure size, by default None\n        backend : str, optional\n            use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"backend:\n\n        Returns\n        -------\n        matplotlib.axes.Axes or plotly.graph_objects.Figure\n        \"\"\"\n        from ._comparison import MOD_COLORS\n\n        cmp = self.comparer\n\n        if title is None:\n            title = cmp.name\n\n        if backend == \"matplotlib\":\n            fig, ax = _get_fig_ax(ax, figsize)\n            for j in range(cmp.n_models):\n                key = cmp.mod_names[j]\n                mod = cmp.raw_mod_data[key]._values_as_series\n                mod.plot(ax=ax, color=MOD_COLORS[j])\n\n            ax.scatter(\n                cmp.time,\n                cmp.data[cmp._obs_name].values,\n                marker=\".\",\n                color=cmp.data[cmp._obs_name].attrs[\"color\"],\n            )\n            ax.set_ylabel(cmp.unit_text)\n            ax.legend([*cmp.mod_names, cmp._obs_name])\n            ax.set_ylim(ylim)\n            if self.is_directional:\n                _ytick_directional(ax, ylim)\n            ax.set_title(title)\n            return ax\n\n        elif backend == \"plotly\":  # pragma: no cover\n            import plotly.graph_objects as go  # type: ignore\n\n            mod_scatter_list = []\n            for j in range(cmp.n_models):\n                key = cmp.mod_names[j]\n                mod = cmp.raw_mod_data[key]._values_as_series\n                mod_scatter_list.append(\n                    go.Scatter(\n                        x=mod.index,\n                        y=mod.values,\n                        name=key,\n                        line=dict(color=MOD_COLORS[j]),\n                    )\n                )\n\n            fig = go.Figure(\n                [\n                    *mod_scatter_list,\n                    go.Scatter(\n                        x=cmp.time,\n                        y=cmp.data[cmp._obs_name].values,\n                        name=cmp._obs_name,\n                        mode=\"markers\",\n                        marker=dict(color=cmp.data[cmp._obs_name].attrs[\"color\"]),\n                    ),\n                ]\n            )\n\n            fig.update_layout(title=title, yaxis_title=cmp.unit_text, **kwargs)\n            fig.update_yaxes(range=ylim)\n\n            return fig\n        else:\n            raise ValueError(f\"Plotting backend: {backend} not supported\")\n\n    def hist(\n        self,\n        bins: int | Sequence = 100,\n        *,\n        model: str | int | None = None,\n        title: str | None = None,\n        ax=None,\n        figsize: Tuple[float, float] | None = None,\n        density: bool = True,\n        alpha: float = 0.5,\n        **kwargs,\n    ):\n        \"\"\"Plot histogram of model data and observations.\n\n        Wraps pandas.DataFrame hist() method.\n\n        Parameters\n        ----------\n        bins : int, optional\n            number of bins, by default 100\n        title : str, optional\n            plot title, default: [model name] vs [observation name]\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        figsize : tuple, optional\n            figure size, by default None\n        density: bool, optional\n            If True, draw and return a probability density\n        alpha : float, optional\n            alpha transparency fraction, by default 0.5\n        kwargs : other keyword arguments to df.plot.hist()\n\n        Returns\n        -------\n        matplotlib axes\n\n        See also\n        --------\n        pandas.Series.plot.hist\n        matplotlib.axes.Axes.hist\n        \"\"\"\n        cmp = self.comparer\n\n        if model is None:\n            mod_names = cmp.mod_names\n        else:\n            warnings.warn(\n                \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.hist()\",\n                FutureWarning,\n            )\n            model_list = [model] if isinstance(model, (str, int)) else model\n            mod_names = [cmp.mod_names[_get_idx(m, cmp.mod_names)] for m in model_list]\n\n        axes = []\n        for mod_name in mod_names:\n            ax_mod = self._hist_one_model(\n                mod_name=mod_name,\n                bins=bins,\n                title=title,\n                ax=ax,\n                figsize=figsize,\n                density=density,\n                alpha=alpha,\n                **kwargs,\n            )\n            axes.append(ax_mod)\n\n        return axes[0] if len(axes) == 1 else axes\n\n    def _hist_one_model(\n        self,\n        *,\n        mod_name: str,\n        bins: int | Sequence | None,\n        title: str | None,\n        ax,\n        figsize: Tuple[float, float] | None,\n        density: bool | None,\n        alpha: float | None,\n        **kwargs,\n    ):\n        from ._comparison import MOD_COLORS  # TODO move to here\n\n        cmp = self.comparer\n        assert mod_name in cmp.mod_names, f\"Model {mod_name} not found in comparer\"\n        mod_id = _get_idx(mod_name, cmp.mod_names)\n\n        title = f\"{mod_name} vs {cmp.name}\" if title is None else title\n\n        _, ax = _get_fig_ax(ax, figsize)\n\n        kwargs[\"alpha\"] = alpha\n        kwargs[\"density\"] = density\n        kwargs[\"ax\"] = ax\n\n        ax = (\n            cmp.data[mod_name]\n            .to_series()\n            .hist(bins=bins, color=MOD_COLORS[mod_id], **kwargs)\n        )\n\n        cmp.data[cmp._obs_name].to_series().hist(\n            bins=bins, color=cmp.data[cmp._obs_name].attrs[\"color\"], **kwargs\n        )\n        ax.legend([mod_name, cmp._obs_name])\n        ax.set_title(title)\n        ax.set_xlabel(f\"{cmp.unit_text}\")\n        if density:\n            ax.set_ylabel(\"density\")\n        else:\n            ax.set_ylabel(\"count\")\n\n        if self.is_directional:\n            _xtick_directional(ax)\n\n        return ax\n\n    def kde(self, ax=None, title=None, figsize=None, **kwargs) -&gt; matplotlib.axes.Axes:\n        \"\"\"Plot kde (kernel density estimates of distributions) of model data and observations.\n\n        Wraps pandas.DataFrame kde() method.\n\n        Parameters\n        ----------\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        title : str, optional\n            plot title, default: \"KDE plot for [observation name]\"\n        figsize : tuple, optional\n            figure size, by default None\n        kwargs : other keyword arguments to df.plot.kde()\n\n        Returns\n        -------\n        matplotlib.axes.Axes\n\n        Examples\n        --------\n        &gt;&gt;&gt; cmp.plot.kde()\n        &gt;&gt;&gt; cmp.plot.kde(bw_method=0.3)\n        &gt;&gt;&gt; cmp.plot.kde(ax=ax, bw_method='silverman')\n        &gt;&gt;&gt; cmp.plot.kde(xlim=[0,None], title=\"Density plot\");\n\n        See also\n        --------\n        pandas.Series.plot.kde\n        \"\"\"\n        cmp = self.comparer\n\n        _, ax = _get_fig_ax(ax, figsize)\n\n        cmp.data.Observation.to_series().plot.kde(\n            ax=ax, linestyle=\"dashed\", label=\"Observation\", **kwargs\n        )\n\n        for model in cmp.mod_names:\n            cmp.data[model].to_series().plot.kde(ax=ax, label=model, **kwargs)\n\n        ax.set_xlabel(cmp.unit_text)  # TODO\n\n        ax.legend()\n\n        # remove y-axis, ticks and label\n        ax.yaxis.set_visible(False)\n        ax.tick_params(axis=\"y\", which=\"both\", length=0)\n        ax.set_ylabel(\"\")\n        title = f\"KDE plot for {cmp.name}\" if title is None else title\n        ax.set_title(title)\n\n        # remove box around plot\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n\n        if self.is_directional:\n            _xtick_directional(ax)\n\n        return ax\n\n    def qq(\n        self,\n        quantiles: int | Sequence[float] | None = None,\n        *,\n        title=None,\n        ax=None,\n        figsize=None,\n        **kwargs,\n    ):\n        \"\"\"Make quantile-quantile (q-q) plot of model data and observations.\n\n        Primarily used to compare multiple models.\n\n        Parameters\n        ----------\n        quantiles: (int, sequence), optional\n            number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n            if int, this is the number of points\n            if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n        title : str, optional\n            plot title, default: \"Q-Q plot for [observation name]\"\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        figsize : tuple, optional\n            figure size, by default None\n        kwargs : other keyword arguments to plt.plot()\n\n        Returns\n        -------\n        matplotlib axes\n\n        Examples\n        --------\n        &gt;&gt;&gt; cmp.plot.qq()\n\n        \"\"\"\n        cmp = self.comparer\n\n        _, ax = _get_fig_ax(ax, figsize)\n\n        x = cmp.data.Observation.values\n        xmin, xmax = x.min(), x.max()\n        ymin, ymax = np.inf, -np.inf\n\n        for mod_name in cmp.mod_names:\n            y = cmp.data[mod_name].values\n            ymin = min([y.min(), ymin])\n            ymax = max([y.max(), ymax])\n            xq, yq = quantiles_xy(x, y, quantiles)\n            ax.plot(\n                xq,\n                yq,\n                \".-\",\n                label=mod_name,\n                zorder=4,\n                **kwargs,\n            )\n\n        xymin = min([xmin, ymin])\n        xymax = max([xmax, ymax])\n\n        # 1:1 line\n        ax.plot(\n            [xymin, xymax],\n            [xymin, xymax],\n            label=options.plot.scatter.oneone_line.label,\n            c=options.plot.scatter.oneone_line.color,\n            zorder=3,\n        )\n\n        ax.axis(\"square\")\n        ax.set_xlim([xymin, xymax])\n        ax.set_ylim([xymin, xymax])\n        ax.minorticks_on()\n        ax.grid(which=\"both\", axis=\"both\", linewidth=\"0.2\", color=\"k\", alpha=0.6)\n\n        ax.legend()\n        ax.set_xlabel(\"Observation, \" + cmp.unit_text)\n        ax.set_ylabel(\"Model, \" + cmp.unit_text)\n        ax.set_title(title or f\"Q-Q plot for {cmp.name}\")\n\n        if self.is_directional:\n            _xtick_directional(ax)\n            _ytick_directional(ax)\n\n        return ax\n\n    def box(self, *, ax=None, title=None, figsize=None, **kwargs):\n        \"\"\"Make a box plot of model data and observations.\n\n        Wraps pandas.DataFrame boxplot() method.\n\n        Parameters\n        ----------\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        title : str, optional\n            plot title, default: [observation name]\n        figsize : tuple, optional\n            figure size, by default None\n        kwargs : other keyword arguments to df.boxplot()\n\n        Returns\n        -------\n        matplotlib axes\n\n        Examples\n        --------\n        &gt;&gt;&gt; cmp.plot.box()\n        &gt;&gt;&gt; cmp.plot.box(showmeans=True)\n        &gt;&gt;&gt; cmp.plot.box(ax=ax, title=\"Box plot\")\n\n        See also\n        --------\n        pandas.DataFrame.boxplot\n        matplotlib.pyplot.boxplot\n        \"\"\"\n        cmp = self.comparer\n\n        _, ax = _get_fig_ax(ax, figsize)\n\n        cols = [\"Observation\"] + cmp.mod_names\n        df = cmp.data[cols].to_dataframe()[cols]\n        df.boxplot(ax=ax, **kwargs)\n        ax.set_ylabel(cmp.unit_text)\n        ax.set_title(title or cmp.name)\n\n        if self.is_directional:\n            _ytick_directional(ax)\n\n        return ax\n\n    def scatter(\n        self,\n        *,\n        model=None,\n        bins: int | float = 120,\n        quantiles: int | Sequence[float] | None = None,\n        fit_to_quantiles: bool = False,\n        show_points: bool | int | float | None = None,\n        show_hist: Optional[bool] = None,\n        show_density: Optional[bool] = None,\n        norm: Optional[colors.Normalize] = None,\n        backend: str = \"matplotlib\",\n        figsize: Tuple[float, float] = (8, 8),\n        xlim: Optional[Tuple[float, float]] = None,\n        ylim: Optional[Tuple[float, float]] = None,\n        reg_method: str | bool = \"ols\",\n        title: Optional[str] = None,\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        skill_table: Optional[Union[str, List[str], bool]] = None,\n        **kwargs,\n    ):\n        \"\"\"Scatter plot showing compared data: observation vs modelled\n        Optionally, with density histogram.\n\n        Parameters\n        ----------\n        bins: (int, float, sequence), optional\n            bins for the 2D histogram on the background. By default 20 bins.\n            if int, represents the number of bins of 2D\n            if float, represents the bin size\n            if sequence (list of int or float), represents the bin edges\n        quantiles: (int, sequence), optional\n            number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n            if int, this is the number of points\n            if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n        fit_to_quantiles: bool, optional, by default False\n            by default the regression line is fitted to all data, if True, it is fitted to the quantiles\n            which can be useful to represent the extremes of the distribution\n        show_points : (bool, int, float), optional\n            Should the scatter points be displayed?\n            None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None.\n            float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points.\n            int: if 'n' (int) given, then 'n' points will be displayed, randomly selected\n        show_hist : bool, optional\n            show the data density as a a 2d histogram, by default None\n        show_density: bool, optional\n            show the data density as a colormap of the scatter, by default None. \n            If both `show_density` and `show_hist` are None, then `show_density` \n            is used by default. For binning the data, the kword `bins=Float` is used. \n        norm : matplotlib.colors norm\n            colormap normalization\n            If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)\n        backend : str, optional\n            use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"\n        figsize : tuple, optional\n            width and height of the figure, by default (8, 8)\n        xlim : tuple, optional\n            plot range for the observation (xmin, xmax), by default None\n        ylim : tuple, optional\n            plot range for the model (ymin, ymax), by default None\n        reg_method : str or bool, optional\n            method for determining the regression line\n            \"ols\" : ordinary least squares regression\n            \"odr\" : orthogonal distance regression,\n            False : no regression line\n            by default \"ols\"\n        title : str, optional\n            plot title, by default None\n        xlabel : str, optional\n            x-label text on plot, by default None\n        ylabel : str, optional\n            y-label text on plot, by default None\n        skill_table : str, List[str], bool, optional\n            list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list.\n            This kword adds a box at the right of the scatter plot,\n            by default False\n        kwargs\n\n        Examples\n        ------\n        &gt;&gt;&gt; cmp.plot.scatter()\n        &gt;&gt;&gt; cmp.plot.scatter(bins=0.2, backend='plotly')\n        &gt;&gt;&gt; cmp.plot.scatter(show_points=False, title='no points')\n        &gt;&gt;&gt; cmp.plot.scatter(xlabel='all observations', ylabel='my model')\n        &gt;&gt;&gt; cmp.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n        \"\"\"\n\n        cmp = self.comparer\n        if model is None:\n            mod_names = cmp.mod_names\n        else:\n            warnings.warn(\n                \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.scatter()\",\n                FutureWarning,\n            )\n            model_list = [model] if isinstance(model, (str, int)) else model\n            mod_names = [cmp.mod_names[_get_idx(m, cmp.mod_names)] for m in model_list]\n\n        axes = []\n        for mod_name in mod_names:\n            ax_mod = self._scatter_one_model(\n                mod_name=mod_name,\n                bins=bins,\n                quantiles=quantiles,\n                fit_to_quantiles=fit_to_quantiles,\n                show_points=show_points,\n                show_hist=show_hist,\n                show_density=show_density,\n                norm=norm,\n                backend=backend,\n                figsize=figsize,\n                xlim=xlim,\n                ylim=ylim,\n                reg_method=reg_method,\n                title=title,\n                xlabel=xlabel,\n                ylabel=ylabel,\n                skill_table=skill_table,\n                **kwargs,\n            )\n            axes.append(ax_mod)\n        return axes[0] if len(axes) == 1 else axes\n\n    def _scatter_one_model(\n        self,\n        *,\n        mod_name: str,\n        bins: int | float,\n        quantiles: int | Sequence[float] | None,\n        fit_to_quantiles: bool,\n        show_points: bool | int | float | None,\n        show_hist: Optional[bool],\n        show_density: Optional[bool],\n        norm: Optional[colors.Normalize],\n        backend: str,\n        figsize: Tuple[float, float],\n        xlim: Optional[Tuple[float, float]],\n        ylim: Optional[Tuple[float, float]],\n        reg_method: str | bool,\n        title: Optional[str],\n        xlabel: Optional[str],\n        ylabel: Optional[str],\n        skill_table: Optional[Union[str, List[str], bool]],\n        **kwargs,\n    ):\n        \"\"\"Scatter plot for one model only\"\"\"\n\n        cmp = self.comparer\n        assert mod_name in cmp.mod_names, f\"Model {mod_name} not found in comparer\"\n\n        if cmp.n_points == 0:\n            raise ValueError(\"No data found in selection\")\n\n        x = cmp.data.Observation.values\n        y = cmp.data[mod_name].values\n\n        assert x.ndim == y.ndim == 1, \"x and y must be 1D arrays\"\n        assert x.shape == y.shape, \"x and y must have the same shape\"\n\n        unit_text = cmp.unit_text\n        xlabel = xlabel or f\"Observation, {unit_text}\"\n        ylabel = ylabel or f\"Model, {unit_text}\"\n        title = title or f\"{mod_name} vs {cmp.name}\"\n\n        skill = None\n        units = None\n\n        if skill_table:\n            metrics = None if skill_table is True else skill_table\n            skill = cmp.skill(metrics=metrics)  # type: ignore\n            try:\n                units = unit_text.split(\"[\")[1].split(\"]\")[0]\n            except IndexError:\n                units = \"\"  # Dimensionless\n\n        if self.is_directional:\n            # hide quantiles and regression line\n            quantiles = 0\n            reg_method = False\n\n        ax = scatter(\n            x=x,\n            y=y,\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            norm=norm,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            skill_df=skill,\n            units=units,\n            **kwargs,\n        )\n\n        if backend == \"matplotlib\" and self.is_directional:\n            _xtick_directional(ax, xlim)\n            _ytick_directional(ax, ylim)\n\n        return ax\n\n    def taylor(\n        self,\n        *,\n        normalize_std: bool = False,\n        figsize: Tuple[float, float] = (7, 7),\n        marker: str = \"o\",\n        marker_size: float = 6.0,\n        title: str = \"Taylor diagram\",\n    ):\n        \"\"\"Taylor diagram showing model std and correlation to observation\n        in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n        Parameters\n        ----------\n        normalize_std : bool, optional\n            plot model std normalized with observation std, default False\n        figsize : tuple, optional\n            width and height of the figure (should be square), by default (7, 7)\n        marker : str, optional\n            marker type e.g. \"x\", \"*\", by default \"o\"\n        marker_size : float, optional\n            size of the marker, by default 6\n        title : str, optional\n            title of the plot, by default \"Taylor diagram\"\n\n        Returns\n        -------\n        matplotlib.figure.Figure\n\n        Examples\n        ------\n        &gt;&gt;&gt; comparer.taylor()\n        &gt;&gt;&gt; comparer.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n        References\n        ----------\n        Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin &lt;yannick.copin@laposte.net&gt;\n        \"\"\"\n        cmp = self.comparer\n\n        # TODO consider if this round-trip  via mtr is necessary to get the std:s\n        metrics = [\n            mtr._std_obs,\n            mtr._std_mod,\n            mtr.cc,\n        ]\n\n        s = cmp.skill(metrics=metrics)\n\n        if s is None:  # TODO\n            return\n        df = s.to_dataframe()\n        ref_std = 1.0 if normalize_std else df.iloc[0][\"_std_obs\"]\n\n        df = df[[\"_std_obs\", \"_std_mod\", \"cc\"]].copy()\n        df.columns = [\"obs_std\", \"std\", \"cc\"]\n\n        pts = [\n            TaylorPoint(\n                r.Index, r.obs_std, r.std, r.cc, marker=marker, marker_size=marker_size\n            )\n            for r in df.itertuples()\n        ]\n\n        return taylor_diagram(\n            obs_std=ref_std,\n            points=pts,\n            figsize=figsize,\n            obs_text=f\"Obs: {cmp.name}\",\n            normalize_std=normalize_std,\n            title=title,\n        )\n\n    def residual_hist(\n        self, bins=100, title=None, color=None, figsize=None, ax=None, **kwargs\n    ) -&gt; matplotlib.axes.Axes:\n        \"\"\"plot histogram of residual values\n\n        Parameters\n        ----------\n        bins : int, optional\n            specification of bins, by default 100\n        title : str, optional\n            plot title, default: Residuals, [name]\n        color : str, optional\n            residual color, by default \"#8B8D8E\"\n        figsize : tuple, optional\n            figure size, by default None\n        ax : matplotlib.axes.Axes, optional\n            axes to plot on, by default None\n        kwargs : other keyword arguments to plt.hist()\n\n        Returns\n        -------\n        matplotlib.axes.Axes\n        \"\"\"\n        _, ax = _get_fig_ax(ax, figsize)\n\n        default_color = \"#8B8D8E\"\n        color = default_color if color is None else color\n        title = f\"Residuals, {self.comparer.name}\" if title is None else title\n        ax.hist(self.comparer.residual, bins=bins, color=color, **kwargs)\n        ax.set_title(title)\n        ax.set_xlabel(f\"Residuals of {self.comparer.unit_text}\")\n\n        if self.is_directional:\n            ticks = np.linspace(-180, 180, 9)\n            ax.set_xticks(ticks)\n            ax.set_xlim(-180, 180)\n\n        return ax\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Plot scatter plot of modelled vs observed data</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def __call__(self, *args, **kwargs):\n    \"\"\"Plot scatter plot of modelled vs observed data\"\"\"\n    return self.scatter(*args, **kwargs)\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.box","title":"<code>box(*, ax=None, title=None, figsize=None, **kwargs)</code>","text":"<p>Make a box plot of model data and observations.</p> <p>Wraps pandas.DataFrame boxplot() method.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>title</code> <code>str</code> <p>plot title, default: [observation name]</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>figure size, by default None</p> <code>None</code> <code>kwargs</code> <code>other keyword arguments to df.boxplot()</code> <code>{}</code> <p>Returns:</p> Type Description <code>matplotlib axes</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cmp.plot.box()\n&gt;&gt;&gt; cmp.plot.box(showmeans=True)\n&gt;&gt;&gt; cmp.plot.box(ax=ax, title=\"Box plot\")\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.box--see-also","title":"See also","text":"<p>pandas.DataFrame.boxplot matplotlib.pyplot.boxplot</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def box(self, *, ax=None, title=None, figsize=None, **kwargs):\n    \"\"\"Make a box plot of model data and observations.\n\n    Wraps pandas.DataFrame boxplot() method.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    title : str, optional\n        plot title, default: [observation name]\n    figsize : tuple, optional\n        figure size, by default None\n    kwargs : other keyword arguments to df.boxplot()\n\n    Returns\n    -------\n    matplotlib axes\n\n    Examples\n    --------\n    &gt;&gt;&gt; cmp.plot.box()\n    &gt;&gt;&gt; cmp.plot.box(showmeans=True)\n    &gt;&gt;&gt; cmp.plot.box(ax=ax, title=\"Box plot\")\n\n    See also\n    --------\n    pandas.DataFrame.boxplot\n    matplotlib.pyplot.boxplot\n    \"\"\"\n    cmp = self.comparer\n\n    _, ax = _get_fig_ax(ax, figsize)\n\n    cols = [\"Observation\"] + cmp.mod_names\n    df = cmp.data[cols].to_dataframe()[cols]\n    df.boxplot(ax=ax, **kwargs)\n    ax.set_ylabel(cmp.unit_text)\n    ax.set_title(title or cmp.name)\n\n    if self.is_directional:\n        _ytick_directional(ax)\n\n    return ax\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.hist","title":"<code>hist(bins=100, *, model=None, title=None, ax=None, figsize=None, density=True, alpha=0.5, **kwargs)</code>","text":"<p>Plot histogram of model data and observations.</p> <p>Wraps pandas.DataFrame hist() method.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int</code> <p>number of bins, by default 100</p> <code>100</code> <code>title</code> <code>str</code> <p>plot title, default: [model name] vs [observation name]</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>figure size, by default None</p> <code>None</code> <code>density</code> <code>bool</code> <p>If True, draw and return a probability density</p> <code>True</code> <code>alpha</code> <code>float</code> <p>alpha transparency fraction, by default 0.5</p> <code>0.5</code> <code>kwargs</code> <code>other keyword arguments to df.plot.hist()</code> <code>{}</code> <p>Returns:</p> Type Description <code>matplotlib axes</code>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.hist--see-also","title":"See also","text":"<p>pandas.Series.plot.hist matplotlib.axes.Axes.hist</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def hist(\n    self,\n    bins: int | Sequence = 100,\n    *,\n    model: str | int | None = None,\n    title: str | None = None,\n    ax=None,\n    figsize: Tuple[float, float] | None = None,\n    density: bool = True,\n    alpha: float = 0.5,\n    **kwargs,\n):\n    \"\"\"Plot histogram of model data and observations.\n\n    Wraps pandas.DataFrame hist() method.\n\n    Parameters\n    ----------\n    bins : int, optional\n        number of bins, by default 100\n    title : str, optional\n        plot title, default: [model name] vs [observation name]\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    figsize : tuple, optional\n        figure size, by default None\n    density: bool, optional\n        If True, draw and return a probability density\n    alpha : float, optional\n        alpha transparency fraction, by default 0.5\n    kwargs : other keyword arguments to df.plot.hist()\n\n    Returns\n    -------\n    matplotlib axes\n\n    See also\n    --------\n    pandas.Series.plot.hist\n    matplotlib.axes.Axes.hist\n    \"\"\"\n    cmp = self.comparer\n\n    if model is None:\n        mod_names = cmp.mod_names\n    else:\n        warnings.warn(\n            \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.hist()\",\n            FutureWarning,\n        )\n        model_list = [model] if isinstance(model, (str, int)) else model\n        mod_names = [cmp.mod_names[_get_idx(m, cmp.mod_names)] for m in model_list]\n\n    axes = []\n    for mod_name in mod_names:\n        ax_mod = self._hist_one_model(\n            mod_name=mod_name,\n            bins=bins,\n            title=title,\n            ax=ax,\n            figsize=figsize,\n            density=density,\n            alpha=alpha,\n            **kwargs,\n        )\n        axes.append(ax_mod)\n\n    return axes[0] if len(axes) == 1 else axes\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.kde","title":"<code>kde(ax=None, title=None, figsize=None, **kwargs)</code>","text":"<p>Plot kde (kernel density estimates of distributions) of model data and observations.</p> <p>Wraps pandas.DataFrame kde() method.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>title</code> <code>str</code> <p>plot title, default: \"KDE plot for [observation name]\"</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>figure size, by default None</p> <code>None</code> <code>kwargs</code> <code>other keyword arguments to df.plot.kde()</code> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cmp.plot.kde()\n&gt;&gt;&gt; cmp.plot.kde(bw_method=0.3)\n&gt;&gt;&gt; cmp.plot.kde(ax=ax, bw_method='silverman')\n&gt;&gt;&gt; cmp.plot.kde(xlim=[0,None], title=\"Density plot\");\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.kde--see-also","title":"See also","text":"<p>pandas.Series.plot.kde</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def kde(self, ax=None, title=None, figsize=None, **kwargs) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot kde (kernel density estimates of distributions) of model data and observations.\n\n    Wraps pandas.DataFrame kde() method.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    title : str, optional\n        plot title, default: \"KDE plot for [observation name]\"\n    figsize : tuple, optional\n        figure size, by default None\n    kwargs : other keyword arguments to df.plot.kde()\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n\n    Examples\n    --------\n    &gt;&gt;&gt; cmp.plot.kde()\n    &gt;&gt;&gt; cmp.plot.kde(bw_method=0.3)\n    &gt;&gt;&gt; cmp.plot.kde(ax=ax, bw_method='silverman')\n    &gt;&gt;&gt; cmp.plot.kde(xlim=[0,None], title=\"Density plot\");\n\n    See also\n    --------\n    pandas.Series.plot.kde\n    \"\"\"\n    cmp = self.comparer\n\n    _, ax = _get_fig_ax(ax, figsize)\n\n    cmp.data.Observation.to_series().plot.kde(\n        ax=ax, linestyle=\"dashed\", label=\"Observation\", **kwargs\n    )\n\n    for model in cmp.mod_names:\n        cmp.data[model].to_series().plot.kde(ax=ax, label=model, **kwargs)\n\n    ax.set_xlabel(cmp.unit_text)  # TODO\n\n    ax.legend()\n\n    # remove y-axis, ticks and label\n    ax.yaxis.set_visible(False)\n    ax.tick_params(axis=\"y\", which=\"both\", length=0)\n    ax.set_ylabel(\"\")\n    title = f\"KDE plot for {cmp.name}\" if title is None else title\n    ax.set_title(title)\n\n    # remove box around plot\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n\n    if self.is_directional:\n        _xtick_directional(ax)\n\n    return ax\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.qq","title":"<code>qq(quantiles=None, *, title=None, ax=None, figsize=None, **kwargs)</code>","text":"<p>Make quantile-quantile (q-q) plot of model data and observations.</p> <p>Primarily used to compare multiple models.</p> <p>Parameters:</p> Name Type Description Default <code>quantiles</code> <code>int | Sequence[float] | None</code> <p>number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)</p> <code>None</code> <code>title</code> <code>str</code> <p>plot title, default: \"Q-Q plot for [observation name]\"</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>figure size, by default None</p> <code>None</code> <code>kwargs</code> <code>other keyword arguments to plt.plot()</code> <code>{}</code> <p>Returns:</p> Type Description <code>matplotlib axes</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cmp.plot.qq()\n</code></pre> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def qq(\n    self,\n    quantiles: int | Sequence[float] | None = None,\n    *,\n    title=None,\n    ax=None,\n    figsize=None,\n    **kwargs,\n):\n    \"\"\"Make quantile-quantile (q-q) plot of model data and observations.\n\n    Primarily used to compare multiple models.\n\n    Parameters\n    ----------\n    quantiles: (int, sequence), optional\n        number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n        if int, this is the number of points\n        if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n    title : str, optional\n        plot title, default: \"Q-Q plot for [observation name]\"\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    figsize : tuple, optional\n        figure size, by default None\n    kwargs : other keyword arguments to plt.plot()\n\n    Returns\n    -------\n    matplotlib axes\n\n    Examples\n    --------\n    &gt;&gt;&gt; cmp.plot.qq()\n\n    \"\"\"\n    cmp = self.comparer\n\n    _, ax = _get_fig_ax(ax, figsize)\n\n    x = cmp.data.Observation.values\n    xmin, xmax = x.min(), x.max()\n    ymin, ymax = np.inf, -np.inf\n\n    for mod_name in cmp.mod_names:\n        y = cmp.data[mod_name].values\n        ymin = min([y.min(), ymin])\n        ymax = max([y.max(), ymax])\n        xq, yq = quantiles_xy(x, y, quantiles)\n        ax.plot(\n            xq,\n            yq,\n            \".-\",\n            label=mod_name,\n            zorder=4,\n            **kwargs,\n        )\n\n    xymin = min([xmin, ymin])\n    xymax = max([xmax, ymax])\n\n    # 1:1 line\n    ax.plot(\n        [xymin, xymax],\n        [xymin, xymax],\n        label=options.plot.scatter.oneone_line.label,\n        c=options.plot.scatter.oneone_line.color,\n        zorder=3,\n    )\n\n    ax.axis(\"square\")\n    ax.set_xlim([xymin, xymax])\n    ax.set_ylim([xymin, xymax])\n    ax.minorticks_on()\n    ax.grid(which=\"both\", axis=\"both\", linewidth=\"0.2\", color=\"k\", alpha=0.6)\n\n    ax.legend()\n    ax.set_xlabel(\"Observation, \" + cmp.unit_text)\n    ax.set_ylabel(\"Model, \" + cmp.unit_text)\n    ax.set_title(title or f\"Q-Q plot for {cmp.name}\")\n\n    if self.is_directional:\n        _xtick_directional(ax)\n        _ytick_directional(ax)\n\n    return ax\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.residual_hist","title":"<code>residual_hist(bins=100, title=None, color=None, figsize=None, ax=None, **kwargs)</code>","text":"<p>plot histogram of residual values</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int</code> <p>specification of bins, by default 100</p> <code>100</code> <code>title</code> <code>str</code> <p>plot title, default: Residuals, [name]</p> <code>None</code> <code>color</code> <code>str</code> <p>residual color, by default \"#8B8D8E\"</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>figure size, by default None</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>kwargs</code> <code>other keyword arguments to plt.hist()</code> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def residual_hist(\n    self, bins=100, title=None, color=None, figsize=None, ax=None, **kwargs\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"plot histogram of residual values\n\n    Parameters\n    ----------\n    bins : int, optional\n        specification of bins, by default 100\n    title : str, optional\n        plot title, default: Residuals, [name]\n    color : str, optional\n        residual color, by default \"#8B8D8E\"\n    figsize : tuple, optional\n        figure size, by default None\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    kwargs : other keyword arguments to plt.hist()\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n    \"\"\"\n    _, ax = _get_fig_ax(ax, figsize)\n\n    default_color = \"#8B8D8E\"\n    color = default_color if color is None else color\n    title = f\"Residuals, {self.comparer.name}\" if title is None else title\n    ax.hist(self.comparer.residual, bins=bins, color=color, **kwargs)\n    ax.set_title(title)\n    ax.set_xlabel(f\"Residuals of {self.comparer.unit_text}\")\n\n    if self.is_directional:\n        ticks = np.linspace(-180, 180, 9)\n        ax.set_xticks(ticks)\n        ax.set_xlim(-180, 180)\n\n    return ax\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.scatter","title":"<code>scatter(*, model=None, bins=120, quantiles=None, fit_to_quantiles=False, show_points=None, show_hist=None, show_density=None, norm=None, backend='matplotlib', figsize=(8, 8), xlim=None, ylim=None, reg_method='ols', title=None, xlabel=None, ylabel=None, skill_table=None, **kwargs)</code>","text":"<p>Scatter plot showing compared data: observation vs modelled Optionally, with density histogram.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int | float</code> <p>bins for the 2D histogram on the background. By default 20 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges</p> <code>120</code> <code>quantiles</code> <code>int | Sequence[float] | None</code> <p>number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)</p> <code>None</code> <code>fit_to_quantiles</code> <code>bool</code> <p>by default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution</p> <code>False</code> <code>show_points</code> <code>(bool, int, float)</code> <p>Should the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points. int: if 'n' (int) given, then 'n' points will be displayed, randomly selected</p> <code>None</code> <code>show_hist</code> <code>bool</code> <p>show the data density as a a 2d histogram, by default None</p> <code>None</code> <code>show_density</code> <code>Optional[bool]</code> <p>show the data density as a colormap of the scatter, by default None.  If both <code>show_density</code> and <code>show_hist</code> are None, then <code>show_density</code>  is used by default. For binning the data, the kword <code>bins=Float</code> is used.</p> <code>None</code> <code>norm</code> <code>matplotlib.colors norm</code> <p>colormap normalization If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)</p> <code>None</code> <code>backend</code> <code>str</code> <p>use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"</p> <code>'matplotlib'</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure, by default (8, 8)</p> <code>(8, 8)</code> <code>xlim</code> <code>tuple</code> <p>plot range for the observation (xmin, xmax), by default None</p> <code>None</code> <code>ylim</code> <code>tuple</code> <p>plot range for the model (ymin, ymax), by default None</p> <code>None</code> <code>reg_method</code> <code>str or bool</code> <p>method for determining the regression line \"ols\" : ordinary least squares regression \"odr\" : orthogonal distance regression, False : no regression line by default \"ols\"</p> <code>'ols'</code> <code>title</code> <code>str</code> <p>plot title, by default None</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>x-label text on plot, by default None</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>y-label text on plot, by default None</p> <code>None</code> <code>skill_table</code> <code>(str, List[str], bool)</code> <p>list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list. This kword adds a box at the right of the scatter plot, by default False</p> <code>None</code> <code>kwargs</code> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cmp.plot.scatter()\n&gt;&gt;&gt; cmp.plot.scatter(bins=0.2, backend='plotly')\n&gt;&gt;&gt; cmp.plot.scatter(show_points=False, title='no points')\n&gt;&gt;&gt; cmp.plot.scatter(xlabel='all observations', ylabel='my model')\n&gt;&gt;&gt; cmp.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n</code></pre> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def scatter(\n    self,\n    *,\n    model=None,\n    bins: int | float = 120,\n    quantiles: int | Sequence[float] | None = None,\n    fit_to_quantiles: bool = False,\n    show_points: bool | int | float | None = None,\n    show_hist: Optional[bool] = None,\n    show_density: Optional[bool] = None,\n    norm: Optional[colors.Normalize] = None,\n    backend: str = \"matplotlib\",\n    figsize: Tuple[float, float] = (8, 8),\n    xlim: Optional[Tuple[float, float]] = None,\n    ylim: Optional[Tuple[float, float]] = None,\n    reg_method: str | bool = \"ols\",\n    title: Optional[str] = None,\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n    skill_table: Optional[Union[str, List[str], bool]] = None,\n    **kwargs,\n):\n    \"\"\"Scatter plot showing compared data: observation vs modelled\n    Optionally, with density histogram.\n\n    Parameters\n    ----------\n    bins: (int, float, sequence), optional\n        bins for the 2D histogram on the background. By default 20 bins.\n        if int, represents the number of bins of 2D\n        if float, represents the bin size\n        if sequence (list of int or float), represents the bin edges\n    quantiles: (int, sequence), optional\n        number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n        if int, this is the number of points\n        if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n    fit_to_quantiles: bool, optional, by default False\n        by default the regression line is fitted to all data, if True, it is fitted to the quantiles\n        which can be useful to represent the extremes of the distribution\n    show_points : (bool, int, float), optional\n        Should the scatter points be displayed?\n        None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None.\n        float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points.\n        int: if 'n' (int) given, then 'n' points will be displayed, randomly selected\n    show_hist : bool, optional\n        show the data density as a a 2d histogram, by default None\n    show_density: bool, optional\n        show the data density as a colormap of the scatter, by default None. \n        If both `show_density` and `show_hist` are None, then `show_density` \n        is used by default. For binning the data, the kword `bins=Float` is used. \n    norm : matplotlib.colors norm\n        colormap normalization\n        If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)\n    backend : str, optional\n        use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"\n    figsize : tuple, optional\n        width and height of the figure, by default (8, 8)\n    xlim : tuple, optional\n        plot range for the observation (xmin, xmax), by default None\n    ylim : tuple, optional\n        plot range for the model (ymin, ymax), by default None\n    reg_method : str or bool, optional\n        method for determining the regression line\n        \"ols\" : ordinary least squares regression\n        \"odr\" : orthogonal distance regression,\n        False : no regression line\n        by default \"ols\"\n    title : str, optional\n        plot title, by default None\n    xlabel : str, optional\n        x-label text on plot, by default None\n    ylabel : str, optional\n        y-label text on plot, by default None\n    skill_table : str, List[str], bool, optional\n        list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list.\n        This kword adds a box at the right of the scatter plot,\n        by default False\n    kwargs\n\n    Examples\n    ------\n    &gt;&gt;&gt; cmp.plot.scatter()\n    &gt;&gt;&gt; cmp.plot.scatter(bins=0.2, backend='plotly')\n    &gt;&gt;&gt; cmp.plot.scatter(show_points=False, title='no points')\n    &gt;&gt;&gt; cmp.plot.scatter(xlabel='all observations', ylabel='my model')\n    &gt;&gt;&gt; cmp.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n    \"\"\"\n\n    cmp = self.comparer\n    if model is None:\n        mod_names = cmp.mod_names\n    else:\n        warnings.warn(\n            \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.scatter()\",\n            FutureWarning,\n        )\n        model_list = [model] if isinstance(model, (str, int)) else model\n        mod_names = [cmp.mod_names[_get_idx(m, cmp.mod_names)] for m in model_list]\n\n    axes = []\n    for mod_name in mod_names:\n        ax_mod = self._scatter_one_model(\n            mod_name=mod_name,\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            norm=norm,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            skill_table=skill_table,\n            **kwargs,\n        )\n        axes.append(ax_mod)\n    return axes[0] if len(axes) == 1 else axes\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.taylor","title":"<code>taylor(*, normalize_std=False, figsize=(7, 7), marker='o', marker_size=6.0, title='Taylor diagram')</code>","text":"<p>Taylor diagram showing model std and correlation to observation in a single-quadrant polar plot, with r=std and theta=arccos(cc).</p> <p>Parameters:</p> Name Type Description Default <code>normalize_std</code> <code>bool</code> <p>plot model std normalized with observation std, default False</p> <code>False</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure (should be square), by default (7, 7)</p> <code>(7, 7)</code> <code>marker</code> <code>str</code> <p>marker type e.g. \"x\", \"*\", by default \"o\"</p> <code>'o'</code> <code>marker_size</code> <code>float</code> <p>size of the marker, by default 6</p> <code>6.0</code> <code>title</code> <code>str</code> <p>title of the plot, by default \"Taylor diagram\"</p> <code>'Taylor diagram'</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; comparer.taylor()\n&gt;&gt;&gt; comparer.taylor(start=\"2017-10-28\", figsize=(5,5))\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.taylor--references","title":"References","text":"<p>Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin yannick.copin@laposte.net</p> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def taylor(\n    self,\n    *,\n    normalize_std: bool = False,\n    figsize: Tuple[float, float] = (7, 7),\n    marker: str = \"o\",\n    marker_size: float = 6.0,\n    title: str = \"Taylor diagram\",\n):\n    \"\"\"Taylor diagram showing model std and correlation to observation\n    in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n    Parameters\n    ----------\n    normalize_std : bool, optional\n        plot model std normalized with observation std, default False\n    figsize : tuple, optional\n        width and height of the figure (should be square), by default (7, 7)\n    marker : str, optional\n        marker type e.g. \"x\", \"*\", by default \"o\"\n    marker_size : float, optional\n        size of the marker, by default 6\n    title : str, optional\n        title of the plot, by default \"Taylor diagram\"\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n\n    Examples\n    ------\n    &gt;&gt;&gt; comparer.taylor()\n    &gt;&gt;&gt; comparer.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n    References\n    ----------\n    Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin &lt;yannick.copin@laposte.net&gt;\n    \"\"\"\n    cmp = self.comparer\n\n    # TODO consider if this round-trip  via mtr is necessary to get the std:s\n    metrics = [\n        mtr._std_obs,\n        mtr._std_mod,\n        mtr.cc,\n    ]\n\n    s = cmp.skill(metrics=metrics)\n\n    if s is None:  # TODO\n        return\n    df = s.to_dataframe()\n    ref_std = 1.0 if normalize_std else df.iloc[0][\"_std_obs\"]\n\n    df = df[[\"_std_obs\", \"_std_mod\", \"cc\"]].copy()\n    df.columns = [\"obs_std\", \"std\", \"cc\"]\n\n    pts = [\n        TaylorPoint(\n            r.Index, r.obs_std, r.std, r.cc, marker=marker, marker_size=marker_size\n        )\n        for r in df.itertuples()\n    ]\n\n    return taylor_diagram(\n        obs_std=ref_std,\n        points=pts,\n        figsize=figsize,\n        obs_text=f\"Obs: {cmp.name}\",\n        normalize_std=normalize_std,\n        title=title,\n    )\n</code></pre>"},{"location":"api/comparer/#modelskill.comparison._comparer_plotter.ComparerPlotter.timeseries","title":"<code>timeseries(*, title=None, ylim=None, ax=None, figsize=None, backend='matplotlib', **kwargs)</code>","text":"<p>Timeseries plot showing compared data: observation vs modelled</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>plot title, by default None</p> <code>None</code> <code>ylim</code> <code>(float, float)</code> <p>plot range for the model (ymin, ymax), by default None</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>figsize</code> <code>(float, float)</code> <p>figure size, by default None</p> <code>None</code> <code>backend</code> <code>str</code> <p>use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"backend:</p> <code>'matplotlib'</code> <p>Returns:</p> Type Description <code>Axes or Figure</code> Source code in <code>modelskill/comparison/_comparer_plotter.py</code> <pre><code>def timeseries(\n    self,\n    *,\n    title: str | None = None,\n    ylim: Tuple[float, float] | None = None,\n    ax=None,\n    figsize: Tuple[float, float] | None = None,\n    backend: str = \"matplotlib\",\n    **kwargs,\n):\n    \"\"\"Timeseries plot showing compared data: observation vs modelled\n\n    Parameters\n    ----------\n    title : str, optional\n        plot title, by default None\n    ylim : (float, float), optional\n        plot range for the model (ymin, ymax), by default None\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    figsize : (float, float), optional\n        figure size, by default None\n    backend : str, optional\n        use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"backend:\n\n    Returns\n    -------\n    matplotlib.axes.Axes or plotly.graph_objects.Figure\n    \"\"\"\n    from ._comparison import MOD_COLORS\n\n    cmp = self.comparer\n\n    if title is None:\n        title = cmp.name\n\n    if backend == \"matplotlib\":\n        fig, ax = _get_fig_ax(ax, figsize)\n        for j in range(cmp.n_models):\n            key = cmp.mod_names[j]\n            mod = cmp.raw_mod_data[key]._values_as_series\n            mod.plot(ax=ax, color=MOD_COLORS[j])\n\n        ax.scatter(\n            cmp.time,\n            cmp.data[cmp._obs_name].values,\n            marker=\".\",\n            color=cmp.data[cmp._obs_name].attrs[\"color\"],\n        )\n        ax.set_ylabel(cmp.unit_text)\n        ax.legend([*cmp.mod_names, cmp._obs_name])\n        ax.set_ylim(ylim)\n        if self.is_directional:\n            _ytick_directional(ax, ylim)\n        ax.set_title(title)\n        return ax\n\n    elif backend == \"plotly\":  # pragma: no cover\n        import plotly.graph_objects as go  # type: ignore\n\n        mod_scatter_list = []\n        for j in range(cmp.n_models):\n            key = cmp.mod_names[j]\n            mod = cmp.raw_mod_data[key]._values_as_series\n            mod_scatter_list.append(\n                go.Scatter(\n                    x=mod.index,\n                    y=mod.values,\n                    name=key,\n                    line=dict(color=MOD_COLORS[j]),\n                )\n            )\n\n        fig = go.Figure(\n            [\n                *mod_scatter_list,\n                go.Scatter(\n                    x=cmp.time,\n                    y=cmp.data[cmp._obs_name].values,\n                    name=cmp._obs_name,\n                    mode=\"markers\",\n                    marker=dict(color=cmp.data[cmp._obs_name].attrs[\"color\"]),\n                ),\n            ]\n        )\n\n        fig.update_layout(title=title, yaxis_title=cmp.unit_text, **kwargs)\n        fig.update_yaxes(range=ylim)\n\n        return fig\n    else:\n        raise ValueError(f\"Plotting backend: {backend} not supported\")\n</code></pre>"},{"location":"api/comparercollection/","title":"ComparerCollection","text":"<p>The <code>ComparerCollection</code> is one of the main objects of the <code>modelskill</code> package. It is collection of <code>Comparer</code> objects and is returned by the <code>match()</code> method of the <code>Model</code> class. </p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection","title":"<code>modelskill.ComparerCollection</code>","text":"<p>             Bases: <code>Mapping</code>, <code>Scoreable</code></p> <p>Collection of comparers, constructed by calling the <code>modelskill.match</code> method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; mr = ms.DfsuModelResult(\"Oresund2D.dfsu\", item=0)\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"drogden.dfs0\", item=0, x=355568.0, y=6156863.0)\n&gt;&gt;&gt; cc = ms.match(obs=[o1,o2], mod=mr)\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>class ComparerCollection(Mapping, Scoreable):\n    \"\"\"\n    Collection of comparers, constructed by calling the `modelskill.match` method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; mr = ms.DfsuModelResult(\"Oresund2D.dfsu\", item=0)\n    &gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n    &gt;&gt;&gt; o2 = ms.PointObservation(\"drogden.dfs0\", item=0, x=355568.0, y=6156863.0)\n    &gt;&gt;&gt; cc = ms.match(obs=[o1,o2], mod=mr)\n    \"\"\"\n\n    plotter = ComparerCollectionPlotter\n\n    \"\"\"Collection of Comparers, indexed by name\"\"\"\n\n    def __init__(self, comparers: Iterable[Comparer]) -&gt; None:\n        self.comparers: Dict[str, Comparer] = {}\n        self._insert_comparers(comparers)\n        self.plot = ComparerCollection.plotter(self)\n\n    def _insert_comparers(self, comparer: Union[Comparer, Iterable[Comparer]]) -&gt; None:\n        if isinstance(comparer, Iterable):\n            for c in comparer:\n                self[c.name] = c\n        elif isinstance(comparer, Comparer):\n            self[comparer.name] = comparer\n        else:\n            pass\n\n    @property\n    def name(self) -&gt; str:\n        return \"Observations\"\n\n    @property\n    def unit_text(self) -&gt; str:\n        # Picking the first one is arbitrary, but it should be the same for all\n        # we could check that they are all the same, but let's assume that they are\n        # for cmp in self:\n        #     if cmp.unit_text != text:\n        #         warnings.warn(f\"Unit text is inconsistent: {text} vs {cmp.unit_text}\")\n        return self[0].unit_text\n\n    @property\n    def n_comparers(self) -&gt; int:\n        \"\"\"Number of comparers\"\"\"\n        return len(self.comparers)\n\n    @property\n    def n_points(self) -&gt; int:\n        \"\"\"number of compared points\"\"\"\n        return sum([c.n_points for c in self.comparers.values()])\n\n    @property\n    def start(self) -&gt; pd.Timestamp:\n        warnings.warn(\n            \"start is deprecated, use start_time instead\",\n            FutureWarning,\n        )\n        return self.start_time\n\n    @property\n    def start_time(self) -&gt; pd.Timestamp:\n        \"\"\"start timestamp of compared data\"\"\"\n        starts = [pd.Timestamp.max]\n        for cmp in self.comparers.values():\n            starts.append(cmp.time[0])\n        return min(starts)\n\n    @property\n    def end(self) -&gt; pd.Timestamp:\n        warnings.warn(\n            \"end is deprecated, use end_time instead\",\n            FutureWarning,\n        )\n        return self.end_time\n\n    @property\n    def end_time(self) -&gt; pd.Timestamp:\n        \"\"\"end timestamp of compared data\"\"\"\n        ends = [pd.Timestamp.min]\n        for cmp in self.comparers.values():\n            ends.append(cmp.time[-1])\n        return max(ends)\n\n    @property\n    def obs_names(self) -&gt; List[str]:\n        \"\"\"List of observation names\"\"\"\n        return [c.name for c in self.comparers.values()]\n\n    @property\n    def n_observations(self) -&gt; int:\n        \"\"\"Number of observations\"\"\"\n        return self.n_comparers\n\n    @property\n    def mod_names(self) -&gt; List[str]:\n        \"\"\"List of unique model names\"\"\"\n        unique_names = []\n        for cmp in self.comparers.values():\n            for n in cmp.mod_names:\n                if n not in unique_names:\n                    unique_names.append(n)\n        return unique_names\n\n    @property\n    def n_models(self) -&gt; int:\n        return len(self.mod_names)\n\n    @property\n    def var_names(self) -&gt; List[str]:\n        \"\"\"List of unique variable names\"\"\"\n        unique_names = []\n        for cmp in self.comparers.values():\n            n = cmp.quantity.name\n            if n not in unique_names:\n                unique_names.append(n)\n        return unique_names\n\n    @property\n    def n_variables(self) -&gt; int:\n        return len(self.var_names)\n\n    @property\n    def metrics(self):\n        return options.metrics.list\n\n    @metrics.setter\n    def metrics(self, values) -&gt; None:\n        if values is None:\n            reset_option(\"metrics.list\")\n        else:\n            options.metrics.list = _parse_metric(values, self.metrics)\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Return a copy of the data as a pandas DataFrame\"\"\"\n        # TODO: var_name\n        # TODO delegate to each comparer\n        res = _all_df_template(self.n_variables)\n        frames = []\n        cols = res.keys()\n        for cmp in self.comparers.values():\n            for j in range(cmp.n_models):\n                mod_name = cmp.mod_names[j]\n                # drop \"x\", \"y\",  ?\n                df = cmp.data.drop_vars([\"z\"])[[mod_name]].to_dataframe().copy()\n                df = df.rename(columns={mod_name: \"mod_val\"})\n                df[\"model\"] = mod_name\n                df[\"observation\"] = cmp.name\n                if self.n_variables &gt; 1:\n                    df[\"variable\"] = cmp.quantity.name\n                df[\"x\"] = cmp.x\n                df[\"y\"] = cmp.y\n                df[\"obs_val\"] = cmp.data[\"Observation\"].values\n                frames.append(df[cols])\n        if len(frames) &gt; 0:\n            res = pd.concat(frames)\n        res = res.sort_index()\n        res.index.name = \"time\"\n        return res\n\n    def __repr__(self):\n        out = []\n        out.append(f\"&lt;{type(self).__name__}&gt;\")\n        for key, value in self.comparers.items():\n            out.append(f\"{type(value).__name__}: {key}\")\n        return str.join(\"\\n\", out)\n\n    @overload\n    def __getitem__(self, x: slice | Iterable[Hashable]) -&gt; ComparerCollection:\n        ...\n\n    @overload\n    def __getitem__(self, x: int | Hashable) -&gt; Comparer:\n        ...\n\n    def __getitem__(self, x):\n        if isinstance(x, str):\n            return self.comparers[x]\n\n        if isinstance(x, slice):\n            idxs = list(range(*x.indices(len(self))))\n            return ComparerCollection([self[i] for i in idxs])\n\n        if isinstance(x, int):\n            name = _get_name(x, self.obs_names)\n            return self.comparers[name]\n\n        if isinstance(x, Iterable):\n            cmps = [self[i] for i in x]\n            return ComparerCollection(cmps)\n\n    def __setitem__(self, x: str, value: Comparer) -&gt; None:\n        assert isinstance(\n            value, Comparer\n        ), f\"comparer must be a Comparer, not {type(value)}\"\n        if x in self.comparers:\n            # comparer with this name already exists!\n            # maybe the user is trying to add a new model\n            # or a new time period\n            self.comparers[x] = self.comparers[x] + value  # type: ignore\n        else:\n            self.comparers[x] = value\n\n    def __len__(self) -&gt; int:\n        return len(self.comparers)\n\n    def __iter__(self):\n        return iter(self.comparers.values())\n\n    def __copy__(self):\n        cls = self.__class__\n        cp = cls.__new__(cls)\n        cp.__init__(list(self.comparers))  # TODO should this use deepcopy?\n        return cp\n\n    def copy(self):\n        return self.__copy__()\n\n    def __add__(\n        self, other: Union[\"Comparer\", \"ComparerCollection\"]\n    ) -&gt; \"ComparerCollection\":\n        if not isinstance(other, (Comparer, ComparerCollection)):\n            raise TypeError(f\"Cannot add {type(other)} to {type(self)}\")\n\n        if isinstance(other, Comparer):\n            return ComparerCollection([*self, other])\n        elif isinstance(other, ComparerCollection):\n            return ComparerCollection([*self, *other])\n\n    def sel(\n        self,\n        model: Optional[IdOrNameTypes] = None,\n        observation: Optional[IdOrNameTypes] = None,\n        variable: Optional[IdOrNameTypes] = None,\n        start: Optional[TimeTypes] = None,\n        end: Optional[TimeTypes] = None,\n        time: Optional[TimeTypes] = None,\n        area: Optional[List[float]] = None,\n        **kwargs,\n    ) -&gt; \"ComparerCollection\":\n        \"\"\"Select data based on model, time and/or area.\n\n        Parameters\n        ----------\n        model : str or int or list of str or list of int, optional\n            Model name or index. If None, all models are selected.\n        observation : str or int or list of str or list of int, optional\n            Observation name or index. If None, all observations are selected.\n        variable : str or int or list of str or list of int, optional\n            Variable name or index. If None, all variables are selected.\n        start : str or datetime, optional\n            Start time. If None, all times are selected.\n        end : str or datetime, optional\n            End time. If None, all times are selected.\n        time : str or datetime, optional\n            Time. If None, all times are selected.\n        area : list of float, optional\n            bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\n        kwargs : dict, optional\n            Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs\n            e.g. `sel(gtype='track')` or `sel(obs_provider='CMEMS')` if at least\n            one comparer has an entry `obs_provider` with value `CMEMS` in its\n            attrs container. Multiple kwargs are combined with logical AND.\n\n        Returns\n        -------\n        ComparerCollection\n            New ComparerCollection with selected data.\n        \"\"\"\n        # TODO is this really necessary to do both in ComparerCollection and Comparer?\n        if model is not None:\n            if isinstance(model, (str, int)):\n                models = [model]\n            else:\n                models = list(model)\n            mod_names: List[str] = [_get_name(m, self.mod_names) for m in models]\n        if observation is None:\n            observation = self.obs_names\n        else:\n            observation = [observation] if np.isscalar(observation) else observation  # type: ignore\n            observation = [_get_name(o, self.obs_names) for o in observation]  # type: ignore\n\n        if (variable is not None) and (self.n_variables &gt; 1):\n            variable = [variable] if np.isscalar(variable) else variable  # type: ignore\n            variable = [_get_name(v, self.var_names) for v in variable]  # type: ignore\n        else:\n            variable = self.var_names\n\n        cmps = []\n        for cmp in self.comparers.values():\n            if cmp.name in observation and cmp.quantity.name in variable:\n                thismodel = (\n                    [m for m in mod_names if m in cmp.mod_names] if model else None\n                )\n                if (thismodel is not None) and (len(thismodel) == 0):\n                    continue\n                cmpsel = cmp.sel(\n                    model=thismodel,\n                    start=start,\n                    end=end,\n                    time=time,\n                    area=area,\n                )\n                if cmpsel is not None:\n                    # TODO: check if cmpsel is empty\n                    if cmpsel.n_points &gt; 0:\n                        cmps.append(cmpsel)\n        cc = ComparerCollection(cmps)\n\n        if kwargs:\n            cc = cc.filter_by_attrs(**kwargs)\n\n        return cc\n\n    def filter_by_attrs(self, **kwargs) -&gt; \"ComparerCollection\":\n        \"\"\"Filter by comparer attrs similar to xarray.Dataset.filter_by_attrs\n\n        Parameters\n        ----------\n        kwargs : dict, optional\n            Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs\n            e.g. `sel(gtype='track')` or `sel(obs_provider='CMEMS')` if at least\n            one comparer has an entry `obs_provider` with value `CMEMS` in its\n            attrs container. Multiple kwargs are combined with logical AND.\n\n        Returns\n        -------\n        ComparerCollection\n            New ComparerCollection with selected data.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cc = ms.match([HKNA, EPL, alti], mr)\n        &gt;&gt;&gt; cc.filter_by_attrs(gtype='track')\n        &lt;ComparerCollection&gt;\n        Comparer: alti\n        \"\"\"\n        cmps = []\n        for cmp in self.comparers.values():\n            for k, v in kwargs.items():\n                # TODO: should we also filter on cmp.data.Observation.attrs?\n                if cmp.data.attrs.get(k) != v:\n                    break\n            else:\n                cmps.append(cmp)\n        return ComparerCollection(cmps)\n\n    def query(self, query: str) -&gt; \"ComparerCollection\":\n        \"\"\"Select data based on a query.\n\n        Parameters\n        ----------\n        query : str\n            Query string. See pandas.DataFrame.query() for details.\n\n        Returns\n        -------\n        ComparerCollection\n            New ComparerCollection with selected data.\n        \"\"\"\n        q_cmps = [cmp.query(query) for cmp in self.comparers.values()]\n        cmps_with_data = [cmp for cmp in q_cmps if cmp.n_points &gt; 0]\n\n        return ComparerCollection(cmps_with_data)\n\n    def skill(\n        self,\n        by: Optional[Union[str, List[str]]] = None,\n        metrics: Optional[List[str]] = None,\n        **kwargs,\n    ) -&gt; SkillTable:\n        \"\"\"Aggregated skill assessment of model(s)\n\n        Parameters\n        ----------\n        by : (str, List[str]), optional\n            group by column name or by temporal bin via the freq-argument\n            (using pandas pd.Grouper(freq)),\n            e.g.: 'freq:M' = monthly; 'freq:D' daily\n            by default [\"model\",\"observation\"]\n        metrics : list, optional\n            list of modelskill.metrics, by default modelskill.options.metrics.list\n\n        Returns\n        -------\n        pd.DataFrame\n            skill assessment as a dataframe\n\n        See also\n        --------\n        sel\n            a method for filtering/selecting data\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)\n        &gt;&gt;&gt; cc.skill().round(2)\n                       n  bias  rmse  urmse   mae    cc    si    r2\n        observation\n        HKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\n        EPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\n        c2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n\n        &gt;&gt;&gt; cc.skill(observation='c2', start='2017-10-28').round(2)\n                       n  bias  rmse  urmse   mae    cc    si    r2\n        observation\n        c2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n\n        &gt;&gt;&gt; cc.skill(by='freq:D').round(2)\n                      n  bias  rmse  urmse   mae    cc    si    r2\n        2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n        2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n        2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n        \"\"\"\n        metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        cmp = self.sel(\n            model=model,\n            observation=observation,\n            variable=variable,\n            start=start,\n            end=end,\n            area=area,\n        )\n        if cmp.n_points == 0:\n            raise ValueError(\"Dataset is empty, no data to compare.\")\n\n        ## ---- end of deprecated code ----\n\n        df = cmp.to_dataframe()\n        n_models = cmp.n_models  # len(df.model.unique())\n        n_obs = cmp.n_observations  # len(df.observation.unique())\n\n        # TODO: FIX\n        n_var = (\n            cmp.n_variables\n        )  # len(df.variable.unique()) if (self.n_variables &gt; 1) else 1\n        by = _parse_groupby(by, n_models, n_obs, n_var)\n\n        res = _groupby_df(df, by, metrics)\n        res[\"x\"] = df.groupby(by=by, observed=False).x.first()\n        res[\"y\"] = df.groupby(by=by, observed=False).y.first()\n        # TODO: set x,y to NaN if TrackObservation\n        res = cmp._add_as_col_if_not_in_index(df, skilldf=res)\n        return SkillTable(res)\n\n    def _add_as_col_if_not_in_index(\n        self, df, skilldf, fields=[\"model\", \"observation\", \"variable\"]\n    ):\n        \"\"\"Add a field to skilldf if unique in df\"\"\"\n        for field in reversed(fields):\n            if (field == \"model\") and (self.n_models &lt;= 1):\n                continue\n            if (field == \"variable\") and (self.n_variables &lt;= 1):\n                continue\n            if field not in skilldf.index.names:\n                unames = df[field].unique()\n                if len(unames) == 1:\n                    skilldf.insert(loc=0, column=field, value=unames[0])\n        return skilldf\n\n    def spatial_skill(\n        self,\n        bins=5,\n        binsize=None,\n        by=None,\n        metrics=None,\n        n_min=None,\n        **kwargs,\n    ):\n        warnings.warn(\n            \"spatial_skill is deprecated, use gridded_skill instead\", FutureWarning\n        )\n        return self.gridded_skill(\n            bins=bins,\n            binsize=binsize,\n            by=by,\n            metrics=metrics,\n            n_min=n_min,\n            **kwargs,\n        )\n\n    def gridded_skill(\n        self,\n        bins=5,\n        binsize: Optional[float] = None,\n        by: Optional[Union[str, List[str]]] = None,\n        metrics: Optional[list] = None,\n        n_min: Optional[int] = None,\n        **kwargs,\n    ) -&gt; SkillGrid:\n        \"\"\"Skill assessment of model(s) on a regular spatial grid.\n\n        Parameters\n        ----------\n        bins: int, list of scalars, or IntervalIndex, or tuple of, optional\n            criteria to bin x and y by, argument bins to pd.cut(), default 5\n            define different bins for x and y a tuple\n            e.g.: bins = 5, bins = (5,[2,3,5])\n        binsize : float, optional\n            bin size for x and y dimension, overwrites bins\n            creates bins with reference to round(mean(x)), round(mean(y))\n        by : (str, List[str]), optional\n            group by column name or by temporal bin via the freq-argument\n            (using pandas pd.Grouper(freq)),\n            e.g.: 'freq:M' = monthly; 'freq:D' daily\n            by default [\"model\",\"observation\"]\n        metrics : list, optional\n            list of modelskill.metrics, by default modelskill.options.metrics.list\n        n_min : int, optional\n            minimum number of observations in a grid cell;\n            cells with fewer observations get a score of `np.nan`\n\n        Returns\n        -------\n        xr.Dataset\n            skill assessment as a dataset\n\n        See also\n        --------\n        skill\n            a method for aggregated skill assessment\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n        &gt;&gt;&gt; cc.gridded_skill(metrics='bias')\n        &lt;xarray.Dataset&gt;\n        Dimensions:      (x: 5, y: 5)\n        Coordinates:\n            observation   'alti'\n        * x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n        * y            (y) float64 50.6 51.66 52.7 53.75 54.8\n        Data variables:\n            n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n            bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n\n        &gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n        &gt;&gt;&gt; ds.coords\n        Coordinates:\n            observation   'alti'\n        * x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n        * y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n        \"\"\"\n\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n        cmp = self.sel(\n            model=model,\n            observation=observation,\n            variable=variable,\n            start=start,\n            end=end,\n            area=area,\n        )\n\n        if cmp.n_points == 0:\n            raise ValueError(\"Dataset is empty, no data to compare.\")\n\n        ## ---- end of deprecated code ----\n\n        df = cmp.to_dataframe()\n        df = _add_spatial_grid_to_df(df=df, bins=bins, binsize=binsize)\n\n        by = _parse_groupby(by, cmp.n_models, cmp.n_observations)\n        if isinstance(by, str) or (not isinstance(by, Iterable)):\n            by = [by]  # type: ignore\n        if \"x\" not in by:  # type: ignore\n            by.insert(0, \"x\")  # type: ignore\n        if \"y\" not in by:  # type: ignore\n            by.insert(0, \"y\")  # type: ignore\n\n        df = df.drop(columns=[\"x\", \"y\"]).rename(columns=dict(xBin=\"x\", yBin=\"y\"))\n        res = _groupby_df(df, by, metrics, n_min)\n        ds = res.to_xarray().squeeze()\n\n        # change categorial index to coordinates\n        for dim in (\"x\", \"y\"):\n            ds[dim] = ds[dim].astype(float)\n        return SkillGrid(ds)\n\n    def scatter(\n        self,\n        *,\n        bins=120,\n        quantiles=None,\n        fit_to_quantiles=False,\n        show_points=None,\n        show_hist=None,\n        show_density=None,\n        backend=\"matplotlib\",\n        figsize=(8, 8),\n        xlim=None,\n        ylim=None,\n        reg_method=\"ols\",\n        title=None,\n        xlabel=None,\n        ylabel=None,\n        skill_table=None,\n        **kwargs,\n    ):\n        warnings.warn(\"scatter is deprecated, use plot.scatter instead\", FutureWarning)\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n\n        # select model\n        mod_id = _get_idx(model, self.mod_names)\n        mod_name = self.mod_names[mod_id]\n\n        # select variable\n        var_id = _get_idx(variable, self.var_names)\n        var_name = self.var_names[var_id]\n\n        # filter data\n        cmp = self.sel(\n            model=mod_name,\n            observation=observation,\n            variable=var_name,\n            start=start,\n            end=end,\n            area=area,\n        )\n\n        return cmp.plot.scatter(\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            skill_table=skill_table,\n            **kwargs,\n        )\n\n    def mean_skill(\n        self,\n        *,\n        weights: Optional[Union[str, List[float], Dict[str, float]]] = None,\n        metrics: Optional[list] = None,\n        **kwargs,\n    ) -&gt; SkillTable:\n        \"\"\"Weighted mean of skills\n\n        First, the skill is calculated per observation,\n        the weighted mean of the skills is then found.\n\n        .. warning::\n            This method is NOT the mean skill of all observational points! (mean_skill_points)\n\n        Parameters\n        ----------\n        weights : (str, List(float), Dict(str, float)), optional\n            None: use observations weight attribute\n            \"equal\": giving all observations equal weight,\n            \"points\": giving all points equal weight,\n            list of weights e.g. [0.3, 0.3, 0.4] per observation,\n            dictionary of observations with special weigths, others will be set to 1.0\n            by default None (i.e. observations weight attribute if assigned else \"equal\")\n        metrics : list, optional\n            list of modelskill.metrics, by default modelskill.options.metrics.list\n\n        Returns\n        -------\n        SkillTable\n            mean skill assessment as a skill object\n\n        See also\n        --------\n        skill\n            skill assessment per observation\n        mean_skill_points\n            skill assessment pooling all observation points together\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n        &gt;&gt;&gt; cc.mean_skill().round(2)\n                      n  bias  rmse  urmse   mae    cc    si    r2\n        HKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n        &gt;&gt;&gt; s = cc.mean_skill(weights=\"equal\")\n        &gt;&gt;&gt; s = cc.mean_skill(weights=\"points\")\n        &gt;&gt;&gt; s = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n        \"\"\"\n\n        # TODO remove in v1.1\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        # filter data\n        cmp = self.sel(\n            model=model,  # deprecated\n            observation=observation,  # deprecated\n            variable=variable,  # deprecated\n            start=start,  # deprecated\n            end=end,  # deprecated\n            area=area,  # deprecated\n        )\n        if cmp.n_points == 0:\n            raise ValueError(\"Dataset is empty, no data to compare.\")\n\n        ## ---- end of deprecated code ----\n\n        df = cmp.to_dataframe()\n        mod_names = cmp.mod_names  # df.model.unique()\n        # obs_names = cmp.obs_names  # df.observation.unique()\n        var_names = cmp.var_names  # self.var_names\n\n        # skill assessment\n        metrics = _parse_metric(metrics, self.metrics, return_list=True)\n        # s = self.skill(df=df, metrics=metrics)\n        s = cmp.skill(metrics=metrics)\n        if s is None:\n            return None\n        skilldf = s.to_dataframe()\n\n        # weights\n        weights = cmp._parse_weights(weights, s.obs_names)\n        skilldf[\"weights\"] = (\n            skilldf.n if weights is None else np.tile(weights, len(mod_names))  # type: ignore\n        )\n\n        def weighted_mean(x):\n            return np.average(x, weights=skilldf.loc[x.index, \"weights\"])\n\n        # group by\n        by = cmp._mean_skill_by(skilldf, mod_names, var_names)\n        agg = {\"n\": \"sum\"}\n        for metric in metrics:  # type: ignore\n            agg[metric.__name__] = weighted_mean  # type: ignore\n        res = skilldf.groupby(by).agg(agg)\n\n        # TODO is this correct?\n        res.index.name = \"model\"\n\n        # output\n        res = cmp._add_as_col_if_not_in_index(df, res, fields=[\"model\", \"variable\"])\n        return SkillTable(res.astype({\"n\": int}))\n\n    # def mean_skill_points(\n    #     self,\n    #     *,\n    #     metrics: Optional[list] = None,\n    #     **kwargs,\n    # ) -&gt; Optional[SkillTable]:  # TODO raise error if no data?\n    #     \"\"\"Mean skill of all observational points\n\n    #     All data points are pooled (disregarding which observation they belong to),\n    #     the skill is then found (for each model).\n\n    #     .. note::\n    #         No weighting can be applied with this method,\n    #         use mean_skill() if you need to apply weighting\n\n    #     .. warning::\n    #         This method is NOT the mean of skills (mean_skill)\n\n    #     Parameters\n    #     ----------\n    #     metrics : list, optional\n    #         list of modelskill.metrics, by default modelskill.options.metrics.list\n\n    #     Returns\n    #     -------\n    #     SkillTable\n    #         mean skill assessment as a skill object\n\n    #     See also\n    #     --------\n    #     skill\n    #         skill assessment per observation\n    #     mean_skill\n    #         weighted mean of skills (not the same as this method)\n\n    #     Examples\n    #     --------\n    #     &gt;&gt;&gt; import modelskill as ms\n    #     &gt;&gt;&gt; cc = ms.match(obs, mod)\n    #     &gt;&gt;&gt; cc.mean_skill_points()\n    #     \"\"\"\n\n    #     # TODO remove in v1.1\n    #     model, start, end, area = _get_deprecated_args(kwargs)\n    #     observation, variable = _get_deprecated_obs_var_args(kwargs)\n    #     assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    #     # filter data\n    #     cmp = self.sel(\n    #         model=model,\n    #         observation=observation,\n    #         variable=variable,\n    #         start=start,\n    #         end=end,\n    #         area=area,\n    #     )\n    #     if cmp.n_points == 0:\n    #         warnings.warn(\"No data!\")\n    #         return None\n\n    #     dfall = cmp.to_dataframe()\n    #     dfall[\"observation\"] = \"all\"\n\n    #     # TODO: no longer possible to do this way\n    #     # return self.skill(df=dfall, metrics=metrics)\n    #     return cmp.skill(metrics=metrics)  # NOT CORRECT - SEE ABOVE\n\n    def _mean_skill_by(self, skilldf, mod_names, var_names):\n        by = []\n        if len(mod_names) &gt; 1:\n            by.append(\"model\")\n        if len(var_names) &gt; 1:\n            by.append(\"variable\")\n        if len(by) == 0:\n            if (self.n_variables &gt; 1) and (\"variable\" in skilldf):\n                by.append(\"variable\")\n            elif \"model\" in skilldf:\n                by.append(\"model\")\n            else:\n                by = [mod_names[0]] * len(skilldf)\n        return by\n\n    def _parse_weights(self, weights, observations):\n        if observations is None:\n            observations = self.obs_names\n        else:\n            observations = [observations] if np.isscalar(observations) else observations\n            observations = [_get_name(o, self.obs_names) for o in observations]\n        n_obs = len(observations)\n\n        if weights is None:\n            # get weights from observation objects\n            # default is equal weight to all\n            weights = [self.comparers[o].weight for o in observations]\n        else:\n            if isinstance(weights, int):\n                weights = np.ones(n_obs)  # equal weight to all\n            elif isinstance(weights, dict):\n                w_dict = weights\n                weights = [w_dict.get(name, 1.0) for name in (self.obs_names)]\n\n            elif isinstance(weights, str):\n                if weights.lower() == \"equal\":\n                    weights = np.ones(n_obs)  # equal weight to all\n                elif \"point\" in weights.lower():\n                    weights = None  # no weight =&gt; use n_points\n                else:\n                    raise ValueError(\n                        \"unknown weights argument (None, 'equal', 'points', or list of floats)\"\n                    )\n            elif not np.isscalar(weights):\n                if n_obs == 1:\n                    if len(weights) &gt; 1:\n                        warnings.warn(\n                            \"Cannot apply multiple weights to one observation\"\n                        )\n                    weights = [1.0]\n                if not len(weights) == n_obs:\n                    raise ValueError(\n                        f\"weights must have same length as observations: {observations}\"\n                    )\n        if weights is not None:\n            assert len(weights) == n_obs\n        return weights\n\n    def score(\n        self,\n        metric: str | Callable = mtr.rmse,\n        **kwargs,\n    ) -&gt; Dict[str, float]:\n        \"\"\"Weighted mean score of model(s) over all observations\n\n        Wrapping mean_skill() with a single metric.\n\n        NOTE: will take simple mean over different variables\n\n        Parameters\n        ----------\n        weights : (str, List(float), Dict(str, float)), optional\n            None: use observations weight attribute\n            \"equal\": giving all observations equal weight,\n            \"points\": giving all points equal weight,\n            list of weights e.g. [0.3, 0.3, 0.4] per observation,\n            dictionary of observations with special weigths, others will be set to 1.0\n            by default None (i.e. observations weight attribute if assigned else \"equal\")\n        metric : list, optional\n            a single metric from modelskill.metrics, by default rmse\n\n        Returns\n        -------\n        Dict[str, float]\n            mean of skills score as a single number (for each model)\n\n        See also\n        --------\n        skill\n            skill assessment per observation\n        mean_skill\n            weighted mean of skills assessment\n        mean_skill_points\n            skill assessment pooling all observation points together\n\n        Examples\n        --------\n        &gt;&gt;&gt; import modelskill as ms\n        &gt;&gt;&gt; cc = ms.match(obs, mod)\n        &gt;&gt;&gt; cc.score()\n        0.30681206\n        &gt;&gt;&gt; cc.score(weights=[0.1,0.1,0.8])\n        0.3383011631797379\n\n        &gt;&gt;&gt; cc.score(weights='points', metric=\"mape\")\n        8.414442957854142\n        \"\"\"\n\n        weights = kwargs.pop(\"weights\", None)\n        if weights is None:\n            weights = {c.name: c.weight for c in self.comparers.values()}\n\n        metric = _parse_metric(metric, self.metrics)\n        if not (callable(metric) or isinstance(metric, str)):\n            raise ValueError(\"metric must be a string or a function\")\n\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        if model is None:\n            models = self.mod_names\n        else:\n            # TODO: these two lines looks familiar, extract to function\n            models = [model] if np.isscalar(model) else model  # type: ignore\n            models = [_get_name(m, self.mod_names) for m in models]  # type: ignore\n\n        cmp = self.sel(\n            model=models,  # deprecated\n            observation=observation,  # deprecated\n            variable=variable,  # deprecated\n            start=start,  # deprecated\n            end=end,  # deprecated\n            area=area,  # deprecated\n        )\n\n        if cmp.n_points == 0:\n            raise ValueError(\"Dataset is empty, no data to compare.\")\n\n        ## ---- end of deprecated code ----\n\n        skill = cmp.mean_skill(weights=weights, metrics=[metric])\n        df = skill.to_dataframe()\n\n        metric_name = metric if isinstance(metric, str) else metric.__name__\n\n        score = df[metric_name].to_dict()\n\n        return score\n\n    def taylor(\n        self,\n        normalize_std=False,\n        aggregate_observations=True,\n        figsize=(7, 7),\n        marker=\"o\",\n        marker_size=6.0,\n        title=\"Taylor diagram\",\n        **kwargs,\n    ):\n        warnings.warn(\"taylor is deprecated, use plot.taylor instead\", FutureWarning)\n\n        model, start, end, area = _get_deprecated_args(kwargs)\n        observation, variable = _get_deprecated_obs_var_args(kwargs)\n        assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n        cmp = self.sel(\n            model=model,\n            observation=observation,\n            variable=variable,\n            start=start,\n            end=end,\n            area=area,\n        )\n\n        if cmp.n_points == 0:\n            warnings.warn(\"No data!\")\n            return\n\n        if (not aggregate_observations) and (not normalize_std):\n            raise ValueError(\n                \"aggregate_observations=False is only possible if normalize_std=True!\"\n            )\n\n        metrics = [mtr._std_obs, mtr._std_mod, mtr.cc]\n        skill_func = cmp.mean_skill if aggregate_observations else cmp.skill\n        s = skill_func(metrics=metrics)\n\n        df = s.to_dataframe()\n        ref_std = 1.0 if normalize_std else df.iloc[0][\"_std_obs\"]\n\n        if isinstance(df.index, pd.MultiIndex):\n            df.index = df.index.map(\"_\".join)\n\n        df = df[[\"_std_obs\", \"_std_mod\", \"cc\"]].copy()\n        df.columns = [\"obs_std\", \"std\", \"cc\"]\n        pts = [\n            TaylorPoint(\n                r.Index, r.obs_std, r.std, r.cc, marker=marker, marker_size=marker_size\n            )\n            for r in df.itertuples()\n        ]\n\n        taylor_diagram(\n            obs_std=ref_std,\n            points=pts,\n            figsize=figsize,\n            normalize_std=normalize_std,\n            title=title,\n        )\n\n    def save(self, filename: Union[str, Path]) -&gt; None:\n        \"\"\"Save the ComparerCollection to a zip file.\n\n        Parameters\n        ----------\n        filename : str or Path\n            Filename of the zip file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cc = ms.match(obs, mod)\n        &gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n\n        Notes\n        -----\n        Each comparer is stored as a netcdf file in the zip file.\n        \"\"\"\n\n        files = []\n        no = 0\n        for name, cmp in self.comparers.items():\n            cmp_fn = f\"{no}_{name}.nc\"\n            cmp.save(cmp_fn)\n            files.append(cmp_fn)\n            no += 1\n\n        with zipfile.ZipFile(filename, \"w\") as zip:\n            for f in files:\n                zip.write(f)\n                os.remove(f)\n\n    @staticmethod\n    def load(filename: Union[str, Path]) -&gt; \"ComparerCollection\":\n        \"\"\"Load a ComparerCollection from a zip file.\n\n        Parameters\n        ----------\n        filename : str or Path\n            Filename of the zip file.\n\n        Returns\n        -------\n        ComparerCollection\n            The loaded ComparerCollection.\n\n        Examples\n        --------\n        &gt;&gt;&gt; cc = ms.match(obs, mod)\n        &gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n        &gt;&gt;&gt; cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")\n        \"\"\"\n\n        folder = tempfile.TemporaryDirectory().name\n\n        with zipfile.ZipFile(filename, \"r\") as zip:\n            for f in zip.namelist():\n                if f.endswith(\".nc\"):\n                    zip.extract(f, path=folder)\n\n        comparers = [\n            ComparerCollection._load_comparer(folder, f)\n            for f in sorted(os.listdir(folder))\n        ]\n        return ComparerCollection(comparers)\n\n    @staticmethod\n    def _load_comparer(folder, f) -&gt; Comparer:\n        f = os.path.join(folder, f)\n        cmp = Comparer.load(f)\n        os.remove(f)\n        return cmp\n\n    def kde(self, ax=None, **kwargs):\n        warnings.warn(\"kde is deprecated, use plot.kde instead\", FutureWarning)\n\n        return self.plot.kde(ax=ax, **kwargs)\n\n    def hist(\n        self,\n        model=None,\n        bins=100,\n        title=None,\n        density=True,\n        alpha=0.5,\n        **kwargs,\n    ):\n        warnings.warn(\"hist is deprecated, use plot.hist instead\", FutureWarning)\n\n        return self.plot.hist(\n            model=model, bins=bins, title=title, density=density, alpha=alpha, **kwargs\n        )\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.end_time","title":"<code>end_time: pd.Timestamp</code>  <code>property</code>","text":"<p>end timestamp of compared data</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.mod_names","title":"<code>mod_names: List[str]</code>  <code>property</code>","text":"<p>List of unique model names</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.n_comparers","title":"<code>n_comparers: int</code>  <code>property</code>","text":"<p>Number of comparers</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.n_observations","title":"<code>n_observations: int</code>  <code>property</code>","text":"<p>Number of observations</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>number of compared points</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.obs_names","title":"<code>obs_names: List[str]</code>  <code>property</code>","text":"<p>List of observation names</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.plotter","title":"<code>plotter = ComparerCollectionPlotter</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Collection of Comparers, indexed by name</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.start_time","title":"<code>start_time: pd.Timestamp</code>  <code>property</code>","text":"<p>start timestamp of compared data</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.var_names","title":"<code>var_names: List[str]</code>  <code>property</code>","text":"<p>List of unique variable names</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.filter_by_attrs","title":"<code>filter_by_attrs(**kwargs)</code>","text":"<p>Filter by comparer attrs similar to xarray.Dataset.filter_by_attrs</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs e.g. <code>sel(gtype='track')</code> or <code>sel(obs_provider='CMEMS')</code> if at least one comparer has an entry <code>obs_provider</code> with value <code>CMEMS</code> in its attrs container. Multiple kwargs are combined with logical AND.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ComparerCollection</code> <p>New ComparerCollection with selected data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc = ms.match([HKNA, EPL, alti], mr)\n&gt;&gt;&gt; cc.filter_by_attrs(gtype='track')\n&lt;ComparerCollection&gt;\nComparer: alti\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def filter_by_attrs(self, **kwargs) -&gt; \"ComparerCollection\":\n    \"\"\"Filter by comparer attrs similar to xarray.Dataset.filter_by_attrs\n\n    Parameters\n    ----------\n    kwargs : dict, optional\n        Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs\n        e.g. `sel(gtype='track')` or `sel(obs_provider='CMEMS')` if at least\n        one comparer has an entry `obs_provider` with value `CMEMS` in its\n        attrs container. Multiple kwargs are combined with logical AND.\n\n    Returns\n    -------\n    ComparerCollection\n        New ComparerCollection with selected data.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cc = ms.match([HKNA, EPL, alti], mr)\n    &gt;&gt;&gt; cc.filter_by_attrs(gtype='track')\n    &lt;ComparerCollection&gt;\n    Comparer: alti\n    \"\"\"\n    cmps = []\n    for cmp in self.comparers.values():\n        for k, v in kwargs.items():\n            # TODO: should we also filter on cmp.data.Observation.attrs?\n            if cmp.data.attrs.get(k) != v:\n                break\n        else:\n            cmps.append(cmp)\n    return ComparerCollection(cmps)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.gridded_skill","title":"<code>gridded_skill(bins=5, binsize=None, by=None, metrics=None, n_min=None, **kwargs)</code>","text":"<p>Skill assessment of model(s) on a regular spatial grid.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <p>criteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])</p> <code>5</code> <code>binsize</code> <code>float</code> <p>bin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))</p> <code>None</code> <code>by</code> <code>(str, List[str])</code> <p>group by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: 'freq:M' = monthly; 'freq:D' daily by default [\"model\",\"observation\"]</p> <code>None</code> <code>metrics</code> <code>list</code> <p>list of modelskill.metrics, by default modelskill.options.metrics.list</p> <code>None</code> <code>n_min</code> <code>int</code> <p>minimum number of observations in a grid cell; cells with fewer observations get a score of <code>np.nan</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>skill assessment as a dataset</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.gridded_skill--see-also","title":"See also","text":"<p>skill     a method for aggregated skill assessment</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n&gt;&gt;&gt; cc.gridded_skill(metrics='bias')\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n</code></pre> <pre><code>&gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; ds.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def gridded_skill(\n    self,\n    bins=5,\n    binsize: Optional[float] = None,\n    by: Optional[Union[str, List[str]]] = None,\n    metrics: Optional[list] = None,\n    n_min: Optional[int] = None,\n    **kwargs,\n) -&gt; SkillGrid:\n    \"\"\"Skill assessment of model(s) on a regular spatial grid.\n\n    Parameters\n    ----------\n    bins: int, list of scalars, or IntervalIndex, or tuple of, optional\n        criteria to bin x and y by, argument bins to pd.cut(), default 5\n        define different bins for x and y a tuple\n        e.g.: bins = 5, bins = (5,[2,3,5])\n    binsize : float, optional\n        bin size for x and y dimension, overwrites bins\n        creates bins with reference to round(mean(x)), round(mean(y))\n    by : (str, List[str]), optional\n        group by column name or by temporal bin via the freq-argument\n        (using pandas pd.Grouper(freq)),\n        e.g.: 'freq:M' = monthly; 'freq:D' daily\n        by default [\"model\",\"observation\"]\n    metrics : list, optional\n        list of modelskill.metrics, by default modelskill.options.metrics.list\n    n_min : int, optional\n        minimum number of observations in a grid cell;\n        cells with fewer observations get a score of `np.nan`\n\n    Returns\n    -------\n    xr.Dataset\n        skill assessment as a dataset\n\n    See also\n    --------\n    skill\n        a method for aggregated skill assessment\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n    &gt;&gt;&gt; cc.gridded_skill(metrics='bias')\n    &lt;xarray.Dataset&gt;\n    Dimensions:      (x: 5, y: 5)\n    Coordinates:\n        observation   'alti'\n    * x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n    * y            (y) float64 50.6 51.66 52.7 53.75 54.8\n    Data variables:\n        n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n        bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n\n    &gt;&gt;&gt; ds = cc.gridded_skill(binsize=0.5)\n    &gt;&gt;&gt; ds.coords\n    Coordinates:\n        observation   'alti'\n    * x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n    * y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n    \"\"\"\n\n    model, start, end, area = _get_deprecated_args(kwargs)\n    observation, variable = _get_deprecated_obs_var_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n    cmp = self.sel(\n        model=model,\n        observation=observation,\n        variable=variable,\n        start=start,\n        end=end,\n        area=area,\n    )\n\n    if cmp.n_points == 0:\n        raise ValueError(\"Dataset is empty, no data to compare.\")\n\n    ## ---- end of deprecated code ----\n\n    df = cmp.to_dataframe()\n    df = _add_spatial_grid_to_df(df=df, bins=bins, binsize=binsize)\n\n    by = _parse_groupby(by, cmp.n_models, cmp.n_observations)\n    if isinstance(by, str) or (not isinstance(by, Iterable)):\n        by = [by]  # type: ignore\n    if \"x\" not in by:  # type: ignore\n        by.insert(0, \"x\")  # type: ignore\n    if \"y\" not in by:  # type: ignore\n        by.insert(0, \"y\")  # type: ignore\n\n    df = df.drop(columns=[\"x\", \"y\"]).rename(columns=dict(xBin=\"x\", yBin=\"y\"))\n    res = _groupby_df(df, by, metrics, n_min)\n    ds = res.to_xarray().squeeze()\n\n    # change categorial index to coordinates\n    for dim in (\"x\", \"y\"):\n        ds[dim] = ds[dim].astype(float)\n    return SkillGrid(ds)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.load","title":"<code>load(filename)</code>  <code>staticmethod</code>","text":"<p>Load a ComparerCollection from a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str or Path</code> <p>Filename of the zip file.</p> required <p>Returns:</p> Type Description <code>ComparerCollection</code> <p>The loaded ComparerCollection.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n&gt;&gt;&gt; cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>@staticmethod\ndef load(filename: Union[str, Path]) -&gt; \"ComparerCollection\":\n    \"\"\"Load a ComparerCollection from a zip file.\n\n    Parameters\n    ----------\n    filename : str or Path\n        Filename of the zip file.\n\n    Returns\n    -------\n    ComparerCollection\n        The loaded ComparerCollection.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cc = ms.match(obs, mod)\n    &gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n    &gt;&gt;&gt; cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")\n    \"\"\"\n\n    folder = tempfile.TemporaryDirectory().name\n\n    with zipfile.ZipFile(filename, \"r\") as zip:\n        for f in zip.namelist():\n            if f.endswith(\".nc\"):\n                zip.extract(f, path=folder)\n\n    comparers = [\n        ComparerCollection._load_comparer(folder, f)\n        for f in sorted(os.listdir(folder))\n    ]\n    return ComparerCollection(comparers)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.mean_skill","title":"<code>mean_skill(*, weights=None, metrics=None, **kwargs)</code>","text":"<p>Weighted mean of skills</p> <p>First, the skill is calculated per observation, the weighted mean of the skills is then found.</p> <p>.. warning::     This method is NOT the mean skill of all observational points! (mean_skill_points)</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>(str, List(float), Dict(str, float))</code> <p>None: use observations weight attribute \"equal\": giving all observations equal weight, \"points\": giving all points equal weight, list of weights e.g. [0.3, 0.3, 0.4] per observation, dictionary of observations with special weigths, others will be set to 1.0 by default None (i.e. observations weight attribute if assigned else \"equal\")</p> <code>None</code> <code>metrics</code> <code>list</code> <p>list of modelskill.metrics, by default modelskill.options.metrics.list</p> <code>None</code> <p>Returns:</p> Type Description <code>SkillTable</code> <p>mean skill assessment as a skill object</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.mean_skill--see-also","title":"See also","text":"<p>skill     skill assessment per observation mean_skill_points     skill assessment pooling all observation points together</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n&gt;&gt;&gt; cc.mean_skill().round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\nHKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n&gt;&gt;&gt; s = cc.mean_skill(weights=\"equal\")\n&gt;&gt;&gt; s = cc.mean_skill(weights=\"points\")\n&gt;&gt;&gt; s = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def mean_skill(\n    self,\n    *,\n    weights: Optional[Union[str, List[float], Dict[str, float]]] = None,\n    metrics: Optional[list] = None,\n    **kwargs,\n) -&gt; SkillTable:\n    \"\"\"Weighted mean of skills\n\n    First, the skill is calculated per observation,\n    the weighted mean of the skills is then found.\n\n    .. warning::\n        This method is NOT the mean skill of all observational points! (mean_skill_points)\n\n    Parameters\n    ----------\n    weights : (str, List(float), Dict(str, float)), optional\n        None: use observations weight attribute\n        \"equal\": giving all observations equal weight,\n        \"points\": giving all points equal weight,\n        list of weights e.g. [0.3, 0.3, 0.4] per observation,\n        dictionary of observations with special weigths, others will be set to 1.0\n        by default None (i.e. observations weight attribute if assigned else \"equal\")\n    metrics : list, optional\n        list of modelskill.metrics, by default modelskill.options.metrics.list\n\n    Returns\n    -------\n    SkillTable\n        mean skill assessment as a skill object\n\n    See also\n    --------\n    skill\n        skill assessment per observation\n    mean_skill_points\n        skill assessment pooling all observation points together\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n    &gt;&gt;&gt; cc.mean_skill().round(2)\n                  n  bias  rmse  urmse   mae    cc    si    r2\n    HKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n    &gt;&gt;&gt; s = cc.mean_skill(weights=\"equal\")\n    &gt;&gt;&gt; s = cc.mean_skill(weights=\"points\")\n    &gt;&gt;&gt; s = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n    \"\"\"\n\n    # TODO remove in v1.1\n    model, start, end, area = _get_deprecated_args(kwargs)\n    observation, variable = _get_deprecated_obs_var_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    # filter data\n    cmp = self.sel(\n        model=model,  # deprecated\n        observation=observation,  # deprecated\n        variable=variable,  # deprecated\n        start=start,  # deprecated\n        end=end,  # deprecated\n        area=area,  # deprecated\n    )\n    if cmp.n_points == 0:\n        raise ValueError(\"Dataset is empty, no data to compare.\")\n\n    ## ---- end of deprecated code ----\n\n    df = cmp.to_dataframe()\n    mod_names = cmp.mod_names  # df.model.unique()\n    # obs_names = cmp.obs_names  # df.observation.unique()\n    var_names = cmp.var_names  # self.var_names\n\n    # skill assessment\n    metrics = _parse_metric(metrics, self.metrics, return_list=True)\n    # s = self.skill(df=df, metrics=metrics)\n    s = cmp.skill(metrics=metrics)\n    if s is None:\n        return None\n    skilldf = s.to_dataframe()\n\n    # weights\n    weights = cmp._parse_weights(weights, s.obs_names)\n    skilldf[\"weights\"] = (\n        skilldf.n if weights is None else np.tile(weights, len(mod_names))  # type: ignore\n    )\n\n    def weighted_mean(x):\n        return np.average(x, weights=skilldf.loc[x.index, \"weights\"])\n\n    # group by\n    by = cmp._mean_skill_by(skilldf, mod_names, var_names)\n    agg = {\"n\": \"sum\"}\n    for metric in metrics:  # type: ignore\n        agg[metric.__name__] = weighted_mean  # type: ignore\n    res = skilldf.groupby(by).agg(agg)\n\n    # TODO is this correct?\n    res.index.name = \"model\"\n\n    # output\n    res = cmp._add_as_col_if_not_in_index(df, res, fields=[\"model\", \"variable\"])\n    return SkillTable(res.astype({\"n\": int}))\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.query","title":"<code>query(query)</code>","text":"<p>Select data based on a query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string. See pandas.DataFrame.query() for details.</p> required <p>Returns:</p> Type Description <code>ComparerCollection</code> <p>New ComparerCollection with selected data.</p> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def query(self, query: str) -&gt; \"ComparerCollection\":\n    \"\"\"Select data based on a query.\n\n    Parameters\n    ----------\n    query : str\n        Query string. See pandas.DataFrame.query() for details.\n\n    Returns\n    -------\n    ComparerCollection\n        New ComparerCollection with selected data.\n    \"\"\"\n    q_cmps = [cmp.query(query) for cmp in self.comparers.values()]\n    cmps_with_data = [cmp for cmp in q_cmps if cmp.n_points &gt; 0]\n\n    return ComparerCollection(cmps_with_data)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.save","title":"<code>save(filename)</code>","text":"<p>Save the ComparerCollection to a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str or Path</code> <p>Filename of the zip file.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.save--notes","title":"Notes","text":"<p>Each comparer is stored as a netcdf file in the zip file.</p> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def save(self, filename: Union[str, Path]) -&gt; None:\n    \"\"\"Save the ComparerCollection to a zip file.\n\n    Parameters\n    ----------\n    filename : str or Path\n        Filename of the zip file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cc = ms.match(obs, mod)\n    &gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n\n    Notes\n    -----\n    Each comparer is stored as a netcdf file in the zip file.\n    \"\"\"\n\n    files = []\n    no = 0\n    for name, cmp in self.comparers.items():\n        cmp_fn = f\"{no}_{name}.nc\"\n        cmp.save(cmp_fn)\n        files.append(cmp_fn)\n        no += 1\n\n    with zipfile.ZipFile(filename, \"w\") as zip:\n        for f in files:\n            zip.write(f)\n            os.remove(f)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.score","title":"<code>score(metric=mtr.rmse, **kwargs)</code>","text":"<p>Weighted mean score of model(s) over all observations</p> <p>Wrapping mean_skill() with a single metric.</p> <p>NOTE: will take simple mean over different variables</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>(str, List(float), Dict(str, float))</code> <p>None: use observations weight attribute \"equal\": giving all observations equal weight, \"points\": giving all points equal weight, list of weights e.g. [0.3, 0.3, 0.4] per observation, dictionary of observations with special weigths, others will be set to 1.0 by default None (i.e. observations weight attribute if assigned else \"equal\")</p> required <code>metric</code> <code>list</code> <p>a single metric from modelskill.metrics, by default rmse</p> <code>rmse</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>mean of skills score as a single number (for each model)</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.score--see-also","title":"See also","text":"<p>skill     skill assessment per observation mean_skill     weighted mean of skills assessment mean_skill_points     skill assessment pooling all observation points together</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.score()\n0.30681206\n&gt;&gt;&gt; cc.score(weights=[0.1,0.1,0.8])\n0.3383011631797379\n</code></pre> <pre><code>&gt;&gt;&gt; cc.score(weights='points', metric=\"mape\")\n8.414442957854142\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def score(\n    self,\n    metric: str | Callable = mtr.rmse,\n    **kwargs,\n) -&gt; Dict[str, float]:\n    \"\"\"Weighted mean score of model(s) over all observations\n\n    Wrapping mean_skill() with a single metric.\n\n    NOTE: will take simple mean over different variables\n\n    Parameters\n    ----------\n    weights : (str, List(float), Dict(str, float)), optional\n        None: use observations weight attribute\n        \"equal\": giving all observations equal weight,\n        \"points\": giving all points equal weight,\n        list of weights e.g. [0.3, 0.3, 0.4] per observation,\n        dictionary of observations with special weigths, others will be set to 1.0\n        by default None (i.e. observations weight attribute if assigned else \"equal\")\n    metric : list, optional\n        a single metric from modelskill.metrics, by default rmse\n\n    Returns\n    -------\n    Dict[str, float]\n        mean of skills score as a single number (for each model)\n\n    See also\n    --------\n    skill\n        skill assessment per observation\n    mean_skill\n        weighted mean of skills assessment\n    mean_skill_points\n        skill assessment pooling all observation points together\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cc = ms.match(obs, mod)\n    &gt;&gt;&gt; cc.score()\n    0.30681206\n    &gt;&gt;&gt; cc.score(weights=[0.1,0.1,0.8])\n    0.3383011631797379\n\n    &gt;&gt;&gt; cc.score(weights='points', metric=\"mape\")\n    8.414442957854142\n    \"\"\"\n\n    weights = kwargs.pop(\"weights\", None)\n    if weights is None:\n        weights = {c.name: c.weight for c in self.comparers.values()}\n\n    metric = _parse_metric(metric, self.metrics)\n    if not (callable(metric) or isinstance(metric, str)):\n        raise ValueError(\"metric must be a string or a function\")\n\n    model, start, end, area = _get_deprecated_args(kwargs)\n    observation, variable = _get_deprecated_obs_var_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    if model is None:\n        models = self.mod_names\n    else:\n        # TODO: these two lines looks familiar, extract to function\n        models = [model] if np.isscalar(model) else model  # type: ignore\n        models = [_get_name(m, self.mod_names) for m in models]  # type: ignore\n\n    cmp = self.sel(\n        model=models,  # deprecated\n        observation=observation,  # deprecated\n        variable=variable,  # deprecated\n        start=start,  # deprecated\n        end=end,  # deprecated\n        area=area,  # deprecated\n    )\n\n    if cmp.n_points == 0:\n        raise ValueError(\"Dataset is empty, no data to compare.\")\n\n    ## ---- end of deprecated code ----\n\n    skill = cmp.mean_skill(weights=weights, metrics=[metric])\n    df = skill.to_dataframe()\n\n    metric_name = metric if isinstance(metric, str) else metric.__name__\n\n    score = df[metric_name].to_dict()\n\n    return score\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.sel","title":"<code>sel(model=None, observation=None, variable=None, start=None, end=None, time=None, area=None, **kwargs)</code>","text":"<p>Select data based on model, time and/or area.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str or int or list of str or list of int</code> <p>Model name or index. If None, all models are selected.</p> <code>None</code> <code>observation</code> <code>str or int or list of str or list of int</code> <p>Observation name or index. If None, all observations are selected.</p> <code>None</code> <code>variable</code> <code>str or int or list of str or list of int</code> <p>Variable name or index. If None, all variables are selected.</p> <code>None</code> <code>start</code> <code>str or datetime</code> <p>Start time. If None, all times are selected.</p> <code>None</code> <code>end</code> <code>str or datetime</code> <p>End time. If None, all times are selected.</p> <code>None</code> <code>time</code> <code>str or datetime</code> <p>Time. If None, all times are selected.</p> <code>None</code> <code>area</code> <code>list of float</code> <p>bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs e.g. <code>sel(gtype='track')</code> or <code>sel(obs_provider='CMEMS')</code> if at least one comparer has an entry <code>obs_provider</code> with value <code>CMEMS</code> in its attrs container. Multiple kwargs are combined with logical AND.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ComparerCollection</code> <p>New ComparerCollection with selected data.</p> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def sel(\n    self,\n    model: Optional[IdOrNameTypes] = None,\n    observation: Optional[IdOrNameTypes] = None,\n    variable: Optional[IdOrNameTypes] = None,\n    start: Optional[TimeTypes] = None,\n    end: Optional[TimeTypes] = None,\n    time: Optional[TimeTypes] = None,\n    area: Optional[List[float]] = None,\n    **kwargs,\n) -&gt; \"ComparerCollection\":\n    \"\"\"Select data based on model, time and/or area.\n\n    Parameters\n    ----------\n    model : str or int or list of str or list of int, optional\n        Model name or index. If None, all models are selected.\n    observation : str or int or list of str or list of int, optional\n        Observation name or index. If None, all observations are selected.\n    variable : str or int or list of str or list of int, optional\n        Variable name or index. If None, all variables are selected.\n    start : str or datetime, optional\n        Start time. If None, all times are selected.\n    end : str or datetime, optional\n        End time. If None, all times are selected.\n    time : str or datetime, optional\n        Time. If None, all times are selected.\n    area : list of float, optional\n        bbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\n    kwargs : dict, optional\n        Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs\n        e.g. `sel(gtype='track')` or `sel(obs_provider='CMEMS')` if at least\n        one comparer has an entry `obs_provider` with value `CMEMS` in its\n        attrs container. Multiple kwargs are combined with logical AND.\n\n    Returns\n    -------\n    ComparerCollection\n        New ComparerCollection with selected data.\n    \"\"\"\n    # TODO is this really necessary to do both in ComparerCollection and Comparer?\n    if model is not None:\n        if isinstance(model, (str, int)):\n            models = [model]\n        else:\n            models = list(model)\n        mod_names: List[str] = [_get_name(m, self.mod_names) for m in models]\n    if observation is None:\n        observation = self.obs_names\n    else:\n        observation = [observation] if np.isscalar(observation) else observation  # type: ignore\n        observation = [_get_name(o, self.obs_names) for o in observation]  # type: ignore\n\n    if (variable is not None) and (self.n_variables &gt; 1):\n        variable = [variable] if np.isscalar(variable) else variable  # type: ignore\n        variable = [_get_name(v, self.var_names) for v in variable]  # type: ignore\n    else:\n        variable = self.var_names\n\n    cmps = []\n    for cmp in self.comparers.values():\n        if cmp.name in observation and cmp.quantity.name in variable:\n            thismodel = (\n                [m for m in mod_names if m in cmp.mod_names] if model else None\n            )\n            if (thismodel is not None) and (len(thismodel) == 0):\n                continue\n            cmpsel = cmp.sel(\n                model=thismodel,\n                start=start,\n                end=end,\n                time=time,\n                area=area,\n            )\n            if cmpsel is not None:\n                # TODO: check if cmpsel is empty\n                if cmpsel.n_points &gt; 0:\n                    cmps.append(cmpsel)\n    cc = ComparerCollection(cmps)\n\n    if kwargs:\n        cc = cc.filter_by_attrs(**kwargs)\n\n    return cc\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.skill","title":"<code>skill(by=None, metrics=None, **kwargs)</code>","text":"<p>Aggregated skill assessment of model(s)</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>(str, List[str])</code> <p>group by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: 'freq:M' = monthly; 'freq:D' daily by default [\"model\",\"observation\"]</p> <code>None</code> <code>metrics</code> <code>list</code> <p>list of modelskill.metrics, by default modelskill.options.metrics.list</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>skill assessment as a dataframe</p>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.skill--see-also","title":"See also","text":"<p>sel     a method for filtering/selecting data</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)\n&gt;&gt;&gt; cc.skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nHKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\nEPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n</code></pre> <pre><code>&gt;&gt;&gt; cc.skill(observation='c2', start='2017-10-28').round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n</code></pre> <pre><code>&gt;&gt;&gt; cc.skill(by='freq:D').round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n</code></pre> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def skill(\n    self,\n    by: Optional[Union[str, List[str]]] = None,\n    metrics: Optional[List[str]] = None,\n    **kwargs,\n) -&gt; SkillTable:\n    \"\"\"Aggregated skill assessment of model(s)\n\n    Parameters\n    ----------\n    by : (str, List[str]), optional\n        group by column name or by temporal bin via the freq-argument\n        (using pandas pd.Grouper(freq)),\n        e.g.: 'freq:M' = monthly; 'freq:D' daily\n        by default [\"model\",\"observation\"]\n    metrics : list, optional\n        list of modelskill.metrics, by default modelskill.options.metrics.list\n\n    Returns\n    -------\n    pd.DataFrame\n        skill assessment as a dataframe\n\n    See also\n    --------\n    sel\n        a method for filtering/selecting data\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)\n    &gt;&gt;&gt; cc.skill().round(2)\n                   n  bias  rmse  urmse   mae    cc    si    r2\n    observation\n    HKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\n    EPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\n    c2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n\n    &gt;&gt;&gt; cc.skill(observation='c2', start='2017-10-28').round(2)\n                   n  bias  rmse  urmse   mae    cc    si    r2\n    observation\n    c2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n\n    &gt;&gt;&gt; cc.skill(by='freq:D').round(2)\n                  n  bias  rmse  urmse   mae    cc    si    r2\n    2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n    2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n    2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n    \"\"\"\n    metrics = _parse_metric(metrics, self.metrics, return_list=True)\n\n    # TODO remove in v1.1\n    model, start, end, area = _get_deprecated_args(kwargs)\n    observation, variable = _get_deprecated_obs_var_args(kwargs)\n    assert kwargs == {}, f\"Unknown keyword arguments: {kwargs}\"\n\n    cmp = self.sel(\n        model=model,\n        observation=observation,\n        variable=variable,\n        start=start,\n        end=end,\n        area=area,\n    )\n    if cmp.n_points == 0:\n        raise ValueError(\"Dataset is empty, no data to compare.\")\n\n    ## ---- end of deprecated code ----\n\n    df = cmp.to_dataframe()\n    n_models = cmp.n_models  # len(df.model.unique())\n    n_obs = cmp.n_observations  # len(df.observation.unique())\n\n    # TODO: FIX\n    n_var = (\n        cmp.n_variables\n    )  # len(df.variable.unique()) if (self.n_variables &gt; 1) else 1\n    by = _parse_groupby(by, n_models, n_obs, n_var)\n\n    res = _groupby_df(df, by, metrics)\n    res[\"x\"] = df.groupby(by=by, observed=False).x.first()\n    res[\"y\"] = df.groupby(by=by, observed=False).y.first()\n    # TODO: set x,y to NaN if TrackObservation\n    res = cmp._add_as_col_if_not_in_index(df, skilldf=res)\n    return SkillTable(res)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.ComparerCollection.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Return a copy of the data as a pandas DataFrame</p> Source code in <code>modelskill/comparison/_collection.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Return a copy of the data as a pandas DataFrame\"\"\"\n    # TODO: var_name\n    # TODO delegate to each comparer\n    res = _all_df_template(self.n_variables)\n    frames = []\n    cols = res.keys()\n    for cmp in self.comparers.values():\n        for j in range(cmp.n_models):\n            mod_name = cmp.mod_names[j]\n            # drop \"x\", \"y\",  ?\n            df = cmp.data.drop_vars([\"z\"])[[mod_name]].to_dataframe().copy()\n            df = df.rename(columns={mod_name: \"mod_val\"})\n            df[\"model\"] = mod_name\n            df[\"observation\"] = cmp.name\n            if self.n_variables &gt; 1:\n                df[\"variable\"] = cmp.quantity.name\n            df[\"x\"] = cmp.x\n            df[\"y\"] = cmp.y\n            df[\"obs_val\"] = cmp.data[\"Observation\"].values\n            frames.append(df[cols])\n    if len(frames) &gt; 0:\n        res = pd.concat(frames)\n    res = res.sort_index()\n    res.index.name = \"time\"\n    return res\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter","title":"<code>modelskill.comparison._collection_plotter.ComparerCollectionPlotter</code>","text":"Source code in <code>modelskill/comparison/_collection_plotter.py</code> <pre><code>class ComparerCollectionPlotter:\n    def __init__(self, cc: ComparerCollection) -&gt; None:\n        self.cc = cc\n        self.is_directional = False\n\n    def __call__(self, *args: Any, **kwds: Any) -&gt; Any:\n        return self.scatter(*args, **kwds)\n\n    def scatter(\n        self,\n        *,\n        model=None,\n        bins: int | float = 120,\n        quantiles: int | Sequence[float] | None = None,\n        fit_to_quantiles: bool = False,\n        show_points: bool | int | float | None = None,\n        show_hist: Optional[bool] = None,\n        show_density: Optional[bool] = None,\n        backend: str = \"matplotlib\",\n        figsize: Tuple[float, float] = (8, 8),\n        xlim: Optional[Tuple[float, float]] = None,\n        ylim: Optional[Tuple[float, float]] = None,\n        reg_method: str | bool = \"ols\",\n        title: Optional[str] = None,\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        skill_table: Optional[Union[str, List[str], bool]] = None,\n        ax=None,\n        **kwargs,\n    ):\n        \"\"\"Scatter plot showing compared data: observation vs modelled\n        Optionally, with density histogram.\n\n        Parameters\n        ----------\n        bins: (int, float, sequence), optional\n            bins for the 2D histogram on the background. By default 20 bins.\n            if int, represents the number of bins of 2D\n            if float, represents the bin size\n            if sequence (list of int or float), represents the bin edges\n        quantiles: (int, sequence), optional\n            number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n            if int, this is the number of points\n            if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n        fit_to_quantiles: bool, optional, by default False\n            by default the regression line is fitted to all data, if True, it is fitted to the quantiles\n            which can be useful to represent the extremes of the distribution\n        show_points : (bool, int, float), optional\n            Should the scatter points be displayed?\n            None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None.\n            float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points.\n            int: if 'n' (int) given, then 'n' points will be displayed, randomly selected\n        show_hist : bool, optional\n            show the data density as a a 2d histogram, by default None\n        show_density: bool, optional\n            show the data density as a colormap of the scatter, by default None.\n            If both `show_density` and `show_hist` are None, then `show_density`\n            is used by default.\n            for binning the data, the kword `bins=Float` is used\n        backend : str, optional\n            use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"\n        figsize : tuple, optional\n            width and height of the figure, by default (8, 8)\n        xlim : tuple, optional\n            plot range for the observation (xmin, xmax), by default None\n        ylim : tuple, optional\n            plot range for the model (ymin, ymax), by default None\n        reg_method : str or bool, optional\n            method for determining the regression line\n            \"ols\" : ordinary least squares regression\n            \"odr\" : orthogonal distance regression,\n            False : no regression line,\n            by default \"ols\"\n        title : str, optional\n            plot title, by default None\n        xlabel : str, optional\n            x-label text on plot, by default None\n        ylabel : str, optional\n            y-label text on plot, by default None\n        skill_table : str, List[str], bool, optional\n            list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list.\n            This kword adds a box at the right of the scatter plot,\n            by default False\n        ax : matplotlib axes, optional\n            axes to plot on, by default None\n        **kwargs :\n            other keyword arguments to matplotlib.pyplot.scatter()\n\n        Examples\n        ------\n        &gt;&gt;&gt; cc.plot.scatter()\n        &gt;&gt;&gt; cc.plot.scatter(bins=0.2, backend='plotly')\n        &gt;&gt;&gt; cc.plot.scatter(show_points=False, title='no points')\n        &gt;&gt;&gt; cc.plot.scatter(xlabel='all observations', ylabel='my model')\n        &gt;&gt;&gt; cc.plot.scatter(model='HKZN_v2', figsize=(10, 10))\n        &gt;&gt;&gt; cc.plot.scatter(observations=['c2','HKNA'])\n        \"\"\"\n\n        cc = self.cc\n        if model is None:\n            mod_names = cc.mod_names\n        else:\n            warnings.warn(\n                \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.scatter()\",\n                FutureWarning,\n            )\n\n            model_list = [model] if isinstance(model, (str, int)) else model\n            mod_names = [\n                self.cc.mod_names[_get_idx(m, self.cc.mod_names)] for m in model_list\n            ]\n\n        axes = []\n        for mod_name in mod_names:\n            ax_mod = self._scatter_one_model(\n                mod_name=mod_name,\n                bins=bins,\n                quantiles=quantiles,\n                fit_to_quantiles=fit_to_quantiles,\n                show_points=show_points,\n                show_hist=show_hist,\n                show_density=show_density,\n                backend=backend,\n                figsize=figsize,\n                xlim=xlim,\n                ylim=ylim,\n                reg_method=reg_method,\n                title=title,\n                xlabel=xlabel,\n                ylabel=ylabel,\n                skill_table=skill_table,\n                ax=ax,\n                **kwargs,\n            )\n            axes.append(ax_mod)\n        return axes[0] if len(axes) == 1 else axes\n\n    def _scatter_one_model(\n        self,\n        *,\n        mod_name: str,\n        bins: int | float,\n        quantiles: int | Sequence[float] | None,\n        fit_to_quantiles: bool,\n        show_points: bool | int | float | None,\n        show_hist: Optional[bool],\n        show_density: Optional[bool],\n        backend: str,\n        figsize: Tuple[float, float],\n        xlim: Optional[Tuple[float, float]],\n        ylim: Optional[Tuple[float, float]],\n        reg_method: str | bool,\n        title: Optional[str],\n        xlabel: Optional[str],\n        ylabel: Optional[str],\n        skill_table: Optional[Union[str, List[str], bool]],\n        ax,\n        **kwargs,\n    ):\n        assert (\n            mod_name in self.cc.mod_names\n        ), f\"Model {mod_name} not found in collection {self.cc.mod_names}\"\n\n        cmp = self.cc.sel(model=mod_name)\n\n        if cmp.n_points == 0:\n            raise ValueError(\"No data found in selection\")\n\n        df = cmp.to_dataframe()\n        x = df.obs_val.values\n        y = df.mod_val.values\n\n        # TODO why the first?\n        unit_text = self.cc[0].unit_text\n\n        xlabel = xlabel or f\"Observation, {unit_text}\"\n        ylabel = ylabel or f\"Model, {unit_text}\"\n        title = title or f\"{mod_name} vs {cmp.name}\"\n\n        skill = None\n        units = None\n        if skill_table:\n            metrics = None if skill_table is True else skill_table\n\n            # TODO why is this here?\n            if isinstance(self, ComparerCollectionPlotter) and cmp.n_observations == 1:\n                skill = cmp.skill(metrics=metrics)  # type: ignore\n            else:\n                skill = cmp.mean_skill(metrics=metrics)  # type: ignore\n            # TODO improve this\n            try:\n                units = unit_text.split(\"[\")[1].split(\"]\")[0]\n            except IndexError:\n                units = \"\"  # Dimensionless\n\n        if self.is_directional:\n            # hide quantiles and regression line\n            quantiles = 0\n            reg_method = False\n\n        ax = scatter(\n            x=x,\n            y=y,\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            skill_df=skill,\n            units=units,\n            ax=ax,\n            **kwargs,\n        )\n\n        if backend == \"matplotlib\" and self.is_directional:\n            _xtick_directional(ax, xlim)\n            _ytick_directional(ax, ylim)\n\n        return ax\n\n    def kde(self, *, ax=None, figsize=None, title=None, **kwargs) -&gt; Axes:\n        \"\"\"Plot kernel density estimate of observation and model data.\n\n        Parameters\n        ----------\n        ax : Axes, optional\n            matplotlib axes, by default None\n        figsize : tuple, optional\n            width and height of the figure, by default None\n        title : str, optional\n            plot title, by default None\n        **kwargs\n            passed to pandas.DataFrame.plot.kde()\n\n        Returns\n        -------\n        Axes\n            matplotlib axes\n\n        Examples\n        --------\n        &gt;&gt;&gt; cc.plot.kde()\n        &gt;&gt;&gt; cc.plot.kde(bw_method=0.5)\n        &gt;&gt;&gt; cc.plot.kde(bw_method='silverman')\n\n        \"\"\"\n        _, ax = _get_fig_ax(ax, figsize)\n\n        df = self.cc.to_dataframe()\n        ax = df.obs_val.plot.kde(\n            ax=ax, linestyle=\"dashed\", label=\"Observation\", **kwargs\n        )\n\n        for model in self.cc.mod_names:\n            df_model = df[df.model == model]\n            df_model.mod_val.plot.kde(ax=ax, label=model, **kwargs)\n\n        ax.set_xlabel(f\"{self.cc.unit_text}\")\n\n        title = (\n            _default_univarate_title(\"Density plot\", self.cc)\n            if title is None\n            else title\n        )\n        ax.set_title(title)\n        ax.legend()\n\n        # remove y-axis, ticks and label\n        ax.yaxis.set_visible(False)\n        ax.tick_params(axis=\"y\", which=\"both\", length=0)\n        ax.set_ylabel(\"\")\n\n        # remove box around plot\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n\n        if self.is_directional:\n            _xtick_directional(ax)\n\n        return ax\n\n    def hist(\n        self,\n        bins: int | Sequence = 100,\n        *,\n        model: str | int | None = None,\n        title: Optional[str] = None,\n        density: bool = True,\n        alpha: float = 0.5,\n        ax=None,\n        figsize: Optional[Tuple[float, float]] = None,\n        **kwargs,\n    ):\n        \"\"\"Plot histogram of specific model and all observations.\n\n        Wraps pandas.DataFrame hist() method.\n\n        Parameters\n        ----------\n        bins : int, optional\n            number of bins, by default 100\n        title : str, optional\n            plot title, default: observation name\n        density: bool, optional\n            If True, draw and return a probability density, by default True\n        alpha : float, optional\n            alpha transparency fraction, by default 0.5\n        ax : matplotlib axes, optional\n            axes to plot on, by default None\n        figsize : tuple, optional\n            width and height of the figure, by default None\n        kwargs : other keyword arguments to df.hist()\n\n        Returns\n        -------\n        matplotlib axes\n\n        Examples\n        --------\n        &gt;&gt;&gt; cc.plot.hist()\n        &gt;&gt;&gt; cc.plot.hist(bins=100)\n\n        See also\n        --------\n        pandas.Series.hist\n        matplotlib.axes.Axes.hist\n        \"\"\"\n        if model is None:\n            mod_names = self.cc.mod_names\n        else:\n            warnings.warn(\n                \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.hist()\",\n                FutureWarning,\n            )\n            model_list = [model] if isinstance(model, (str, int)) else model\n            mod_names = [\n                self.cc.mod_names[_get_idx(m, self.cc.mod_names)] for m in model_list\n            ]\n\n        axes = []\n        for mod_name in mod_names:\n            ax_mod = self._hist_one_model(\n                mod_name=mod_name,\n                bins=bins,\n                title=title,\n                density=density,\n                alpha=alpha,\n                ax=ax,\n                figsize=figsize,\n                **kwargs,\n            )\n            axes.append(ax_mod)\n        return axes[0] if len(axes) == 1 else axes\n\n    def _hist_one_model(\n        self,\n        *,\n        mod_name: str,\n        bins: int | Sequence,\n        title: Optional[str],\n        density: bool,\n        alpha: float,\n        ax,\n        figsize: Optional[Tuple[float, float]],\n        **kwargs,\n    ):\n        from ._comparison import MOD_COLORS\n\n        _, ax = _get_fig_ax(ax, figsize)\n\n        assert (\n            mod_name in self.cc.mod_names\n        ), f\"Model {mod_name} not found in collection\"\n        mod_id = _get_idx(mod_name, self.cc.mod_names)\n\n        title = (\n            _default_univarate_title(\"Histogram\", self.cc) if title is None else title\n        )\n\n        cmp = self.cc\n        df = cmp.to_dataframe()\n        kwargs[\"alpha\"] = alpha\n        kwargs[\"density\"] = density\n        df.mod_val.hist(bins=bins, color=MOD_COLORS[mod_id], ax=ax, **kwargs)\n        df.obs_val.hist(\n            bins=bins,\n            color=self.cc[0].data[\"Observation\"].attrs[\"color\"],\n            ax=ax,\n            **kwargs,\n        )\n\n        ax.legend([mod_name, \"observations\"])\n        ax.set_title(title)\n        ax.set_xlabel(f\"{self.cc[df.observation.iloc[0]].unit_text}\")\n\n        if density:\n            ax.set_ylabel(\"density\")\n        else:\n            ax.set_ylabel(\"count\")\n\n        if self.is_directional:\n            _xtick_directional(ax)\n\n        return ax\n\n    def taylor(\n        self,\n        *,\n        normalize_std: bool = False,\n        aggregate_observations: bool = True,\n        figsize: Tuple[float, float] = (7, 7),\n        marker: str = \"o\",\n        marker_size: float = 6.0,\n        title: str = \"Taylor diagram\",\n    ):\n        \"\"\"Taylor diagram showing model std and correlation to observation\n        in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n        Parameters\n        ----------\n        normalize_std : bool, optional\n            plot model std normalized with observation std, default False\n        aggregate_observations : bool, optional\n            should multiple observations be aggregated before plotting\n            (or shown individually), default True\n        figsize : tuple, optional\n            width and height of the figure (should be square), by default (7, 7)\n        marker : str, optional\n            marker type e.g. \"x\", \"*\", by default \"o\"\n        marker_size : float, optional\n            size of the marker, by default 6\n        title : str, optional\n            title of the plot, by default \"Taylor diagram\"\n\n        Returns\n        -------\n        matplotlib.figure.Figure\n\n        Examples\n        ------\n        &gt;&gt;&gt; cc.plot.taylor()\n        &gt;&gt;&gt; cc.plot.taylor(observation=\"c2\")\n        &gt;&gt;&gt; cc.plot.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n        References\n        ----------\n        Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin &lt;yannick.copin@laposte.net&gt;\n        \"\"\"\n\n        if (not aggregate_observations) and (not normalize_std):\n            raise ValueError(\n                \"aggregate_observations=False is only possible if normalize_std=True!\"\n            )\n\n        metrics = [mtr._std_obs, mtr._std_mod, mtr.cc]\n        skill_func = self.cc.mean_skill if aggregate_observations else self.cc.skill\n        s = skill_func(\n            metrics=metrics,  # type: ignore\n        )\n        if s is None:\n            return\n\n        df = s.to_dataframe()\n        ref_std = 1.0 if normalize_std else df.iloc[0][\"_std_obs\"]\n\n        if isinstance(df.index, pd.MultiIndex):\n            df.index = df.index.map(\"_\".join)\n\n        df = df[[\"_std_obs\", \"_std_mod\", \"cc\"]].copy()\n        df.columns = [\"obs_std\", \"std\", \"cc\"]\n        pts = [\n            TaylorPoint(\n                r.Index, r.obs_std, r.std, r.cc, marker=marker, marker_size=marker_size\n            )\n            for r in df.itertuples()\n        ]\n\n        return taylor_diagram(\n            obs_std=ref_std,\n            points=pts,\n            figsize=figsize,\n            normalize_std=normalize_std,\n            title=title,\n        )\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.hist","title":"<code>hist(bins=100, *, model=None, title=None, density=True, alpha=0.5, ax=None, figsize=None, **kwargs)</code>","text":"<p>Plot histogram of specific model and all observations.</p> <p>Wraps pandas.DataFrame hist() method.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int</code> <p>number of bins, by default 100</p> <code>100</code> <code>title</code> <code>str</code> <p>plot title, default: observation name</p> <code>None</code> <code>density</code> <code>bool</code> <p>If True, draw and return a probability density, by default True</p> <code>True</code> <code>alpha</code> <code>float</code> <p>alpha transparency fraction, by default 0.5</p> <code>0.5</code> <code>ax</code> <code>matplotlib axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure, by default None</p> <code>None</code> <code>kwargs</code> <code>other keyword arguments to df.hist()</code> <code>{}</code> <p>Returns:</p> Type Description <code>matplotlib axes</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc.plot.hist()\n&gt;&gt;&gt; cc.plot.hist(bins=100)\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.hist--see-also","title":"See also","text":"<p>pandas.Series.hist matplotlib.axes.Axes.hist</p> Source code in <code>modelskill/comparison/_collection_plotter.py</code> <pre><code>def hist(\n    self,\n    bins: int | Sequence = 100,\n    *,\n    model: str | int | None = None,\n    title: Optional[str] = None,\n    density: bool = True,\n    alpha: float = 0.5,\n    ax=None,\n    figsize: Optional[Tuple[float, float]] = None,\n    **kwargs,\n):\n    \"\"\"Plot histogram of specific model and all observations.\n\n    Wraps pandas.DataFrame hist() method.\n\n    Parameters\n    ----------\n    bins : int, optional\n        number of bins, by default 100\n    title : str, optional\n        plot title, default: observation name\n    density: bool, optional\n        If True, draw and return a probability density, by default True\n    alpha : float, optional\n        alpha transparency fraction, by default 0.5\n    ax : matplotlib axes, optional\n        axes to plot on, by default None\n    figsize : tuple, optional\n        width and height of the figure, by default None\n    kwargs : other keyword arguments to df.hist()\n\n    Returns\n    -------\n    matplotlib axes\n\n    Examples\n    --------\n    &gt;&gt;&gt; cc.plot.hist()\n    &gt;&gt;&gt; cc.plot.hist(bins=100)\n\n    See also\n    --------\n    pandas.Series.hist\n    matplotlib.axes.Axes.hist\n    \"\"\"\n    if model is None:\n        mod_names = self.cc.mod_names\n    else:\n        warnings.warn(\n            \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.hist()\",\n            FutureWarning,\n        )\n        model_list = [model] if isinstance(model, (str, int)) else model\n        mod_names = [\n            self.cc.mod_names[_get_idx(m, self.cc.mod_names)] for m in model_list\n        ]\n\n    axes = []\n    for mod_name in mod_names:\n        ax_mod = self._hist_one_model(\n            mod_name=mod_name,\n            bins=bins,\n            title=title,\n            density=density,\n            alpha=alpha,\n            ax=ax,\n            figsize=figsize,\n            **kwargs,\n        )\n        axes.append(ax_mod)\n    return axes[0] if len(axes) == 1 else axes\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.kde","title":"<code>kde(*, ax=None, figsize=None, title=None, **kwargs)</code>","text":"<p>Plot kernel density estimate of observation and model data.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>matplotlib axes, by default None</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure, by default None</p> <code>None</code> <code>title</code> <code>str</code> <p>plot title, by default None</p> <code>None</code> <code>**kwargs</code> <p>passed to pandas.DataFrame.plot.kde()</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>matplotlib axes</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc.plot.kde()\n&gt;&gt;&gt; cc.plot.kde(bw_method=0.5)\n&gt;&gt;&gt; cc.plot.kde(bw_method='silverman')\n</code></pre> Source code in <code>modelskill/comparison/_collection_plotter.py</code> <pre><code>def kde(self, *, ax=None, figsize=None, title=None, **kwargs) -&gt; Axes:\n    \"\"\"Plot kernel density estimate of observation and model data.\n\n    Parameters\n    ----------\n    ax : Axes, optional\n        matplotlib axes, by default None\n    figsize : tuple, optional\n        width and height of the figure, by default None\n    title : str, optional\n        plot title, by default None\n    **kwargs\n        passed to pandas.DataFrame.plot.kde()\n\n    Returns\n    -------\n    Axes\n        matplotlib axes\n\n    Examples\n    --------\n    &gt;&gt;&gt; cc.plot.kde()\n    &gt;&gt;&gt; cc.plot.kde(bw_method=0.5)\n    &gt;&gt;&gt; cc.plot.kde(bw_method='silverman')\n\n    \"\"\"\n    _, ax = _get_fig_ax(ax, figsize)\n\n    df = self.cc.to_dataframe()\n    ax = df.obs_val.plot.kde(\n        ax=ax, linestyle=\"dashed\", label=\"Observation\", **kwargs\n    )\n\n    for model in self.cc.mod_names:\n        df_model = df[df.model == model]\n        df_model.mod_val.plot.kde(ax=ax, label=model, **kwargs)\n\n    ax.set_xlabel(f\"{self.cc.unit_text}\")\n\n    title = (\n        _default_univarate_title(\"Density plot\", self.cc)\n        if title is None\n        else title\n    )\n    ax.set_title(title)\n    ax.legend()\n\n    # remove y-axis, ticks and label\n    ax.yaxis.set_visible(False)\n    ax.tick_params(axis=\"y\", which=\"both\", length=0)\n    ax.set_ylabel(\"\")\n\n    # remove box around plot\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n\n    if self.is_directional:\n        _xtick_directional(ax)\n\n    return ax\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.scatter","title":"<code>scatter(*, model=None, bins=120, quantiles=None, fit_to_quantiles=False, show_points=None, show_hist=None, show_density=None, backend='matplotlib', figsize=(8, 8), xlim=None, ylim=None, reg_method='ols', title=None, xlabel=None, ylabel=None, skill_table=None, ax=None, **kwargs)</code>","text":"<p>Scatter plot showing compared data: observation vs modelled Optionally, with density histogram.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int | float</code> <p>bins for the 2D histogram on the background. By default 20 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges</p> <code>120</code> <code>quantiles</code> <code>int | Sequence[float] | None</code> <p>number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)</p> <code>None</code> <code>fit_to_quantiles</code> <code>bool</code> <p>by default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution</p> <code>False</code> <code>show_points</code> <code>(bool, int, float)</code> <p>Should the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points. int: if 'n' (int) given, then 'n' points will be displayed, randomly selected</p> <code>None</code> <code>show_hist</code> <code>bool</code> <p>show the data density as a a 2d histogram, by default None</p> <code>None</code> <code>show_density</code> <code>Optional[bool]</code> <p>show the data density as a colormap of the scatter, by default None. If both <code>show_density</code> and <code>show_hist</code> are None, then <code>show_density</code> is used by default. for binning the data, the kword <code>bins=Float</code> is used</p> <code>None</code> <code>backend</code> <code>str</code> <p>use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"</p> <code>'matplotlib'</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure, by default (8, 8)</p> <code>(8, 8)</code> <code>xlim</code> <code>tuple</code> <p>plot range for the observation (xmin, xmax), by default None</p> <code>None</code> <code>ylim</code> <code>tuple</code> <p>plot range for the model (ymin, ymax), by default None</p> <code>None</code> <code>reg_method</code> <code>str or bool</code> <p>method for determining the regression line \"ols\" : ordinary least squares regression \"odr\" : orthogonal distance regression, False : no regression line, by default \"ols\"</p> <code>'ols'</code> <code>title</code> <code>str</code> <p>plot title, by default None</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>x-label text on plot, by default None</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>y-label text on plot, by default None</p> <code>None</code> <code>skill_table</code> <code>(str, List[str], bool)</code> <p>list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list. This kword adds a box at the right of the scatter plot, by default False</p> <code>None</code> <code>ax</code> <code>matplotlib axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>**kwargs</code> <p>other keyword arguments to matplotlib.pyplot.scatter()</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc.plot.scatter()\n&gt;&gt;&gt; cc.plot.scatter(bins=0.2, backend='plotly')\n&gt;&gt;&gt; cc.plot.scatter(show_points=False, title='no points')\n&gt;&gt;&gt; cc.plot.scatter(xlabel='all observations', ylabel='my model')\n&gt;&gt;&gt; cc.plot.scatter(model='HKZN_v2', figsize=(10, 10))\n&gt;&gt;&gt; cc.plot.scatter(observations=['c2','HKNA'])\n</code></pre> Source code in <code>modelskill/comparison/_collection_plotter.py</code> <pre><code>def scatter(\n    self,\n    *,\n    model=None,\n    bins: int | float = 120,\n    quantiles: int | Sequence[float] | None = None,\n    fit_to_quantiles: bool = False,\n    show_points: bool | int | float | None = None,\n    show_hist: Optional[bool] = None,\n    show_density: Optional[bool] = None,\n    backend: str = \"matplotlib\",\n    figsize: Tuple[float, float] = (8, 8),\n    xlim: Optional[Tuple[float, float]] = None,\n    ylim: Optional[Tuple[float, float]] = None,\n    reg_method: str | bool = \"ols\",\n    title: Optional[str] = None,\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n    skill_table: Optional[Union[str, List[str], bool]] = None,\n    ax=None,\n    **kwargs,\n):\n    \"\"\"Scatter plot showing compared data: observation vs modelled\n    Optionally, with density histogram.\n\n    Parameters\n    ----------\n    bins: (int, float, sequence), optional\n        bins for the 2D histogram on the background. By default 20 bins.\n        if int, represents the number of bins of 2D\n        if float, represents the bin size\n        if sequence (list of int or float), represents the bin edges\n    quantiles: (int, sequence), optional\n        number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n        if int, this is the number of points\n        if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n    fit_to_quantiles: bool, optional, by default False\n        by default the regression line is fitted to all data, if True, it is fitted to the quantiles\n        which can be useful to represent the extremes of the distribution\n    show_points : (bool, int, float), optional\n        Should the scatter points be displayed?\n        None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None.\n        float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points.\n        int: if 'n' (int) given, then 'n' points will be displayed, randomly selected\n    show_hist : bool, optional\n        show the data density as a a 2d histogram, by default None\n    show_density: bool, optional\n        show the data density as a colormap of the scatter, by default None.\n        If both `show_density` and `show_hist` are None, then `show_density`\n        is used by default.\n        for binning the data, the kword `bins=Float` is used\n    backend : str, optional\n        use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"\n    figsize : tuple, optional\n        width and height of the figure, by default (8, 8)\n    xlim : tuple, optional\n        plot range for the observation (xmin, xmax), by default None\n    ylim : tuple, optional\n        plot range for the model (ymin, ymax), by default None\n    reg_method : str or bool, optional\n        method for determining the regression line\n        \"ols\" : ordinary least squares regression\n        \"odr\" : orthogonal distance regression,\n        False : no regression line,\n        by default \"ols\"\n    title : str, optional\n        plot title, by default None\n    xlabel : str, optional\n        x-label text on plot, by default None\n    ylabel : str, optional\n        y-label text on plot, by default None\n    skill_table : str, List[str], bool, optional\n        list of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list.\n        This kword adds a box at the right of the scatter plot,\n        by default False\n    ax : matplotlib axes, optional\n        axes to plot on, by default None\n    **kwargs :\n        other keyword arguments to matplotlib.pyplot.scatter()\n\n    Examples\n    ------\n    &gt;&gt;&gt; cc.plot.scatter()\n    &gt;&gt;&gt; cc.plot.scatter(bins=0.2, backend='plotly')\n    &gt;&gt;&gt; cc.plot.scatter(show_points=False, title='no points')\n    &gt;&gt;&gt; cc.plot.scatter(xlabel='all observations', ylabel='my model')\n    &gt;&gt;&gt; cc.plot.scatter(model='HKZN_v2', figsize=(10, 10))\n    &gt;&gt;&gt; cc.plot.scatter(observations=['c2','HKNA'])\n    \"\"\"\n\n    cc = self.cc\n    if model is None:\n        mod_names = cc.mod_names\n    else:\n        warnings.warn(\n            \"The 'model' keyword is deprecated! Instead, filter comparer before plotting cmp.sel(model=...).plot.scatter()\",\n            FutureWarning,\n        )\n\n        model_list = [model] if isinstance(model, (str, int)) else model\n        mod_names = [\n            self.cc.mod_names[_get_idx(m, self.cc.mod_names)] for m in model_list\n        ]\n\n    axes = []\n    for mod_name in mod_names:\n        ax_mod = self._scatter_one_model(\n            mod_name=mod_name,\n            bins=bins,\n            quantiles=quantiles,\n            fit_to_quantiles=fit_to_quantiles,\n            show_points=show_points,\n            show_hist=show_hist,\n            show_density=show_density,\n            backend=backend,\n            figsize=figsize,\n            xlim=xlim,\n            ylim=ylim,\n            reg_method=reg_method,\n            title=title,\n            xlabel=xlabel,\n            ylabel=ylabel,\n            skill_table=skill_table,\n            ax=ax,\n            **kwargs,\n        )\n        axes.append(ax_mod)\n    return axes[0] if len(axes) == 1 else axes\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.taylor","title":"<code>taylor(*, normalize_std=False, aggregate_observations=True, figsize=(7, 7), marker='o', marker_size=6.0, title='Taylor diagram')</code>","text":"<p>Taylor diagram showing model std and correlation to observation in a single-quadrant polar plot, with r=std and theta=arccos(cc).</p> <p>Parameters:</p> Name Type Description Default <code>normalize_std</code> <code>bool</code> <p>plot model std normalized with observation std, default False</p> <code>False</code> <code>aggregate_observations</code> <code>bool</code> <p>should multiple observations be aggregated before plotting (or shown individually), default True</p> <code>True</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure (should be square), by default (7, 7)</p> <code>(7, 7)</code> <code>marker</code> <code>str</code> <p>marker type e.g. \"x\", \"*\", by default \"o\"</p> <code>'o'</code> <code>marker_size</code> <code>float</code> <p>size of the marker, by default 6</p> <code>6.0</code> <code>title</code> <code>str</code> <p>title of the plot, by default \"Taylor diagram\"</p> <code>'Taylor diagram'</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cc.plot.taylor()\n&gt;&gt;&gt; cc.plot.taylor(observation=\"c2\")\n&gt;&gt;&gt; cc.plot.taylor(start=\"2017-10-28\", figsize=(5,5))\n</code></pre>"},{"location":"api/comparercollection/#modelskill.comparison._collection_plotter.ComparerCollectionPlotter.taylor--references","title":"References","text":"<p>Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin yannick.copin@laposte.net</p> Source code in <code>modelskill/comparison/_collection_plotter.py</code> <pre><code>def taylor(\n    self,\n    *,\n    normalize_std: bool = False,\n    aggregate_observations: bool = True,\n    figsize: Tuple[float, float] = (7, 7),\n    marker: str = \"o\",\n    marker_size: float = 6.0,\n    title: str = \"Taylor diagram\",\n):\n    \"\"\"Taylor diagram showing model std and correlation to observation\n    in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n    Parameters\n    ----------\n    normalize_std : bool, optional\n        plot model std normalized with observation std, default False\n    aggregate_observations : bool, optional\n        should multiple observations be aggregated before plotting\n        (or shown individually), default True\n    figsize : tuple, optional\n        width and height of the figure (should be square), by default (7, 7)\n    marker : str, optional\n        marker type e.g. \"x\", \"*\", by default \"o\"\n    marker_size : float, optional\n        size of the marker, by default 6\n    title : str, optional\n        title of the plot, by default \"Taylor diagram\"\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n\n    Examples\n    ------\n    &gt;&gt;&gt; cc.plot.taylor()\n    &gt;&gt;&gt; cc.plot.taylor(observation=\"c2\")\n    &gt;&gt;&gt; cc.plot.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n    References\n    ----------\n    Copin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin &lt;yannick.copin@laposte.net&gt;\n    \"\"\"\n\n    if (not aggregate_observations) and (not normalize_std):\n        raise ValueError(\n            \"aggregate_observations=False is only possible if normalize_std=True!\"\n        )\n\n    metrics = [mtr._std_obs, mtr._std_mod, mtr.cc]\n    skill_func = self.cc.mean_skill if aggregate_observations else self.cc.skill\n    s = skill_func(\n        metrics=metrics,  # type: ignore\n    )\n    if s is None:\n        return\n\n    df = s.to_dataframe()\n    ref_std = 1.0 if normalize_std else df.iloc[0][\"_std_obs\"]\n\n    if isinstance(df.index, pd.MultiIndex):\n        df.index = df.index.map(\"_\".join)\n\n    df = df[[\"_std_obs\", \"_std_mod\", \"cc\"]].copy()\n    df.columns = [\"obs_std\", \"std\", \"cc\"]\n    pts = [\n        TaylorPoint(\n            r.Index, r.obs_std, r.std, r.cc, marker=marker, marker_size=marker_size\n        )\n        for r in df.itertuples()\n    ]\n\n    return taylor_diagram(\n        obs_std=ref_std,\n        points=pts,\n        figsize=figsize,\n        normalize_std=normalize_std,\n        title=title,\n    )\n</code></pre>"},{"location":"api/gridded_skill/","title":"Gridded Skill","text":""},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid","title":"<code>modelskill.skill_grid.SkillGrid</code>","text":"<p>             Bases: <code>SkillGridMixin</code></p> <p>Gridded skill object for analysis and visualization of spatially gridded skill data. The object wraps the xr.DataSet class which can be accessed from the attribute data.</p> <p>The object contains one or more \"arrays\" of skill metrics, each corresponding to a single metric (e.g. bias, rmse, r2). The arrays are indexed by the metric name, e.g. <code>ss[\"bias\"]</code> or <code>ss.bias</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ss = cc.gridded_skill()\n&gt;&gt;&gt; ss.metrics\n['n', 'bias', 'rmse', 'urmse', 'mae', 'cc', 'si', 'r2']\n</code></pre> <pre><code>&gt;&gt;&gt; ss.mod_names\n['SW_1', 'SW_2']\n</code></pre> <pre><code>&gt;&gt;&gt; ss.rmse.plot(model='SW_1')\n</code></pre> Source code in <code>modelskill/skill_grid.py</code> <pre><code>class SkillGrid(SkillGridMixin):\n    \"\"\"\n    Gridded skill object for analysis and visualization of spatially\n    gridded skill data. The object wraps the xr.DataSet class\n    which can be accessed from the attribute data.\n\n    The object contains one or more \"arrays\" of skill metrics, each\n    corresponding to a single metric (e.g. bias, rmse, r2). The arrays\n    are indexed by the metric name, e.g. `ss[\"bias\"]` or `ss.bias`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; ss = cc.gridded_skill()\n    &gt;&gt;&gt; ss.metrics\n    ['n', 'bias', 'rmse', 'urmse', 'mae', 'cc', 'si', 'r2']\n\n    &gt;&gt;&gt; ss.mod_names\n    ['SW_1', 'SW_2']\n\n    &gt;&gt;&gt; ss.rmse.plot(model='SW_1')\n    \"\"\"\n\n    def __init__(self, data, name: Optional[str] = None):\n        # TODO: add type and unit info; add domain to plot outline on map\n        self.data = data\n        self.name = name\n        self._set_attrs()\n\n    @property\n    def metrics(self):\n        \"\"\"List of metrics (=data vars)\"\"\"\n        return list(self.data.data_vars)\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def _repr_html_(self):\n        return self.data._repr_html_()\n\n    @overload\n    def __getitem__(self, key: Hashable | int) -&gt; SkillGridArray:\n        ...\n\n    @overload\n    def __getitem__(self, key: Iterable[Hashable]) -&gt; SkillGrid:\n        ...\n\n    def __getitem__(self, key) -&gt; SkillGridArray | SkillGrid:\n        result = self.data[key]\n        if isinstance(result, xr.DataArray):\n            return SkillGridArray(result)\n        elif isinstance(result, xr.Dataset):\n            return SkillGrid(result)\n        else:\n            return result\n\n    def __getattr__(self, item):\n        if item in self.data.data_vars:\n            return self[item]  # Redirects to __getitem__\n\n        # For other attributes, return them directly\n        return getattr(self.data, item)\n\n    def _set_attrs(self):\n        # TODO: use type and unit to give better long name\n        # self.ds[\"bias\"].attrs = dict(long_name=\"Bias of Hm0\", units=\"m\")\n\n        self.data[\"n\"].attrs = dict(long_name=\"Number of observations\", units=\"-\")\n        if self._has_geographical_coords():\n            self.data[\"x\"].attrs = dict(long_name=\"Longitude\", units=\"degrees east\")\n            self.data[\"y\"].attrs = dict(long_name=\"Latitude\", units=\"degrees north\")\n        else:\n            self.data[\"x\"].attrs = dict(long_name=\"Easting\", units=\"meter\")\n            self.data[\"y\"].attrs = dict(long_name=\"Northing\", units=\"meter\")\n\n    def _has_geographical_coords(self):\n        is_geo = True\n        if (self.x.min() &lt; -180.0) or (self.x.max() &gt; 360.0):\n            is_geo = False\n        if (self.y.min() &lt; -90.0) or (self.y.max() &gt; 90.0):\n            is_geo = False\n        return is_geo\n\n    def sel(self, model: str) -&gt; SkillGrid:\n        \"\"\"Select a model from the SkillGrid\n\n        Parameters\n        ----------\n        model : str\n            Name of model to select\n\n        Returns\n        -------\n        SkillGrid\n            SkillGrid with only the selected model\n        \"\"\"\n        return SkillGrid(self.data.sel(model=model))\n\n    def plot(self, metric: str, model=None, **kwargs):\n        warnings.warn(\n            \"plot() is deprecated and will be removed in a future version. \",\n            FutureWarning,\n        )\n        if metric not in self.metrics:\n            raise ValueError(f\"metric {metric} not found in {self.metrics}\")\n        return self[metric].plot(model=model, **kwargs)\n\n    def to_dataframe(self):\n        \"\"\"export as pandas.DataFrame\"\"\"\n        return self.data.to_dataframe()\n</code></pre>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.coords","title":"<code>coords</code>  <code>property</code>","text":"<p>Coordinates (same as xr.DataSet.coords)</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>List of metrics (=data vars)</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.mod_names","title":"<code>mod_names</code>  <code>property</code>","text":"<p>List of model names</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.obs_names","title":"<code>obs_names</code>  <code>property</code>","text":"<p>List of observation names</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.x","title":"<code>x</code>  <code>property</code>","text":"<p>x-coordinate values</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.y","title":"<code>y</code>  <code>property</code>","text":"<p>y-coordinate values</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.sel","title":"<code>sel(model)</code>","text":"<p>Select a model from the SkillGrid</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of model to select</p> required <p>Returns:</p> Type Description <code>SkillGrid</code> <p>SkillGrid with only the selected model</p> Source code in <code>modelskill/skill_grid.py</code> <pre><code>def sel(self, model: str) -&gt; SkillGrid:\n    \"\"\"Select a model from the SkillGrid\n\n    Parameters\n    ----------\n    model : str\n        Name of model to select\n\n    Returns\n    -------\n    SkillGrid\n        SkillGrid with only the selected model\n    \"\"\"\n    return SkillGrid(self.data.sel(model=model))\n</code></pre>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGrid.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>export as pandas.DataFrame</p> Source code in <code>modelskill/skill_grid.py</code> <pre><code>def to_dataframe(self):\n    \"\"\"export as pandas.DataFrame\"\"\"\n    return self.data.to_dataframe()\n</code></pre>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray","title":"<code>modelskill.skill_grid.SkillGridArray</code>","text":"<p>             Bases: <code>SkillGridMixin</code></p> <p>A SkillGridArray is a single metric-SkillGrid, corresponding to a \"column\" in a SkillGrid</p> <p>Typically created by indexing a SkillGrid object, e.g. <code>ss[\"bias\"]</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ss = cc.gridded_skill()\n&gt;&gt;&gt; ss[\"bias\"].plot()\n</code></pre> Source code in <code>modelskill/skill_grid.py</code> <pre><code>class SkillGridArray(SkillGridMixin):\n    \"\"\"A SkillGridArray is a single metric-SkillGrid, corresponding to a \"column\" in a SkillGrid\n\n    Typically created by indexing a SkillGrid object, e.g. `ss[\"bias\"]`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; ss = cc.gridded_skill()\n    &gt;&gt;&gt; ss[\"bias\"].plot()\n    \"\"\"\n\n    def __init__(self, data):\n        assert isinstance(data, xr.DataArray)\n        self.data = data\n\n    def __repr__(self):\n        return repr(self.data)\n\n    def _repr_html_(self):\n        return self.data._repr_html_()\n\n    def plot(self, model=None, **kwargs):\n        \"\"\"wrapper for xArray DataArray plot function\n\n        Parameters\n        ----------\n        model : str, optional\n            Name of model to plot, by default all models\n        **kwargs : keyword arguments passed to xr.DataArray plot()\n            e.g. figsize\n\n        Examples\n        --------\n        &gt;&gt;&gt; ss = cc.gridded_skill()\n        &gt;&gt;&gt; ss[\"bias\"].plot()\n        &gt;&gt;&gt; ss.rmse.plot(model='SW_1')\n        &gt;&gt;&gt; ss.r2.plot(cmap='YlOrRd', figsize=(10,10))\n        \"\"\"\n        if model is None:\n            da = self.data\n        else:\n            warnings.warn(\n                \"model argument is deprecated, use sel(model=...)\",\n                FutureWarning,\n            )\n            if model not in self.mod_names:\n                raise ValueError(f\"model {model} not in model list ({self.mod_names})\")\n            da = self.data.sel({\"model\": model})\n\n        extra_dims = [d for d in da.coords.dims if d not in [\"x\", \"y\"]]\n        if len(extra_dims) == 2:\n            ax = da.plot(col=extra_dims[0], row=extra_dims[1], **kwargs)\n        elif len(extra_dims) == 1:\n            ax = da.plot(col=extra_dims[0], **kwargs)\n        else:\n            ax = da.plot(**kwargs)\n        return ax\n</code></pre>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.coords","title":"<code>coords</code>  <code>property</code>","text":"<p>Coordinates (same as xr.DataSet.coords)</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.mod_names","title":"<code>mod_names</code>  <code>property</code>","text":"<p>List of model names</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.obs_names","title":"<code>obs_names</code>  <code>property</code>","text":"<p>List of observation names</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.x","title":"<code>x</code>  <code>property</code>","text":"<p>x-coordinate values</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.y","title":"<code>y</code>  <code>property</code>","text":"<p>y-coordinate values</p>"},{"location":"api/gridded_skill/#modelskill.skill_grid.SkillGridArray.plot","title":"<code>plot(model=None, **kwargs)</code>","text":"<p>wrapper for xArray DataArray plot function</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of model to plot, by default all models</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments passed to xr.DataArray plot()</code> <p>e.g. figsize</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ss = cc.gridded_skill()\n&gt;&gt;&gt; ss[\"bias\"].plot()\n&gt;&gt;&gt; ss.rmse.plot(model='SW_1')\n&gt;&gt;&gt; ss.r2.plot(cmap='YlOrRd', figsize=(10,10))\n</code></pre> Source code in <code>modelskill/skill_grid.py</code> <pre><code>def plot(self, model=None, **kwargs):\n    \"\"\"wrapper for xArray DataArray plot function\n\n    Parameters\n    ----------\n    model : str, optional\n        Name of model to plot, by default all models\n    **kwargs : keyword arguments passed to xr.DataArray plot()\n        e.g. figsize\n\n    Examples\n    --------\n    &gt;&gt;&gt; ss = cc.gridded_skill()\n    &gt;&gt;&gt; ss[\"bias\"].plot()\n    &gt;&gt;&gt; ss.rmse.plot(model='SW_1')\n    &gt;&gt;&gt; ss.r2.plot(cmap='YlOrRd', figsize=(10,10))\n    \"\"\"\n    if model is None:\n        da = self.data\n    else:\n        warnings.warn(\n            \"model argument is deprecated, use sel(model=...)\",\n            FutureWarning,\n        )\n        if model not in self.mod_names:\n            raise ValueError(f\"model {model} not in model list ({self.mod_names})\")\n        da = self.data.sel({\"model\": model})\n\n    extra_dims = [d for d in da.coords.dims if d not in [\"x\", \"y\"]]\n    if len(extra_dims) == 2:\n        ax = da.plot(col=extra_dims[0], row=extra_dims[1], **kwargs)\n    elif len(extra_dims) == 1:\n        ax = da.plot(col=extra_dims[0], **kwargs)\n    else:\n        ax = da.plot(**kwargs)\n    return ax\n</code></pre>"},{"location":"api/matching/","title":"Matching","text":"<p>A Comparer/ComparerCollection can be created in one of the following ways:</p> <ul> <li><code>match()</code> - match observations and model results</li> <li><code>from_matched()</code> - create a Comparer/ComparerCollection from matched data</li> <li><code>from_config()</code> - create a Comparer/ComparerCollection from a config file</li> </ul>"},{"location":"api/matching/#modelskill.match","title":"<code>modelskill.match(obs, mod, *, obs_item=None, mod_item=None, gtype=None, max_model_gap=None)</code>","text":"<p>Compare observations and model results</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>(str, DataFrame, Observation)</code> <p>Observation to be compared</p> required <code>mod</code> <code>(str, DataFrame, ModelResultInterface)</code> <p>Model result to be compared</p> required <code>obs_item</code> <code>(int, str)</code> <p>observation item, by default None</p> <code>None</code> <code>mod_item</code> <code>(int, str)</code> <p>model item, by default None</p> <code>None</code> <code>gtype</code> <code>(str, optional)</code> <p>Geometry type of the model result. If not specified, it will be guessed.</p> <code>None</code> <code>max_model_gap</code> <code>(float, optional)</code> <p>Maximum time gap (s) in the model result, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ComparerCollection</code> <p>To be used for plotting and statistics</p> Source code in <code>modelskill/matching.py</code> <pre><code>def match(\n    obs,\n    mod,\n    *,\n    obs_item=None,\n    mod_item=None,\n    gtype=None,\n    max_model_gap=None,\n):\n    \"\"\"Compare observations and model results\n    Parameters\n    ----------\n    obs : (str, pd.DataFrame, Observation)\n        Observation to be compared\n    mod : (str, pd.DataFrame, ModelResultInterface)\n        Model result to be compared\n    obs_item : (int, str), optional\n        observation item, by default None\n    mod_item : (int, str), optional\n        model item, by default None\n    gtype : (str, optional)\n        Geometry type of the model result. If not specified, it will be guessed.\n    max_model_gap : (float, optional)\n        Maximum time gap (s) in the model result, by default None\n\n    Returns\n    -------\n    ComparerCollection\n        To be used for plotting and statistics\n    \"\"\"\n    if isinstance(obs, get_args(ObsInputType)):\n        return _single_obs_compare(\n            obs,\n            mod,\n            obs_item=obs_item,\n            mod_item=mod_item,\n            gtype=gtype,\n            max_model_gap=max_model_gap,\n        )\n\n    assert isinstance(obs, Iterable)\n\n    if len(obs) &gt; 1 and isinstance(mod, Iterable) and len(mod) &gt; 1:\n        if not all(isinstance(m, (DfsuModelResult, GridModelResult)) for m in mod):\n            raise ValueError(\n                \"\"\"\n                In case of multiple observations, multiple models can _only_ \n                be matched if they are _all_ of SpatialField type, e.g. DfsuModelResult \n                or GridModelResult. \n\n                If you want match multiple point observations with multiple point model results, \n                please match one observation at a time and then create a collection of these \n                using modelskill.ComparerCollection(cmp_list) afterwards. The same applies to track data.\n                \"\"\"\n            )\n\n    clist = [\n        _single_obs_compare(\n            o,\n            mod,\n            obs_item=obs_item,\n            mod_item=mod_item,\n            gtype=gtype,\n            max_model_gap=max_model_gap,\n        )\n        for o in obs\n    ]\n\n    return ComparerCollection(clist)\n</code></pre>"},{"location":"api/matching/#modelskill.from_matched","title":"<code>modelskill.from_matched(data, *, obs_item=0, mod_items=None, aux_items=None, quantity=None, name=None, weight=1.0, x=None, y=None, z=None)</code>","text":"<p>Create a Comparer from observation and model results that are already matched (aligned)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>[DataFrame, str, Path, Dfs0, Dataset]</code> <p>DataFrame (or object that can be converted to a DataFrame e.g. dfs0) with columns obs_item, mod_items, aux_items</p> required <code>obs_item</code> <code>[str, int]</code> <p>Name or index of observation item, by default first item</p> <code>0</code> <code>mod_items</code> <code>Iterable[str, int]</code> <p>Names or indicies of model items, if None all remaining columns are model items, by default None</p> <code>None</code> <code>aux_items</code> <code>Iterable[str, int]</code> <p>Names or indicies of auxiliary items, by default None</p> <code>None</code> <code>quantity</code> <code>Quantity</code> <p>Quantity of the observation and model results, by default Quantity(name=\"Undefined\", unit=\"Undefined\")</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the comparer, by default None (will be set to obs_item)</p> <code>None</code> <code>x</code> <code>float</code> <p>x-coordinate of observation, by default None</p> <code>None</code> <code>y</code> <code>float</code> <p>y-coordinate of observation, by default None</p> <code>None</code> <code>z</code> <code>float</code> <p>z-coordinate of observation, by default None</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a') # remaining columns are model results\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n Model: local, rmse=0.100\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1], 'global': [1.2,2.2,3.2], 'nonsense':[1,2,3]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a', mod_items=['local', 'global'])\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n    Model: local, rmse=0.100\n    Model: global, rmse=0.200\n</code></pre> Source code in <code>modelskill/matching.py</code> <pre><code>def from_matched(\n    data: Union[str, Path, pd.DataFrame, mikeio.Dfs0, mikeio.Dataset],\n    *,\n    obs_item: str | int | None = 0,\n    mod_items: Optional[Iterable[str | int]] = None,\n    aux_items: Optional[Iterable[str | int]] = None,\n    quantity: Optional[Quantity] = None,\n    name: Optional[str] = None,\n    weight: float = 1.0,\n    x: Optional[float] = None,\n    y: Optional[float] = None,\n    z: Optional[float] = None,\n) -&gt; Comparer:\n    \"\"\"Create a Comparer from observation and model results that are already matched (aligned)\n    Parameters\n    ----------\n    data : [pd.DataFrame,str,Path,mikeio.Dfs0, mikeio.Dataset]\n        DataFrame (or object that can be converted to a DataFrame e.g. dfs0)\n        with columns obs_item, mod_items, aux_items\n    obs_item : [str,int], optional\n        Name or index of observation item, by default first item\n    mod_items : Iterable[str,int], optional\n        Names or indicies of model items, if None all remaining columns are model items, by default None\n    aux_items : Iterable[str,int], optional\n        Names or indicies of auxiliary items, by default None\n    quantity : Quantity, optional\n        Quantity of the observation and model results, by default Quantity(name=\"Undefined\", unit=\"Undefined\")\n    name : str, optional\n        Name of the comparer, by default None (will be set to obs_item)\n    x : float, optional\n        x-coordinate of observation, by default None\n    y : float, optional\n        y-coordinate of observation, by default None\n    z : float, optional\n        z-coordinate of observation, by default None\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1]}, index=pd.date_range('2010-01-01', periods=3))\n    &gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a') # remaining columns are model results\n    &gt;&gt;&gt; cmp\n    &lt;Comparer&gt;\n    Quantity: Undefined [Undefined]\n    Observation: stn_a, n_points=3\n     Model: local, rmse=0.100\n    &gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1], 'global': [1.2,2.2,3.2], 'nonsense':[1,2,3]}, index=pd.date_range('2010-01-01', periods=3))\n    &gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a', mod_items=['local', 'global'])\n    &gt;&gt;&gt; cmp\n    &lt;Comparer&gt;\n    Quantity: Undefined [Undefined]\n    Observation: stn_a, n_points=3\n        Model: local, rmse=0.100\n        Model: global, rmse=0.200\n    \"\"\"\n    # pre-process if dfs0, or mikeio.Dataset\n    if isinstance(data, (str, Path)):\n        assert Path(data).suffix == \".dfs0\", \"File must be a dfs0 file\"\n        data = mikeio.read(data)  # now mikeio.Dataset\n    elif isinstance(data, mikeio.Dfs0):\n        data = data.read()  # now mikeio.Dataset\n    if isinstance(data, mikeio.Dataset):\n        assert len(data.shape) == 1, \"Only 0-dimensional data are supported\"\n        if quantity is None:\n            quantity = Quantity.from_mikeio_iteminfo(data[obs_item].item)\n        data = data.to_dataframe()\n\n    cmp = Comparer.from_matched_data(\n        data,\n        obs_item=obs_item,\n        mod_items=mod_items,\n        aux_items=aux_items,\n        name=name,\n        weight=weight,\n        x=x,\n        y=y,\n        z=z,\n        quantity=quantity,\n    )\n\n    return cmp\n</code></pre>"},{"location":"api/matching/#modelskill.from_config","title":"<code>modelskill.from_config(conf, *, validate_eum=True, relative_path=True)</code>","text":"<p>Load Connector from a config file (or dict)</p> <p>Parameters:</p> Name Type Description Default <code>conf</code> <code>Union[str, dict]</code> <p>path to config file or dict with configuration</p> required <code>validate_eum</code> <code>bool</code> <p>require eum to match, by default True</p> <code>True</code> <code>relative_path</code> <p>True: file paths are relative to configuration file, False: file paths are absolute (relative to the current directory), by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>Connector</code> <p>A Connector object with the given configuration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; con = ms.from_config('Oresund.yml')\n&gt;&gt;&gt; cc = con.extract()\n</code></pre> Source code in <code>modelskill/configuration.py</code> <pre><code>def from_config(conf: Union[dict, str], *, validate_eum=True, relative_path=True):\n    \"\"\"Load Connector from a config file (or dict)\n\n    Parameters\n    ----------\n    conf : Union[str, dict]\n        path to config file or dict with configuration\n    validate_eum : bool, optional\n        require eum to match, by default True\n    relative_path: bool, optional\n        True: file paths are relative to configuration file,\n        False: file paths are absolute (relative to the current directory),\n        by default True\n\n    Returns\n    -------\n    Connector\n        A Connector object with the given configuration\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; con = ms.from_config('Oresund.yml')\n    &gt;&gt;&gt; cc = con.extract()\n    \"\"\"\n    if isinstance(conf, str):\n        filename = conf\n        ext = os.path.splitext(filename)[-1]\n        dirname = os.path.dirname(filename)\n        if (ext == \".yml\") or (ext == \".yaml\") or (ext == \".conf\"):\n            conf = _yaml_to_dict(filename)\n        elif \"xls\" in ext:\n            conf = _excel_to_dict(filename)\n        else:\n            raise ValueError(\"Filename extension not supported! Use .yml or .xlsx\")\n    else:\n        dirname = \"\"\n\n    modelresults = {}\n\n    assert isinstance(conf, dict)\n    for name, mr_dict in conf[\"modelresults\"].items():\n        if not mr_dict.get(\"include\", True):\n            continue\n        if relative_path:\n            filename = os.path.join(dirname, mr_dict[\"filename\"])\n        else:\n            filename = mr_dict[\"filename\"]\n        item = mr_dict.get(\"item\")\n        mr = model_result(filename, name=name, item=item)\n        modelresults[name] = mr\n    mr_list = list(modelresults.values())\n\n    observations = {}\n    for name, obs_dict in conf[\"observations\"].items():\n        if not obs_dict.get(\"include\", True):\n            continue\n        if relative_path:\n            filename = os.path.join(dirname, obs_dict[\"filename\"])\n        else:\n            filename = obs_dict[\"filename\"]\n        item = obs_dict.get(\"item\")\n        alt_name = obs_dict.get(\"name\")\n        name = name if alt_name is None else alt_name\n\n        otype = obs_dict.get(\"type\")\n        if (otype is not None) and (\"track\" in otype.lower()):\n            obs = TrackObservation(filename, item=item, name=name)  # type: ignore\n        else:\n            x, y = obs_dict.get(\"x\"), obs_dict.get(\"y\")\n            obs = PointObservation(filename, item=item, x=x, y=y, name=name)  # type: ignore\n        observations[name] = obs\n    obs_list = list(observations.values())\n\n    if \"connections\" in conf:\n        raise NotImplementedError()\n    else:\n        con = Connector(obs_list, mr_list, validate=validate_eum)\n    return con\n</code></pre>"},{"location":"api/metrics/","title":"Metrics","text":""},{"location":"api/metrics/#modelskill.metrics","title":"<code>modelskill.metrics</code>","text":"<p>The <code>metrics</code> module contains different skill metrics for evaluating the  difference between a model and an observation. </p> <ul> <li>bias</li> <li>max_error</li> <li>root_mean_squared_error (rmse) </li> <li>urmse</li> <li>mean_absolute_error (mae)</li> <li>mean_absolute_percentage_error (mape)</li> <li>kling_gupta_efficiency (kge)</li> <li>nash_sutcliffe_efficiency (nse)</li> <li>r2 (r2=nse)</li> <li>model_efficiency_factor (mef)</li> <li>wilmott</li> <li>scatter_index (si)</li> <li>scatter_index2</li> <li>corrcoef (cc)</li> <li>spearmanr (rho)</li> <li>lin_slope</li> <li>hit_ratio</li> <li>explained_variance (ev)</li> <li>peak_ratio (pr)</li> </ul> <p>Circular metrics (for directional data with units in degrees):</p> <ul> <li>c_bias</li> <li>c_max_error</li> <li>c_mean_absolute_error (c_mae)</li> <li>c_root_mean_squared_error (c_rmse)</li> <li>c_unbiased_root_mean_squared_error (c_urmse)</li> </ul> <p>The names in parentheses are shorthand aliases for the different metrics.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([0.3, 2.1, -1.0])\n&gt;&gt;&gt; mod = np.array([0.0, 2.3, 1.0])\n&gt;&gt;&gt; bias(obs, mod)\n0.6333333333333332\n&gt;&gt;&gt; max_error(obs, mod)\n2.0\n&gt;&gt;&gt; rmse(obs, mod)\n1.173314393786536\n&gt;&gt;&gt; urmse(obs, mod)\n0.9877021593352702\n&gt;&gt;&gt; mae(obs, mod)\n0.8333333333333331\n&gt;&gt;&gt; mape(obs, mod)\n103.17460317460316\n&gt;&gt;&gt; nse(obs, mod)\n0.14786795048143053\n&gt;&gt;&gt; r2(obs, mod)\n0.14786795048143053\n&gt;&gt;&gt; mef(obs, mod)\n0.9231099877688299\n&gt;&gt;&gt; si(obs, mod)\n0.8715019052958266\n&gt;&gt;&gt; spearmanr(obs, mod)\n0.5\n&gt;&gt;&gt; willmott(obs, mod)\n0.7484604452865941\n&gt;&gt;&gt; hit_ratio(obs, mod, a=0.5)\n0.6666666666666666\n&gt;&gt;&gt; ev(obs, mod)\n0.39614855570839064\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.add_metric","title":"<code>add_metric(metric, has_units=False)</code>","text":"<p>Adds a metric to the metric list. Useful for custom metrics.</p> <p>Some metrics are dimensionless, others have the same dimension as the observations.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str or callable</code> <p>Metric name or function</p> required <code>has_units</code> <code>bool</code> <p>True if metric has a dimension, False otherwise. Default:False</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; add_metric(hit_ratio)\n&gt;&gt;&gt; add_metric(rmse,True)\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def add_metric(metric: Callable, has_units: bool = False) -&gt; None:\n    \"\"\"Adds a metric to the metric list. Useful for custom metrics.\n\n    Some metrics are dimensionless, others have the same dimension as the observations.\n\n    Parameters\n    ----------\n    metric : str or callable\n        Metric name or function\n    has_units : bool\n        True if metric has a dimension, False otherwise. Default:False\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; add_metric(hit_ratio)\n    &gt;&gt;&gt; add_metric(rmse,True)\n    \"\"\"\n    defined_metrics.add(metric.__name__)\n    if has_units:\n        METRICS_WITH_DIMENSION.add(metric.__name__)\n\n    # add the function to the module\n    setattr(sys.modules[__name__], metric.__name__, metric)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.bias","title":"<code>bias(obs, model)</code>","text":"<p>Bias (mean error)</p> \\[ bias=\\frac{1}{n}\\sum_{i=1}^n (model_i - obs_i) \\] <p>Range: \\((-\\infty, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def bias(obs, model) -&gt; float:\n    r\"\"\"Bias (mean error)\n\n    $$\n    bias=\\frac{1}{n}\\sum_{i=1}^n (model_i - obs_i)\n    $$\n\n    Range: $(-\\infty, \\infty)$; Best: 0\n    \"\"\"\n\n    assert obs.size == model.size\n    return np.mean(model.ravel() - obs.ravel())\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_bias","title":"<code>c_bias(obs, model)</code>","text":"<p>Circular bias (mean error)</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observation in degrees (0, 360)</p> required <code>model</code> <code>ndarray</code> <p>Model in degrees (0, 360)</p> required <p>Range: [-180., 180.]; Best: 0.</p> <p>Returns:</p> Type Description <code>float</code> <p>Circular bias</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([10., 355., 170.])\n&gt;&gt;&gt; mod = np.array([20., 5., -180.])\n&gt;&gt;&gt; c_bias(obs, mod)\n10.0\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_bias(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"Circular bias (mean error)\n\n    Parameters\n    ----------\n    obs : np.ndarray\n        Observation in degrees (0, 360)\n    model : np.ndarray\n        Model in degrees (0, 360)\n\n    Range: [-180., 180.]; Best: 0.\n\n    Returns\n    -------\n    float\n        Circular bias\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.array([10., 355., 170.])\n    &gt;&gt;&gt; mod = np.array([20., 5., -180.])\n    &gt;&gt;&gt; c_bias(obs, mod)\n    10.0\n    \"\"\"\n    from scipy.stats import circmean\n\n    resi = _c_residual(obs, model)\n    return circmean(resi, low=-180.0, high=180.0)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_mae","title":"<code>c_mae(obs, model, weights=None)</code>","text":"<p>alias for circular mean absolute error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_mae(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"alias for circular mean absolute error\"\"\"\n    return c_mean_absolute_error(obs, model, weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_max_error","title":"<code>c_max_error(obs, model)</code>","text":"<p>Circular max error</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observation in degrees (0, 360)</p> required <code>model</code> <code>ndarray</code> <p>Model in degrees (0, 360)</p> required <p>Range: :math:<code>[0, \\infty)</code>; Best: 0</p> <p>Returns:</p> Type Description <code>float</code> <p>Circular max error</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([10., 350., 10.])\n&gt;&gt;&gt; mod = np.array([20., 10., 350.])\n&gt;&gt;&gt; c_max_error(obs, mod)\n20.0\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_max_error(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"Circular max error\n\n    Parameters\n    ----------\n    obs : np.ndarray\n        Observation in degrees (0, 360)\n    model : np.ndarray\n        Model in degrees (0, 360)\n\n    Range: :math:`[0, \\\\infty)`; Best: 0\n\n    Returns\n    -------\n    float\n        Circular max error\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.array([10., 350., 10.])\n    &gt;&gt;&gt; mod = np.array([20., 10., 350.])\n    &gt;&gt;&gt; c_max_error(obs, mod)\n    20.0\n    \"\"\"\n\n    resi = _c_residual(obs, model)\n\n    # Compute the absolute differences and then\n    # find the shortest distance between angles\n    abs_diffs = np.abs(resi)\n    circular_diffs = np.minimum(abs_diffs, 360 - abs_diffs)\n    return np.max(circular_diffs)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_mean_absolute_error","title":"<code>c_mean_absolute_error(obs, model, weights=None)</code>","text":"<p>Circular mean absolute error</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observation in degrees (0, 360)</p> required <code>model</code> <code>ndarray</code> <p>Model in degrees (0, 360)</p> required <code>weights</code> <code>ndarray</code> <p>Weights, by default None</p> <code>None</code> <p>Range: [0, 180]; Best: 0</p> <p>Returns:</p> Type Description <code>float</code> <p>Circular mean absolute error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_mean_absolute_error(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Circular mean absolute error\n\n    Parameters\n    ----------\n    obs : np.ndarray\n        Observation in degrees (0, 360)\n    model : np.ndarray\n        Model in degrees (0, 360)\n    weights : np.ndarray, optional\n        Weights, by default None\n\n    Range: [0, 180]; Best: 0\n\n    Returns\n    -------\n    float\n        Circular mean absolute error\n    \"\"\"\n\n    resi = _c_residual(obs, model)\n    return np.average(np.abs(resi), weights=weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_rmse","title":"<code>c_rmse(obs, model, weights=None)</code>","text":"<p>alias for circular root mean squared error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_rmse(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"alias for circular root mean squared error\"\"\"\n    return c_root_mean_squared_error(obs, model, weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_root_mean_squared_error","title":"<code>c_root_mean_squared_error(obs, model, weights=None)</code>","text":"<p>Circular root mean squared error</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observation in degrees (0, 360)</p> required <code>model</code> <code>ndarray</code> <p>Model in degrees (0, 360)</p> required <code>weights</code> <code>ndarray</code> <p>Weights, by default None</p> <code>None</code> <p>Range: [0, 180]; Best: 0</p> <p>Returns:</p> Type Description <code>float</code> <p>Circular root mean squared error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_root_mean_squared_error(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Circular root mean squared error\n\n    Parameters\n    ----------\n    obs : np.ndarray\n        Observation in degrees (0, 360)\n    model : np.ndarray\n        Model in degrees (0, 360)\n    weights : np.ndarray, optional\n        Weights, by default None\n\n    Range: [0, 180]; Best: 0\n\n    Returns\n    -------\n    float\n        Circular root mean squared error\n    \"\"\"\n    residual = _c_residual(obs, model)\n    return np.sqrt(np.average(residual**2, weights=weights))\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_unbiased_root_mean_squared_error","title":"<code>c_unbiased_root_mean_squared_error(obs, model, weights=None)</code>","text":"<p>Circular unbiased root mean squared error</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ndarray</code> <p>Observation in degrees (0, 360)</p> required <code>model</code> <code>ndarray</code> <p>Model in degrees (0, 360)</p> required <code>weights</code> <code>ndarray</code> <p>Weights, by default None</p> <code>None</code> <p>Range: [0, 180]; Best: 0</p> <p>Returns:</p> Type Description <code>float</code> <p>Circular unbiased root mean squared error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_unbiased_root_mean_squared_error(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Circular unbiased root mean squared error\n\n    Parameters\n    ----------\n    obs : np.ndarray\n        Observation in degrees (0, 360)\n    model : np.ndarray\n        Model in degrees (0, 360)\n    weights : np.ndarray, optional\n        Weights, by default None\n\n    Range: [0, 180]; Best: 0\n\n    Returns\n    -------\n    float\n        Circular unbiased root mean squared error\n    \"\"\"\n    from scipy.stats import circmean\n\n    residual = _c_residual(obs, model)\n    residual = residual - circmean(residual, low=-180.0, high=180.0)\n    return np.sqrt(np.average(residual**2, weights=weights))\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.c_urmse","title":"<code>c_urmse(obs, model, weights=None)</code>","text":"<p>alias for circular unbiased root mean squared error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def c_urmse(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"alias for circular unbiased root mean squared error\"\"\"\n    return c_unbiased_root_mean_squared_error(obs, model, weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.cc","title":"<code>cc(obs, model, weights=None)</code>","text":"<p>alias for corrcoef</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def cc(obs: np.ndarray, model: np.ndarray, weights=None) -&gt; float:\n    \"\"\"alias for corrcoef\"\"\"\n    return corrcoef(obs, model, weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.corrcoef","title":"<code>corrcoef(obs, model, weights=None)</code>","text":"<p>Pearson\u2019s Correlation coefficient (CC)</p> \\[ CC = \\frac{\\sum_{i=1}^n (model_i - \\overline{model})(obs_i - \\overline{obs}) }                {\\sqrt{\\sum_{i=1}^n (model_i - \\overline{model})^2}                 \\sqrt{\\sum_{i=1}^n (obs_i - \\overline{obs})^2} } \\] <p>Range: [-1, 1]; Best: 1</p>"},{"location":"api/metrics/#modelskill.metrics.corrcoef--see-also","title":"See Also","text":"<p>spearmanr np.corrcoef</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def corrcoef(obs, model, weights=None) -&gt; float:\n    r\"\"\"Pearson\u2019s Correlation coefficient (CC)\n\n    $$\n    CC = \\frac{\\sum_{i=1}^n (model_i - \\overline{model})(obs_i - \\overline{obs}) }\n                   {\\sqrt{\\sum_{i=1}^n (model_i - \\overline{model})^2}\n                    \\sqrt{\\sum_{i=1}^n (obs_i - \\overline{obs})^2} }\n    $$\n\n    Range: [-1, 1]; Best: 1\n\n    See Also\n    --------\n    spearmanr\n    np.corrcoef\n    \"\"\"\n    assert obs.size == model.size\n    if len(obs) &lt;= 1:\n        return np.nan\n\n    if weights is None:\n        return np.corrcoef(obs.ravel(), model.ravel())[0, 1]\n    else:\n        C = np.cov(obs.ravel(), model.ravel(), fweights=weights)\n        return C[0, 1] / np.sqrt(C[0, 0] * C[1, 1])\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.ev","title":"<code>ev(obs, model)</code>","text":"<p>alias for explained_variance</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def ev(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for explained_variance\"\"\"\n    assert obs.size == model.size\n    return explained_variance(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.explained_variance","title":"<code>explained_variance(obs, model)</code>","text":"<p>EV: Explained variance</p> <p>EV is the explained variance and measures the proportion  [0 - 1] to which the model accounts for the variation  (dispersion) of the observations.</p> <p>In cases with no bias, EV is equal to r2</p> \\[ \\frac{ \\sum_{i=1}^n (obs_i - \\overline{obs})^2 - \\sum_{i=1}^n \\left( (obs_i - \\overline{obs}) - (model_i - \\overline{model}) \\right)^2}{\\sum_{i=1}^n (obs_i - \\overline{obs})^2} \\] <p>Range: [0, 1]; Best: 1</p>"},{"location":"api/metrics/#modelskill.metrics.explained_variance--see-also","title":"See Also","text":"<p>r2</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def explained_variance(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"EV: Explained variance\n\n     EV is the explained variance and measures the proportion\n     [0 - 1] to which the model accounts for the variation\n     (dispersion) of the observations.\n\n     In cases with no bias, EV is equal to r2\n\n    $$\n    \\frac{ \\sum_{i=1}^n (obs_i - \\overline{obs})^2 -\n    \\sum_{i=1}^n \\left( (obs_i - \\overline{obs}) -\n    (model_i - \\overline{model}) \\right)^2}{\\sum_{i=1}^n\n    (obs_i - \\overline{obs})^2}\n    $$\n\n    Range: [0, 1]; Best: 1\n\n    See Also\n    --------\n    r2\n    \"\"\"\n\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n\n    nominator = np.sum((obs.ravel() - obs.mean()) ** 2) - np.sum(\n        ((obs.ravel() - obs.mean()) - (model.ravel() - model.mean())) ** 2\n    )\n    denominator = np.sum((obs.ravel() - obs.mean()) ** 2)\n\n    return nominator / denominator\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.hit_ratio","title":"<code>hit_ratio(obs, model, a=0.1)</code>","text":"<p>Fraction within obs \u00b1 acceptable deviation</p> \\[ HR = \\frac{1}{n}\\sum_{i=1}^n I_{|(model_i - obs_i)|} &lt; a \\] <p>Range: [0, 1]; Best: 1</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.05)\n0.2857142857142857\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.1)\n0.8571428571428571\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.15)\n1.0\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def hit_ratio(obs: np.ndarray, model: np.ndarray, a=0.1) -&gt; float:\n    r\"\"\"Fraction within obs \u00b1 acceptable deviation\n\n    $$\n    HR = \\frac{1}{n}\\sum_{i=1}^n I_{|(model_i - obs_i)|} &lt; a\n    $$\n\n    Range: [0, 1]; Best: 1\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n    &gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n    &gt;&gt;&gt; hit_ratio(obs, model, a=0.05)\n    0.2857142857142857\n    &gt;&gt;&gt; hit_ratio(obs, model, a=0.1)\n    0.8571428571428571\n    &gt;&gt;&gt; hit_ratio(obs, model, a=0.15)\n    1.0\n    \"\"\"\n    assert obs.size == model.size\n\n    return np.mean(np.abs(obs.ravel() - model.ravel()) &lt; a)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.kge","title":"<code>kge(obs, model)</code>","text":"<p>alias for kling_gupta_efficiency</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def kge(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for kling_gupta_efficiency\"\"\"\n    return kling_gupta_efficiency(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.kling_gupta_efficiency","title":"<code>kling_gupta_efficiency(obs, model)</code>","text":"<p>Kling-Gupta Efficiency (KGE)</p> \\[ KGE = 1 - \\sqrt{(r-1)^2 + \\left(\\frac{\\sigma_{mod}}{\\sigma_{obs}} - 1\\right)^2 +                             \\left(\\frac{\\mu_{mod}}{\\mu_{obs}} - 1\\right)^2 } \\] <p>where \\(r\\) is the pearson correlation coefficient, \\(\\mu_{obs},\\mu_{mod}\\) and \\(\\sigma_{obs},\\sigma_{mod}\\) is the mean and standard deviation of observations and model.</p> <p>Range: \\((-\\infty, 1]\\); Best: 1</p>"},{"location":"api/metrics/#modelskill.metrics.kling_gupta_efficiency--references","title":"References","text":"<p>Gupta, H. V., Kling, H., Yilmaz, K. K. and Martinez, G. F., (2009), Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling, J. Hydrol., 377(1-2), 80-91 https://doi.org/10.1016/j.jhydrol.2009.08.003</p> <p>Knoben, W. J. M., Freer, J. E., and Woods, R. A. (2019) Technical note: Inherent benchmark or not? Comparing Nash\u2013Sutcliffe and Kling\u2013Gupta efficiency scores, Hydrol. Earth Syst. Sci., 23, 4323-4331 https://doi.org/10.5194/hess-23-4323-2019</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def kling_gupta_efficiency(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"\n    Kling-Gupta Efficiency (KGE)\n\n    $$\n    KGE = 1 - \\sqrt{(r-1)^2 + \\left(\\frac{\\sigma_{mod}}{\\sigma_{obs}} - 1\\right)^2 +\n                                \\left(\\frac{\\mu_{mod}}{\\mu_{obs}} - 1\\right)^2 }\n    $$\n\n    where $r$ is the pearson correlation coefficient, $\\mu_{obs},\\mu_{mod}$ and $\\sigma_{obs},\\sigma_{mod}$ is the mean and standard deviation of observations and model.\n\n    Range: $(-\\infty, 1]$; Best: 1\n\n    References\n    ----------\n    Gupta, H. V., Kling, H., Yilmaz, K. K. and Martinez, G. F., (2009), Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling, J. Hydrol., 377(1-2), 80-91 &lt;https://doi.org/10.1016/j.jhydrol.2009.08.003&gt;\n\n    Knoben, W. J. M., Freer, J. E., and Woods, R. A. (2019) Technical note: Inherent benchmark or not? Comparing Nash\u2013Sutcliffe and Kling\u2013Gupta efficiency scores, Hydrol. Earth Syst. Sci., 23, 4323-4331 &lt;https://doi.org/10.5194/hess-23-4323-2019&gt;\n    \"\"\"\n    assert obs.size == model.size\n\n    if len(obs) == 0 or obs.std() == 0.0:\n        return np.nan\n\n    if model.std() &gt; 1e-12:\n        r = corrcoef(obs, model)\n        if np.isnan(r):\n            r = 0.0\n    else:\n        r = 0.0\n\n    res = 1 - np.sqrt(\n        (r - 1) ** 2\n        + (model.std() / obs.std() - 1.0) ** 2\n        + (model.mean() / obs.mean() - 1.0) ** 2\n    )\n\n    return res\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.lin_slope","title":"<code>lin_slope(obs, model, reg_method='ols')</code>","text":"<p>Slope of the regression line.</p> \\[ slope = \\frac{\\sum_{i=1}^n (model_i - \\overline {model})(obs_i - \\overline {obs})}                 {\\sum_{i=1}^n (obs_i - \\overline {obs})^2} \\] <p>Range: \\((-\\infty, \\infty )\\); Best: 1</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def lin_slope(obs: np.ndarray, model: np.ndarray, reg_method=\"ols\") -&gt; float:\n    r\"\"\"Slope of the regression line.\n\n    $$\n    slope = \\frac{\\sum_{i=1}^n (model_i - \\overline {model})(obs_i - \\overline {obs})}\n                    {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n    $$\n\n    Range: $(-\\infty, \\infty )$; Best: 1\n    \"\"\"\n    assert obs.size == model.size\n    return _linear_regression(obs.ravel(), model.ravel(), reg_method)[0]\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.mae","title":"<code>mae(obs, model, weights=None)</code>","text":"<p>alias for mean_absolute_error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def mae(\n    obs: np.ndarray, model: np.ndarray, weights: Optional[np.ndarray] = None\n) -&gt; float:\n    \"\"\"alias for mean_absolute_error\"\"\"\n    assert obs.size == model.size\n    return mean_absolute_error(obs, model, weights)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.mape","title":"<code>mape(obs, model)</code>","text":"<p>alias for mean_absolute_percentage_error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def mape(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for mean_absolute_percentage_error\"\"\"\n    return mean_absolute_percentage_error(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.max_error","title":"<code>max_error(obs, model)</code>","text":"<p>Max (absolute) error</p> \\[ max_{error} = max(|model_i - obs_i|) \\] <p>Range: \\([0, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def max_error(obs, model) -&gt; float:\n    r\"\"\"Max (absolute) error\n\n    $$\n    max_{error} = max(|model_i - obs_i|)\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n    \"\"\"\n\n    assert obs.size == model.size\n    return np.max(np.abs(model.ravel() - obs.ravel()))\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.mean_absolute_error","title":"<code>mean_absolute_error(obs, model, weights=None)</code>","text":"<p>Mean Absolute Error (MAE)</p> \\[ MAE=\\frac{1}{n}\\sum_{i=1}^n|model_i - obs_i| \\] <p>Range: \\([0, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def mean_absolute_error(\n    obs: np.ndarray, model: np.ndarray, weights: Optional[np.ndarray] = None\n) -&gt; float:\n    r\"\"\"Mean Absolute Error (MAE)\n\n    $$\n    MAE=\\frac{1}{n}\\sum_{i=1}^n|model_i - obs_i|\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n    \"\"\"\n    assert obs.size == model.size\n\n    error = np.average(np.abs(model.ravel() - obs.ravel()), weights=weights)\n\n    return error\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.mean_absolute_percentage_error","title":"<code>mean_absolute_percentage_error(obs, model)</code>","text":"<p>Mean Absolute Percentage Error (MAPE)</p> \\[ MAPE=\\frac{1}{n}\\sum_{i=1}^n\\frac{|model_i - obs_i|}{obs_i}*100 \\] <p>Range: \\([0, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def mean_absolute_percentage_error(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Mean Absolute Percentage Error (MAPE)\n\n    $$\n    MAPE=\\frac{1}{n}\\sum_{i=1}^n\\frac{|model_i - obs_i|}{obs_i}*100\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n    \"\"\"\n\n    assert obs.size == model.size\n\n    if len(obs) == 0:\n        return np.nan\n    if np.any(obs == 0.0):\n        warnings.warn(\"Observation is zero, consider to use another metric than MAPE\")\n        return np.nan  # TODO is it better to return a large value +inf than NaN?\n\n    return np.mean(np.abs((obs.ravel() - model.ravel()) / obs.ravel())) * 100\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.mef","title":"<code>mef(obs, model)</code>","text":"<p>alias for model_efficiency_factor</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def mef(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for model_efficiency_factor\"\"\"\n    return model_efficiency_factor(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.metric_has_units","title":"<code>metric_has_units(metric)</code>","text":"<p>Check if a metric has units (dimension).</p> <p>Some metrics are dimensionless, others have the same dimension as the observations.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str or callable</code> <p>Metric name or function</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if metric has a dimension, False otherwise</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric_has_units(\"rmse\")\nTrue\n&gt;&gt;&gt; metric_has_units(\"kge\")\nFalse\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def metric_has_units(metric: Union[str, Callable]) -&gt; bool:\n    \"\"\"Check if a metric has units (dimension).\n\n    Some metrics are dimensionless, others have the same dimension as the observations.\n\n    Parameters\n    ----------\n    metric : str or callable\n        Metric name or function\n\n    Returns\n    -------\n    bool\n        True if metric has a dimension, False otherwise\n\n    Examples\n    --------\n    &gt;&gt;&gt; metric_has_units(\"rmse\")\n    True\n    &gt;&gt;&gt; metric_has_units(\"kge\")\n    False\n    \"\"\"\n    if hasattr(metric, \"__name__\"):\n        name = metric.__name__\n    else:\n        name = metric\n\n    if name not in defined_metrics:\n        raise ValueError(f\"Metric {name} not defined. Choose from {defined_metrics}\")\n\n    return name in METRICS_WITH_DIMENSION\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.model_efficiency_factor","title":"<code>model_efficiency_factor(obs, model)</code>","text":"<p>Model Efficiency Factor (MEF)</p> <p>Scale independent RMSE, standardized by Stdev of observations</p> \\[ MEF = \\frac{RMSE}{STDEV}=\\frac{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}}                                 {\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(obs_i - \\overline{obs})^2}}=\\sqrt{1-NSE} \\] <p>Range: \\([0, \\infty)\\); Best: 0</p>"},{"location":"api/metrics/#modelskill.metrics.model_efficiency_factor--see-also","title":"See Also","text":"<p>nash_sutcliffe_efficiency root_mean_squared_error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def model_efficiency_factor(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Model Efficiency Factor (MEF)\n\n    Scale independent RMSE, standardized by Stdev of observations\n\n    $$\n    MEF = \\frac{RMSE}{STDEV}=\\frac{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}}\n                                    {\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(obs_i - \\overline{obs})^2}}=\\sqrt{1-NSE}\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n\n    See Also\n    --------\n    nash_sutcliffe_efficiency\n    root_mean_squared_error\n\n    \"\"\"\n    assert obs.size == model.size\n\n    return rmse(obs, model) / obs.std()\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.nash_sutcliffe_efficiency","title":"<code>nash_sutcliffe_efficiency(obs, model)</code>","text":"<p>Nash-Sutcliffe Efficiency (NSE)</p> \\[ NSE = 1 - \\frac {\\sum _{i=1}^{n}\\left(model_{i} - obs_{i}\\right)^{2}}                 {\\sum_{i=1}^{n}\\left(obs_{i} - {\\overline{obs}}\\right)^{2}} \\] <p>Range: \\((-\\infty, 1]\\); Best: 1</p>"},{"location":"api/metrics/#modelskill.metrics.nash_sutcliffe_efficiency--note","title":"Note","text":"<p>r2 = nash_sutcliffe_efficiency(nse)</p>"},{"location":"api/metrics/#modelskill.metrics.nash_sutcliffe_efficiency--references","title":"References","text":"<p>Nash, J. E.; Sutcliffe, J. V. (1970). \"River flow forecasting through conceptual models part I \u2014 A discussion of principles\". Journal of Hydrology. 10 (3): 282\u2013290. https://doi.org/10.1016/0022-1694(70)90255-6</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def nash_sutcliffe_efficiency(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Nash-Sutcliffe Efficiency (NSE)\n\n    $$\n    NSE = 1 - \\frac {\\sum _{i=1}^{n}\\left(model_{i} - obs_{i}\\right)^{2}}\n                    {\\sum_{i=1}^{n}\\left(obs_{i} - {\\overline{obs}}\\right)^{2}}\n    $$\n\n    Range: $(-\\infty, 1]$; Best: 1\n\n    Note\n    ----\n    r2 = nash_sutcliffe_efficiency(nse)\n\n    References\n    ----------\n    Nash, J. E.; Sutcliffe, J. V. (1970). \"River flow forecasting through conceptual models part I \u2014 A discussion of principles\". Journal of Hydrology. 10 (3): 282\u2013290. &lt;https://doi.org/10.1016/0022-1694(70)90255-6&gt;\n    \"\"\"\n    assert obs.size == model.size\n\n    if len(obs) == 0:\n        return np.nan\n    error = 1 - (\n        np.sum((obs.ravel() - model.ravel()) ** 2)\n        / np.sum((obs.ravel() - np.mean(obs.ravel())) ** 2)\n    )\n\n    return error\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.nse","title":"<code>nse(obs, model)</code>","text":"<p>alias for nash_sutcliffe_efficiency</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def nse(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for nash_sutcliffe_efficiency\"\"\"\n    return nash_sutcliffe_efficiency(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.peak_ratio","title":"<code>peak_ratio(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')</code>","text":"<p>Peak Ratio</p> <p>PR is the mean of the individual ratios of identified peaks in the model / identified peaks in the measurements. PR is calculated only for the joint-events, ie, events that ocurr simulateneously within a window +/- 0.5*inter_event_time.</p> <p>Parameters:</p> Name Type Description Default <code>inter_event_level</code> <code>float</code> <p>Inter-event level threshold (default: 0.7).</p> <code>0.7</code> <code>AAP</code> <code>int</code> <p>Average Annual Peaks (ie, Number of peaks per year, on average). (default: 2)</p> <code>2</code> <code>inter_event_time</code> <pre><code>Maximum time interval between peaks (default: 36 hours).\n</code></pre> <code>'36h'</code> \\[ \\frac{\\sum_{i=1}^{N_{joint-peaks}} (\\frac{Peak_{model_i}}{Peak_{obs_i}} )}{N_{joint-peaks}} \\] <p>Range: \\([0, \\infty)\\); Best: 1.0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def peak_ratio(\n    obs: pd.Series,\n    model: pd.Series,\n    inter_event_level: float = 0.7,\n    AAP: int = 2,\n    inter_event_time=\"36h\",\n) -&gt; float:\n    r\"\"\"Peak Ratio\n\n    PR is the mean of the individual ratios of identified peaks in the\n    model / identified peaks in the measurements. PR is calculated only for the joint-events,\n    ie, events that ocurr simulateneously within a window +/- 0.5*inter_event_time.\n\n    Parameters\n    ----------\n    inter_event_level (float, optional)\n        Inter-event level threshold (default: 0.7).\n    AAP (float, optional)\n        Average Annual Peaks (ie, Number of peaks per year, on average). (default: 2)\n    inter_event_time (str, optional)\n            Maximum time interval between peaks (default: 36 hours).\n\n    $$\n    \\frac{\\sum_{i=1}^{N_{joint-peaks}} (\\frac{Peak_{model_i}}{Peak_{obs_i}} )}{N_{joint-peaks}}\n    $$\n\n    Range: $[0, \\infty)$; Best: 1.0\n    \"\"\"\n\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n    assert isinstance(obs.index, pd.DatetimeIndex)\n    time = obs.index\n    # Calculate number of years\n    dt_int = time[1:].values - time[0:-1].values\n    dt_int_mode = float(stats.mode(dt_int, keepdims=False)[0]) / 1e9  # in seconds\n    N_years = dt_int_mode / 24 / 3600 / 365.25 * len(time)\n    found_peaks = []\n    for data in [obs, model]:\n        peak_index, AAP_ = _partial_duration_series(\n            time,\n            data,\n            inter_event_level=inter_event_level,\n            AAP=AAP,\n            inter_event_time=inter_event_time,\n        )\n        peaks = data[peak_index]\n        peaks_sorted = peaks.sort_values(ascending=False)\n        found_peaks.append(\n            peaks_sorted[0 : max(1, min(round(AAP_ * N_years), np.sum(peaks)))]\n        )\n    found_peaks_obs = found_peaks[0]\n    found_peaks_mod = found_peaks[1]\n\n    # Resample~ish, find peaks spread maximum Half the inter event time (if inter event =36, select data paired +/- 18h) (or inter_event) and then select\n    indices_mod = (\n        abs(found_peaks_obs.index.values[:, None] - found_peaks_mod.index.values)\n        &lt; pd.Timedelta(inter_event_time) / 2\n    ).any(axis=0)\n    indices_obs = (\n        abs(found_peaks_mod.index.values[:, None] - found_peaks_obs.index.values)\n        &lt; pd.Timedelta(inter_event_time) / 2\n    ).any(axis=0)\n    obs_joint = found_peaks_obs.loc[indices_obs]\n    mod_joint = found_peaks_mod.loc[indices_mod]\n\n    if len(obs_joint) == 0 or len(mod_joint) == 0:\n        return np.nan\n    res = np.mean(mod_joint.values / obs_joint.values)\n    return res\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.pr","title":"<code>pr(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')</code>","text":"<p>alias for peak_ratio</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def pr(\n    obs: np.ndarray,\n    model: np.ndarray,\n    inter_event_level: float = 0.7,\n    AAP: int = 2,\n    inter_event_time=\"36h\",\n) -&gt; float:\n    \"\"\"alias for peak_ratio\"\"\"\n    assert obs.size == model.size\n    return peak_ratio(obs, model, inter_event_level, AAP, inter_event_time)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.r2","title":"<code>r2(obs, model)</code>","text":"<p>Coefficient of determination (R2)</p> <p>Pronounced 'R-squared'; the proportion of the variation in the dependent variable that is predictable from the independent variable(s), i.e. the proportion of explained variance.</p> \\[ R^2 = 1 - \\frac{\\sum_{i=1}^n (model_i - obs_i)^2}                 {\\sum_{i=1}^n (obs_i - \\overline {obs})^2} \\] <p>Range: \\((-\\infty, 1]\\); Best: 1</p>"},{"location":"api/metrics/#modelskill.metrics.r2--note","title":"Note","text":"<p>r2 = nash_sutcliffe_efficiency(nse)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1.0,1.1,1.2,1.3,1.4])\n&gt;&gt;&gt; model = np.array([1.09, 1.16, 1.3 , 1.38, 1.49])\n&gt;&gt;&gt; r2(obs,model)\n0.6379999999999998\n</code></pre> Source code in <code>modelskill/metrics.py</code> <pre><code>def r2(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Coefficient of determination (R2)\n\n    Pronounced 'R-squared'; the proportion of the variation in the dependent variable that is predictable from the independent variable(s), i.e. the proportion of explained variance.\n\n    $$\n    R^2 = 1 - \\frac{\\sum_{i=1}^n (model_i - obs_i)^2}\n                    {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n    $$\n\n    Range: $(-\\infty, 1]$; Best: 1\n\n    Note\n    ----\n    r2 = nash_sutcliffe_efficiency(nse)\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.array([1.0,1.1,1.2,1.3,1.4])\n    &gt;&gt;&gt; model = np.array([1.09, 1.16, 1.3 , 1.38, 1.49])\n    &gt;&gt;&gt; r2(obs,model)\n    0.6379999999999998\n    \"\"\"\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n\n    residual = model.ravel() - obs.ravel()\n    SSr = np.sum(residual**2)\n    SSt = np.sum((obs - obs.mean()) ** 2)\n\n    return 1 - SSr / SSt\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.rho","title":"<code>rho(obs, model)</code>","text":"<p>alias for spearmanr</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def rho(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for spearmanr\"\"\"\n    return spearmanr(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.rmse","title":"<code>rmse(obs, model, weights=None, unbiased=False)</code>","text":"<p>alias for root_mean_squared_error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def rmse(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n    unbiased: bool = False,\n) -&gt; float:\n    \"\"\"alias for root_mean_squared_error\"\"\"\n    return root_mean_squared_error(obs, model, weights, unbiased)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.root_mean_squared_error","title":"<code>root_mean_squared_error(obs, model, weights=None, unbiased=False)</code>","text":"<p>Root Mean Squared Error (RMSE)</p> \\[ res_i = model_i - obs_i \\] \\[ RMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_i^2} \\] <p>Unbiased version:</p> \\[ res_{u,i} = res_i - \\overline {res} \\] \\[ uRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2} \\] <p>Range: \\([0, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def root_mean_squared_error(\n    obs: np.ndarray,\n    model: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n    unbiased: bool = False,\n) -&gt; float:\n    r\"\"\"Root Mean Squared Error (RMSE)\n\n    $$\n    res_i = model_i - obs_i\n    $$\n\n    $$\n    RMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_i^2}\n    $$\n\n    Unbiased version:\n\n    $$\n    res_{u,i} = res_i - \\overline {res}\n    $$\n\n    $$\n    uRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n\n    \"\"\"\n    assert obs.size == model.size\n\n    residual = obs.ravel() - model.ravel()\n    if unbiased:\n        residual = residual - residual.mean()\n    error = np.sqrt(np.average(residual**2, weights=weights))\n\n    return error\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.scatter_index","title":"<code>scatter_index(obs, model)</code>","text":"<p>Scatter index (SI)</p> <p>Which is the same as the unbiased-RMSE normalized by the absolute mean of the observations.</p> \\[ \\frac{ \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2} } {\\frac{1}{n} \\sum_{i=1}^n | obs_i | } \\] <p>Range: \\([0, \\infty)\\); Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def scatter_index(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Scatter index (SI)\n\n    Which is the same as the unbiased-RMSE normalized by the absolute mean of the observations.\n\n    $$\n    \\frac{ \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2} }\n    {\\frac{1}{n} \\sum_{i=1}^n | obs_i | }\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n    \"\"\"\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n\n    residual = obs.ravel() - model.ravel()\n    residual = residual - residual.mean()  # unbiased\n    return np.sqrt(np.mean(residual**2)) / np.mean(np.abs(obs.ravel()))\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.scatter_index2","title":"<code>scatter_index2(obs, model)</code>","text":"<p>Alternative formulation of the scatter index (SI)</p> \\[ \\sqrt {\\frac{\\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2} {\\sum_{i=1}^n obs_i^2}} \\] <p>Range: [0, 100]; Best: 0</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def scatter_index2(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Alternative formulation of the scatter index (SI)\n\n    $$\n    \\sqrt {\\frac{\\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2}\n    {\\sum_{i=1}^n obs_i^2}}\n    $$\n\n    Range: [0, 100]; Best: 0\n    \"\"\"\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n\n    return np.sqrt(\n        np.sum(((model.ravel() - model.mean()) - (obs.ravel() - obs.mean())) ** 2)\n        / np.sum(obs.ravel() ** 2)\n    )\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.si","title":"<code>si(obs, model)</code>","text":"<p>alias for scatter_index</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def si(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    \"\"\"alias for scatter_index\"\"\"\n    return scatter_index(obs, model)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.spearmanr","title":"<code>spearmanr(obs, model)</code>","text":"<p>Spearman rank correlation coefficient</p> <p>The rank correlation coefficient is similar to the Pearson correlation coefficient but applied to ranked quantities and is useful to quantify a monotonous relationship</p> \\[ \\rho = \\frac{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})(robs_i - \\overline{robs}) }                 {\\sqrt{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})^2}                 \\sqrt{\\sum_{i=1}^n (robs_i - \\overline{robs})^2} } \\] <p>Range: [-1, 1]; Best: 1</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.linspace(-20, 20, 100)\n&gt;&gt;&gt; mod = np.tanh(obs)\n&gt;&gt;&gt; rho(obs, mod)\n0.9999759973116955\n&gt;&gt;&gt; spearmanr(obs, mod)\n0.9999759973116955\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.spearmanr--see-also","title":"See Also","text":"<p>corrcoef</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def spearmanr(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Spearman rank correlation coefficient\n\n    The rank correlation coefficient is similar to the Pearson correlation coefficient but\n    applied to ranked quantities and is useful to quantify a monotonous relationship\n\n    $$\n    \\rho = \\frac{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})(robs_i - \\overline{robs}) }\n                    {\\sqrt{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})^2}\n                    \\sqrt{\\sum_{i=1}^n (robs_i - \\overline{robs})^2} }\n    $$\n\n    Range: [-1, 1]; Best: 1\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.linspace(-20, 20, 100)\n    &gt;&gt;&gt; mod = np.tanh(obs)\n    &gt;&gt;&gt; rho(obs, mod)\n    0.9999759973116955\n    &gt;&gt;&gt; spearmanr(obs, mod)\n    0.9999759973116955\n\n    See Also\n    --------\n    corrcoef\n    \"\"\"\n    import scipy.stats\n\n    return scipy.stats.spearmanr(obs, model)[0]\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.urmse","title":"<code>urmse(obs, model, weights=None)</code>","text":"<p>Unbiased Root Mean Squared Error (uRMSE)</p> \\[ res_i = model_i - obs_i \\] \\[ res_{u,i} = res_i - \\overline {res} \\] \\[ uRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2} \\] <p>Range: \\([0, \\infty)\\); Best: 0</p>"},{"location":"api/metrics/#modelskill.metrics.urmse--see-also","title":"See Also","text":"<p>root_mean_squared_error</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def urmse(\n    obs: np.ndarray, model: np.ndarray, weights: Optional[np.ndarray] = None\n) -&gt; float:\n    r\"\"\"Unbiased Root Mean Squared Error (uRMSE)\n\n    $$\n    res_i = model_i - obs_i\n    $$\n\n    $$\n    res_{u,i} = res_i - \\overline {res}\n    $$\n\n    $$\n    uRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n    $$\n\n    Range: $[0, \\infty)$; Best: 0\n\n    See Also\n    --------\n    root_mean_squared_error\n    \"\"\"\n    return root_mean_squared_error(obs, model, weights, unbiased=True)\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.willmott","title":"<code>willmott(obs, model)</code>","text":"<p>Willmott's Index of Agreement</p> <p>A scaled representation of the predictive accuracy of the model against observations. A value of 1 indicates a perfect match, and 0 indicates no agreement at all.</p> \\[ willmott = 1 - \\frac{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}                     {\\frac{1}{n} \\sum_{i=1}^n(|model_i - \\overline{obs}| + |obs_i - \\overline{obs}|)^2} \\] <p>Range: [0, 1]; Best: 1</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; willmott(obs, model)\n0.9501403174479723\n</code></pre>"},{"location":"api/metrics/#modelskill.metrics.willmott--references","title":"References","text":"<p>Willmott, C. J. 1981. \"On the validation of models\". Physical Geography, 2, 184\u2013194.</p> Source code in <code>modelskill/metrics.py</code> <pre><code>def willmott(obs: np.ndarray, model: np.ndarray) -&gt; float:\n    r\"\"\"Willmott's Index of Agreement\n\n    A scaled representation of the predictive accuracy of the model against observations. A value of 1 indicates a perfect match, and 0 indicates no agreement at all.\n\n    $$\n    willmott = 1 - \\frac{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}\n                        {\\frac{1}{n} \\sum_{i=1}^n(|model_i - \\overline{obs}| + |obs_i - \\overline{obs}|)^2}\n    $$\n\n    Range: [0, 1]; Best: 1\n\n    Examples\n    --------\n    &gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n    &gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n    &gt;&gt;&gt; willmott(obs, model)\n    0.9501403174479723\n\n    References\n    ----------\n    Willmott, C. J. 1981. \"On the validation of models\". Physical Geography, 2, 184\u2013194.\n    \"\"\"\n\n    assert obs.size == model.size\n    if len(obs) == 0:\n        return np.nan\n\n    residual = model.ravel() - obs.ravel()\n    nominator = np.sum(residual**2)\n    denominator = np.sum((np.abs(model - obs.mean()) + np.abs(obs - obs.mean())) ** 2)\n\n    return 1 - nominator / denominator\n</code></pre>"},{"location":"api/plotting/","title":"Plotting","text":""},{"location":"api/plotting/#modelskill.plotting","title":"<code>modelskill.plotting</code>","text":"<p>The plotting module provides functions useful for skill assessment that can be used independently of the comparison module.</p> <ul> <li><code>scatter</code> is a function that can be used to plot a scatter suitable for skill assessment, with a 1:1 line and a linear regression line.</li> <li><code>wind_rose</code> is a function that can be used to plot a dual wind rose to compare two datasets of magnitudes and directions.</li> <li><code>spatial_overview</code> is a function that can be used to plot a spatial overview of two datasets.</li> <li><code>temporal_coverage</code> is a function that can be used to plot the temporal coverage of two datasets.</li> </ul>"},{"location":"api/plotting/#modelskill.plotting.scatter","title":"<code>scatter(x, y, *, bins=120, quantiles=None, fit_to_quantiles=False, show_points=None, show_hist=None, show_density=None, norm=None, backend='matplotlib', figsize=(8, 8), xlim=None, ylim=None, reg_method='ols', title='', xlabel='', ylabel='', skill_df=None, units='', ax=None, **kwargs)</code>","text":"<p>Scatter plot showing compared data: observation vs modelled Optionally, with density histogram.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>X values e.g model values, must be same length as y</p> required <code>y</code> <code>ndarray</code> <p>Y values e.g observation values, must be same length as x</p> required <code>bins</code> <code>int | float</code> <p>bins for the 2D histogram on the background. By default 120 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges</p> <code>120</code> <code>quantiles</code> <code>int | Sequence[float] | None</code> <p>number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)</p> <code>None</code> <code>fit_to_quantiles</code> <code>bool</code> <p>by default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution</p> <code>False</code> <code>show_points</code> <code>(bool, int, float)</code> <p>Should the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points. int: if 'n' (int) given, then 'n' points will be displayed, randomly selected.</p> <code>None</code> <code>show_hist</code> <code>bool</code> <p>show the data density as a 2d histogram, by default None</p> <code>None</code> <code>show_density</code> <code>Optional[bool]</code> <p>show the data density as a colormap of the scatter, by default None. If both <code>show_density</code> and <code>show_hist</code> are None, then <code>show_density</code> is used by default. for binning the data, the previous kword <code>bins=Float</code> is used</p> <code>None</code> <code>norm</code> <code>Normalize</code> <p>colormap normalization If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)</p> <code>None</code> <code>backend</code> <code>str</code> <p>use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"</p> <code>'matplotlib'</code> <code>figsize</code> <code>tuple</code> <p>width and height of the figure, by default (8, 8)</p> <code>(8, 8)</code> <code>xlim</code> <code>tuple</code> <p>plot range for the observation (xmin, xmax), by default None</p> <code>None</code> <code>ylim</code> <code>tuple</code> <p>plot range for the model (ymin, ymax), by default None</p> <code>None</code> <code>reg_method</code> <code>str or bool</code> <p>method for determining the regression line \"ols\" : ordinary least squares regression \"odr\" : orthogonal distance regression, False : no regression line by default \"ols\"</p> <code>'ols'</code> <code>title</code> <code>str</code> <p>plot title, by default None</p> <code>''</code> <code>xlabel</code> <code>str</code> <p>x-label text on plot, by default None</p> <code>''</code> <code>ylabel</code> <code>str</code> <p>y-label text on plot, by default None</p> <code>''</code> <code>skill_df</code> <code>dataframe</code> <p>dataframe with skill (stats) results to be added to plot, by default None</p> <code>None</code> <code>units</code> <code>str</code> <p>user default units to override default units, eg 'metre', by default None</p> <code>''</code> <code>ax</code> <code>Axes</code> <p>axes to plot on, by default None</p> <code>None</code> <code>**kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axes on which the scatter plot was drawn.</p> Source code in <code>modelskill/plotting/_scatter.py</code> <pre><code>def scatter(\n    x: np.ndarray,\n    y: np.ndarray,\n    *,\n    bins: int | float = 120,\n    quantiles: int | Sequence[float] | None = None,\n    fit_to_quantiles: bool = False,\n    show_points: bool | int | float | None = None,\n    show_hist: Optional[bool] = None,\n    show_density: Optional[bool] = None,\n    norm: Optional[colors.Normalize] = None,\n    backend: str = \"matplotlib\",\n    figsize: Tuple[float, float] = (8, 8),\n    xlim: Optional[Tuple[float, float]] = None,\n    ylim: Optional[Tuple[float, float]] = None,\n    reg_method: str | bool = \"ols\",\n    title: str = \"\",\n    xlabel: str = \"\",\n    ylabel: str = \"\",\n    skill_df: Optional[pd.DataFrame] = None,\n    units: Optional[str] = \"\",\n    ax: Optional[Axes] = None,\n    **kwargs,\n):\n    \"\"\"Scatter plot showing compared data: observation vs modelled\n    Optionally, with density histogram.\n\n    Parameters\n    ----------\n    x: np.array\n        X values e.g model values, must be same length as y\n    y: np.array\n        Y values e.g observation values, must be same length as x\n    bins: (int, float, sequence), optional\n        bins for the 2D histogram on the background. By default 120 bins.\n        if int, represents the number of bins of 2D\n        if float, represents the bin size\n        if sequence (list of int or float), represents the bin edges\n    quantiles: (int, sequence), optional\n        number of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000)\n        if int, this is the number of points\n        if sequence (list of floats), represents the desired quantiles (from 0 to 1)\n    fit_to_quantiles: bool, optional, by default False\n        by default the regression line is fitted to all data, if True, it is fitted to the quantiles\n        which can be useful to represent the extremes of the distribution\n    show_points : (bool, int, float), optional\n        Should the scatter points be displayed?\n        None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None.\n        float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points.\n        int: if 'n' (int) given, then 'n' points will be displayed, randomly selected.\n    show_hist : bool, optional\n        show the data density as a 2d histogram, by default None\n    show_density: bool, optional\n        show the data density as a colormap of the scatter, by default None. If both `show_density` and `show_hist`\n        are None, then `show_density` is used by default.\n        for binning the data, the previous kword `bins=Float` is used\n    norm : matplotlib.colors.Normalize\n        colormap normalization\n        If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)\n    backend : str, optional\n        use \"plotly\" (interactive) or \"matplotlib\" backend, by default \"matplotlib\"\n    figsize : tuple, optional\n        width and height of the figure, by default (8, 8)\n    xlim : tuple, optional\n        plot range for the observation (xmin, xmax), by default None\n    ylim : tuple, optional\n        plot range for the model (ymin, ymax), by default None\n    reg_method : str or bool, optional\n        method for determining the regression line\n        \"ols\" : ordinary least squares regression\n        \"odr\" : orthogonal distance regression,\n        False : no regression line\n        by default \"ols\"\n    title : str, optional\n        plot title, by default None\n    xlabel : str, optional\n        x-label text on plot, by default None\n    ylabel : str, optional\n        y-label text on plot, by default None\n    skill_df : dataframe, optional\n        dataframe with skill (stats) results to be added to plot, by default None\n    units : str, optional\n        user default units to override default units, eg 'metre', by default None\n    ax : matplotlib.axes.Axes, optional\n        axes to plot on, by default None\n    **kwargs\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axes on which the scatter plot was drawn.\n    \"\"\"\n    if show_hist is None and show_density is None:\n        # Default: points density\n        show_density = True\n\n    if len(x) != len(y):\n        raise ValueError(\"x &amp; y are not of equal length\")\n\n    if norm is None:\n        # Default: PowerNorm with gamma of 0.5\n        norm = colors.PowerNorm(vmin=1, gamma=0.5)\n\n    x_sample, y_sample = sample_points(x, y, show_points)\n    xq, yq = quantiles_xy(x, y, quantiles)\n\n    xmin, xmax = x.min(), x.max()\n    ymin, ymax = y.min(), y.max()\n    xymin = min([xmin, ymin])\n    xymax = max([xmax, ymax])\n\n    nbins_hist, binsize = _get_bins(bins, xymin=xymin, xymax=xymax)\n\n    if xlim is None:\n        xlim = (xymin - binsize, xymax + binsize)\n\n    if ylim is None:\n        ylim = (xymin - binsize, xymax + binsize)\n\n    x_trend = np.array([xlim[0], xlim[1]])\n\n    if show_hist and show_density:\n        raise TypeError(\n            \"if `show_hist=True` then `show_density` must be either `False` or `None`\"\n        )\n\n    z = None\n    if show_density and len(x_sample) &gt; 0:\n        if not isinstance(bins, (float, int)):\n            raise TypeError(\n                \"if `show_density=True` then bins must be either float or int\"\n            )\n\n        # calculate density data\n        z = __scatter_density(x_sample, y_sample, binsize=binsize)\n        idx = z.argsort()\n        # Sort data by colormaps\n        x_sample, y_sample, z = x_sample[idx], y_sample[idx], z[idx]\n        # scale Z by sample size\n        z = z * len(x) / len(x_sample)\n\n    PLOTTING_BACKENDS: dict[str, Callable] = {\n        \"matplotlib\": _scatter_matplotlib,\n        \"plotly\": _scatter_plotly,\n    }\n\n    if backend not in PLOTTING_BACKENDS:\n        raise ValueError(f\"backend must be one of {list(PLOTTING_BACKENDS.keys())}\")\n\n    return PLOTTING_BACKENDS[backend](\n        x=x,\n        y=y,\n        x_sample=x_sample,\n        y_sample=y_sample,\n        z=z,\n        xq=xq,\n        yq=yq,\n        x_trend=x_trend,\n        show_density=show_density,\n        norm=norm,\n        show_points=show_points,\n        show_hist=show_hist,\n        nbins_hist=nbins_hist,\n        reg_method=reg_method,\n        xlabel=xlabel,\n        ylabel=ylabel,\n        figsize=figsize,\n        xlim=xlim,\n        ylim=ylim,\n        title=title,\n        skill_df=skill_df,\n        units=units,\n        fit_to_quantiles=fit_to_quantiles,\n        ax=ax,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/plotting/#modelskill.plotting.spatial_overview","title":"<code>spatial_overview(obs, mod=None, ax=None, figsize=None, title=None)</code>","text":"<p>Plot observation points on a map showing the model domain</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>List[Observation]</code> <p>List of observations to be shown on map</p> required <code>mod</code> <code>Union[ModelResult, GeometryFM]</code> <p>Model domain to be shown as outline</p> <code>None</code> <code>ax</code> <p>Adding to existing axis, instead of creating new fig</p> <code>None</code> <code>figsize</code> <code>(float, float)</code> <p>figure size, by default None</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>plot title, default empty</p> <code>None</code>"},{"location":"api/plotting/#modelskill.plotting.spatial_overview--see-also","title":"See Also","text":"<p>temporal_coverage</p> <p>Returns:</p> Type Description <code>Axes</code> <p>The matplotlib axes object</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.PointObservation('HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\n&gt;&gt;&gt; o2 = ms.TrackObservation(\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\n&gt;&gt;&gt; mr1 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast.dfsu', name='SW_1', item=0)\n&gt;&gt;&gt; mr2 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast_v2.dfsu', name='SW_2', item=0)\n&gt;&gt;&gt; ms.plotting.spatial_overview([o1, o2], [mr1, mr2])\n</code></pre> Source code in <code>modelskill/plotting/_spatial_overview.py</code> <pre><code>def spatial_overview(\n    obs: List[Observation],\n    mod=None,\n    ax=None,\n    figsize: Optional[Tuple] = None,\n    title: Optional[str] = None,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot observation points on a map showing the model domain\n\n    Parameters\n    ----------\n    obs: list[Observation]\n        List of observations to be shown on map\n    mod : Union[ModelResult, mikeio.GeometryFM], optional\n        Model domain to be shown as outline\n    ax: matplotlib.axes, optional\n        Adding to existing axis, instead of creating new fig\n    figsize : (float, float), optional\n        figure size, by default None\n    title: str, optional\n        plot title, default empty\n\n    See Also\n    --------\n    temporal_coverage\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The matplotlib axes object\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; o1 = ms.PointObservation('HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\n    &gt;&gt;&gt; o2 = ms.TrackObservation(\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\n    &gt;&gt;&gt; mr1 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast.dfsu', name='SW_1', item=0)\n    &gt;&gt;&gt; mr2 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast_v2.dfsu', name='SW_2', item=0)\n    &gt;&gt;&gt; ms.plotting.spatial_overview([o1, o2], [mr1, mr2])\n    \"\"\"\n    obs = [] if obs is None else list(obs) if isinstance(obs, Sequence) else [obs]  # type: ignore\n    mod = [] if mod is None else list(mod) if isinstance(mod, Sequence) else [mod]  # type: ignore\n\n    ax = _get_ax(ax=ax, figsize=figsize)\n    offset_x = 1  # TODO: better default\n\n    for m in mod:\n        # TODO: support Gridded ModelResults\n        if isinstance(m, (PointModelResult, TrackModelResult)):\n            raise ValueError(\n                f\"Model type {type(m)} not supported. Only DfsuModelResult and mikeio.GeometryFM supported!\"\n            )\n        if hasattr(m, \"data\") and hasattr(m.data, \"geometry\"):\n            # mod_name = m.name  # TODO: better support for multiple models\n            m = m.data.geometry\n        if hasattr(m, \"node_coordinates\"):\n            xn = m.node_coordinates[:, 0]\n            offset_x = 0.02 * (max(xn) - min(xn))\n        m.plot.outline(ax=ax)\n\n    for o in obs:\n        if isinstance(o, PointObservation):\n            ax.scatter(x=o.x, y=o.y, marker=\"x\")\n            ax.annotate(o.name, (o.x + offset_x, o.y))  # type: ignore\n        elif isinstance(o, TrackObservation):\n            if o.n_points &lt; 10000:\n                ax.scatter(x=o.x, y=o.y, c=o.values, marker=\".\", cmap=\"Reds\")\n            else:\n                print(f\"{o.name}: Too many points to plot\")\n                # TODO: group by lonlat bin or sample randomly\n        else:\n            raise ValueError(\n                f\"Could not show observation {o}. Only PointObservation and TrackObservation supported.\"\n            )\n\n    if not title:\n        title = \"Spatial coverage\"\n    ax.set_title(title)\n\n    return ax\n</code></pre>"},{"location":"api/plotting/#modelskill.plotting.taylor_diagram","title":"<code>taylor_diagram(obs_std, points, figsize=(7, 7), obs_text='Observations', normalize_std=False, ax=None, title='Taylor diagram')</code>","text":"<p>Plot a Taylor diagram using the given observations and points.</p> <p>Parameters:</p> Name Type Description Default <code>obs_std</code> <code>float</code> <p>Standard deviation of the observations.</p> required <code>points</code> <code>list of TaylorPoint objects or a single TaylorPoint object</code> <p>Points to plot on the Taylor diagram.</p> required <code>figsize</code> <code>tuple</code> <p>Figure size in inches. Default is (7, 7).</p> <code>(7, 7)</code> <code>obs_text</code> <code>str</code> <p>Label for the observations. Default is \"Observations\".</p> <code>'Observations'</code> <code>normalize_std</code> <code>bool</code> <p>Whether to normalize the standard deviation of the points by the standard deviation of the observations. Default is False.</p> <code>False</code> <code>title</code> <code>str</code> <p>Title of the plot. Default is \"Taylor diagram\".</p> <code>'Taylor diagram'</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The matplotlib figure object</p> Source code in <code>modelskill/plotting/_taylor_diagram.py</code> <pre><code>def taylor_diagram(\n    obs_std,\n    points,\n    figsize=(7, 7),\n    obs_text=\"Observations\",\n    normalize_std=False,\n    ax=None,\n    title=\"Taylor diagram\",\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"\n    Plot a Taylor diagram using the given observations and points.\n\n    Parameters\n    -----------\n    obs_std : float\n        Standard deviation of the observations.\n    points : list of TaylorPoint objects or a single TaylorPoint object\n        Points to plot on the Taylor diagram.\n    figsize : tuple, optional\n        Figure size in inches. Default is (7, 7).\n    obs_text : str, optional\n        Label for the observations. Default is \"Observations\".\n    normalize_std : bool, optional\n        Whether to normalize the standard deviation of the points by the standard deviation of the observations. Default is False.\n    title : str, optional\n        Title of the plot. Default is \"Taylor diagram\".\n\n    Returns\n    --------\n    matplotlib.figure.Figure\n            The matplotlib figure object\n    \"\"\"\n\n    if np.isscalar(figsize):\n        figsize = (figsize, figsize)\n    elif figsize[0] != figsize[1]:\n        warnings.warn(\n            \"It is strongly recommended that the aspect ratio is 1:1 for Taylor diagrams\"\n        )\n    fig = plt.figure(figsize=figsize)\n\n    # srange=(0, 1.5),\n    if len(obs_text) &gt; 30:\n        obs_text = obs_text[:25] + \"...\"\n\n    td = TaylorDiagram(\n        obs_std, fig=fig, rect=111, label=obs_text, normalize_std=normalize_std\n    )\n    contours = td.add_contours(levels=8, colors=\"0.5\", linestyles=\"dotted\")\n    plt.clabel(contours, inline=1, fontsize=10, fmt=\"%.2f\")\n\n    if isinstance(points, TaylorPoint):\n        points = [points]\n    for p in points:\n        assert isinstance(p, TaylorPoint)\n        m = \"o\" if p.marker is None else p.marker\n        ms = \"6\" if p.marker_size is None else p.marker_size\n        std = p.std / p.obs_std if normalize_std else p.std\n        td.add_sample(std, p.cc, marker=m, ms=ms, ls=\"\", label=p.name)\n        # marker=f\"${1}$\",\n        # td.add_sample(0.2, 0.8, marker=\"+\", ms=15, mew=1.2, ls=\"\", label=\"m2\")\n    td.add_grid()\n    fig.legend(\n        td.samplePoints,\n        [p.get_label() for p in td.samplePoints],\n        numpoints=1,\n        prop=dict(size=\"medium\"),\n        loc=\"upper right\",\n    )\n    fig.suptitle(title, size=\"x-large\")\n\n    return fig\n</code></pre>"},{"location":"api/plotting/#modelskill.plotting.temporal_coverage","title":"<code>temporal_coverage(obs=None, mod=None, *, limit_to_model_period=True, marker='_', ax=None, figsize=None, title=None)</code>","text":"<p>Plot graph showing temporal coverage for all observations and models</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>List[Observation]</code> <p>Show observation(s) as separate lines on plot</p> <code>None</code> <code>mod</code> <code>List[ModelResult]</code> <p>Show model(s) as separate lines on plot, by default None</p> <code>None</code> <code>limit_to_model_period</code> <code>bool</code> <p>Show temporal coverage only for period covered by the model, by default True</p> <code>True</code> <code>marker</code> <code>str</code> <p>plot marker for observations, by default \"_\"</p> <code>'_'</code> <code>ax</code> <p>Adding to existing axis, instead of creating new fig</p> <code>None</code> <code>figsize</code> <code>Tuple(float, float)</code> <p>size of figure, by default (7, 0.45*n_lines)</p> <code>None</code> <code>title</code> <p>plot title, default empty</p> <code>None</code>"},{"location":"api/plotting/#modelskill.plotting.temporal_coverage--see-also","title":"See Also","text":"<p>spatial_overview</p> <p>Returns:</p> Type Description <code>Axes</code> <p>The matplotlib axes object</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.PointObservation('HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\n&gt;&gt;&gt; o2 = ms.TrackObservation(\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\n&gt;&gt;&gt; mr1 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast.dfsu', name='SW_1', item=0)\n&gt;&gt;&gt; mr2 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast_v2.dfsu', name='SW_2', item=0)\n&gt;&gt;&gt; ms.plotting.temporal_coverage([o1, o2], [mr1, mr2])\n&gt;&gt;&gt; ms.plotting.temporal_coverage([o1, o2], mr2, limit_to_model_period=False)\n&gt;&gt;&gt; ms.plotting.temporal_coverage(o2, [mr1, mr2], marker=\".\")\n&gt;&gt;&gt; ms.plotting.temporal_coverage(mod=[mr1, mr2], figsize=(5,3))\n</code></pre> Source code in <code>modelskill/plotting/_temporal_coverage.py</code> <pre><code>def temporal_coverage(\n    obs=None,\n    mod=None,\n    *,\n    limit_to_model_period=True,\n    marker=\"_\",\n    ax=None,\n    figsize=None,\n    title=None,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plot graph showing temporal coverage for all observations and models\n\n    Parameters\n    ----------\n    obs : List[Observation], optional\n        Show observation(s) as separate lines on plot\n    mod : List[ModelResult], optional\n        Show model(s) as separate lines on plot, by default None\n    limit_to_model_period : bool, optional\n        Show temporal coverage only for period covered\n        by the model, by default True\n    marker : str, optional\n        plot marker for observations, by default \"_\"\n    ax: matplotlib.axes, optional\n        Adding to existing axis, instead of creating new fig\n    figsize : Tuple(float, float), optional\n        size of figure, by default (7, 0.45*n_lines)\n    title: str, optional\n        plot title, default empty\n\n    See Also\n    --------\n    spatial_overview\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The matplotlib axes object\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; o1 = ms.PointObservation('HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\n    &gt;&gt;&gt; o2 = ms.TrackObservation(\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\n    &gt;&gt;&gt; mr1 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast.dfsu', name='SW_1', item=0)\n    &gt;&gt;&gt; mr2 = ms.DfsuModelResult('HKZN_local_2017_DutchCoast_v2.dfsu', name='SW_2', item=0)\n    &gt;&gt;&gt; ms.plotting.temporal_coverage([o1, o2], [mr1, mr2])\n    &gt;&gt;&gt; ms.plotting.temporal_coverage([o1, o2], mr2, limit_to_model_period=False)\n    &gt;&gt;&gt; ms.plotting.temporal_coverage(o2, [mr1, mr2], marker=\".\")\n    &gt;&gt;&gt; ms.plotting.temporal_coverage(mod=[mr1, mr2], figsize=(5,3))\n    \"\"\"\n    obs = [] if obs is None else list(obs) if isinstance(obs, Sequence) else [obs]\n    mod = [] if mod is None else list(mod) if isinstance(mod, Sequence) else [mod]\n\n    n_lines = len(obs) + len(mod)\n    if figsize is None:\n        ysize = max(2.0, 0.45 * n_lines)\n        figsize = (7, ysize)\n\n    fig, ax = _get_fig_ax(ax=ax, figsize=figsize)\n    y = np.repeat(0.0, 2)\n    labels = []\n\n    if len(mod) &gt; 0:\n        for mr in mod:\n            y += 1.0\n            plt.plot([mr.time[0], mr.time[-1]], y)\n            labels.append(mr.name)\n\n    for o in obs:\n        y += 1.0\n        plt.plot(o.time, y[0] * np.ones(len(o.time)), marker, markersize=5)\n        labels.append(o.name)\n\n    if len(mod) &gt; 0 and limit_to_model_period:\n        mr = mod[0]  # take first model\n        plt.xlim([mr.time[0], mr.time[-1]])\n\n    plt.yticks(np.arange(n_lines) + 1, labels)\n    if len(mod) &gt; 0:\n        for j in range(len(mod)):\n            ax.get_yticklabels()[j].set_fontstyle(\"italic\")\n            ax.get_yticklabels()[j].set_weight(\"bold\")\n            # set_color(\"#004165\")\n    fig.autofmt_xdate()\n\n    if title:\n        ax.set_title(title)\n    return ax\n</code></pre>"},{"location":"api/plotting/#modelskill.plotting.wind_rose","title":"<code>wind_rose(data, *, labels=('Measurement', 'Model'), mag_step=None, n_sectors=16, calm_threshold=None, calm_size=None, calm_text='Calm', r_step=0.1, r_max=None, legend=True, cmap1='viridis', cmap2='Greys', mag_bins=None, max_bin=None, n_dir_labels=None, secondary_dir_step_factor=2.0, figsize=(8, 8), ax=None, title=None)</code>","text":"<p>Plots a (dual) wind (wave or current) roses with calms.</p> <p>The size of the calm is determined by the primary (measurement) data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>array with 2 or 4 columns (magnitude, direction, magnitude2, direction2)</p> required <code>labels</code> <p>labels for the legend(s)</p> <code>('Measurement', 'Model')</code> <code>mag_step</code> <code>Optional[float]</code> <p>discretization for magnitude (delta_r, in radial direction )</p> <code>None</code> <code>n_sectors</code> <code>int</code> <p>number of directional sectors</p> <code>16</code> <code>calm_threshold</code> <code>Optional[float]</code> <p>minimum value for data being counted as valid (i.e. below this is calm)</p> <code>None</code> <code>calm_text</code> <code>str</code> <p>text to display in calm.</p> <code>'Calm'</code> <code>r_step</code> <code>float</code> <p>radial axis discretization. By default 0.1 i.e. every 10%.</p> <code>0.1</code> <code>r_max</code> <code>Optional[float]</code> <p>maximum radius (%) of plot, e.g. if 50% wanted then r_max=0.5</p> <code>None</code> <code>max_bin</code> <code>Optional[float]</code> <p>max value to truncate the data, e.g.,  max_bin=1.0 if hm0=1m is the desired final bin.</p> <code>None</code> <code>mag_bins</code> <code>array of floats (optional) Default = None</code> <p>force bins to array of values, e.g. when specifying non-equidistant bins.</p> <code>None</code> <code>legend</code> <code>bool</code> <p>show legend</p> <code>True</code> <code>cmap1</code> <code>string. Default= 'viridis'</code> <p>colormap for main axis</p> <code>'viridis'</code> <code>cmap2</code> <code>string. Default= 'Greys'</code> <p>colormap for secondary axis</p> <code>'Greys'</code> <code>n_dir_labels</code> <code>int. Default= 4</code> <p>number of labels in the polar plot, choose between 4, 8 or 16, default is to use the same as n_sectors</p> <code>None</code> <code>secondary_dir_step_factor</code> <code>float. Default= 2.0</code> <p>reduce width of secondary axis by this factor</p> <code>2.0</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>figure size</p> <code>(8, 8)</code> <code>ax</code> <p>Matplotlib axis to plot on defined as polar, it can be done using \"subplot_kw = dict(projection = 'polar')\". Default = None, new axis created.</p> <code>None</code> <code>title</code> <p>title of the plot</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Matplotlib axis with the plot</p> Source code in <code>modelskill/plotting/_wind_rose.py</code> <pre><code>def wind_rose(\n    data,\n    *,\n    labels=(\"Measurement\", \"Model\"),\n    mag_step: Optional[float] = None,\n    n_sectors: int = 16,\n    calm_threshold: Optional[float] = None,  # TODO rename to vmin?\n    calm_size: Optional[float] = None,\n    calm_text: str = \"Calm\",\n    r_step: float = 0.1,\n    r_max: Optional[float] = None,\n    legend: bool = True,\n    cmap1: str = \"viridis\",\n    cmap2: str = \"Greys\",\n    mag_bins: Optional[List[float]] = None,\n    max_bin: Optional[float] = None,  # TODO rename to vmax?\n    n_dir_labels: Optional[int] = None,\n    secondary_dir_step_factor: float = 2.0,\n    figsize: Tuple[float, float] = (8, 8),\n    ax=None,\n    title=None,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"Plots a (dual) wind (wave or current) roses with calms.\n\n    The size of the calm is determined by the primary (measurement) data.\n\n    Parameters\n    ----------\n    data: array-like\n        array with 2 or 4 columns (magnitude, direction, magnitude2, direction2)\n    labels: tuple of strings. Default= (\"Measurement\", \"Model\")\n        labels for the legend(s)\n    mag_step: float, (optional) Default= None\n        discretization for magnitude (delta_r, in radial direction )\n    n_sectors: int (optional) Default= 16\n        number of directional sectors\n    calm_threshold: float (optional) Default= None (auto calculated)\n        minimum value for data being counted as valid (i.e. below this is calm)\n    calm_text: str (optional) Default: 'Calm'\n        text to display in calm.\n    r_step: float (optional) Default= 0.1\n        radial axis discretization. By default 0.1 i.e. every 10%.\n    r_max: float (optional) Default= None\n        maximum radius (%) of plot, e.g. if 50% wanted then r_max=0.5\n    max_bin:  float (optional) Default= None\n        max value to truncate the data, e.g.,  max_bin=1.0 if hm0=1m is the desired final bin.\n    mag_bins : array of floats (optional) Default = None\n        force bins to array of values, e.g. when specifying non-equidistant bins.\n    legend: boolean. Default= True\n        show legend\n    cmap1 : string. Default= 'viridis'\n        colormap for main axis\n    cmap2 : string. Default= 'Greys'\n        colormap for secondary axis\n    n_dir_labels : int. Default= 4\n        number of labels in the polar plot, choose between 4, 8 or 16, default is to use the same as n_sectors\n    secondary_dir_step_factor : float. Default= 2.0\n        reduce width of secondary axis by this factor\n    figsize: tuple(float,float)\n        figure size\n    ax: Matplotlib axis Default= None\n        Matplotlib axis to plot on defined as polar, it can be done using \"subplot_kw = dict(projection = 'polar')\". Default = None, new axis created.\n    title: str Default= None\n        title of the plot\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        Matplotlib axis with the plot\n    \"\"\"\n    if hasattr(data, \"to_numpy\"):\n        data = data.to_numpy()\n\n    # check that data is array_like\n    assert hasattr(data, \"__array__\"), \"data must be array_like\"\n\n    data_1 = data[:, 0:2]  # primary magnitude and direction\n    magmax = data_1[:, 0].max()\n\n    ncols = data.shape[1]\n    assert ncols in [2, 4], \"data must have 2 or 4 columns\"\n    dual = ncols == 4\n\n    if dual:\n        data_2 = data[:, 2:4]  # secondary magnitude and direction\n        magmax = max(magmax, data_2[:, 0].max())\n        assert len(labels) == 2, \"labels must have 2 elements\"\n\n    # magnitude bins\n    ui, vmin, vmax = pretty_intervals(\n        magmax,\n        mag_bins,\n        mag_step,\n        calm_threshold,\n        max_bin,\n    )\n\n    dir_step = 360 // n_sectors\n\n    if n_dir_labels is None:\n        if n_sectors in (4, 8, 16):\n            n_dir_labels = n_sectors\n        else:\n            # Directional labels are not identical to the number of sectors, use a sane default\n            n_dir_labels = 16\n\n    dh = _dirhist2d(data_1, ui=ui, dir_step=dir_step)\n    calm = dh.calm\n\n    if dual:\n        assert len(data_1) == len(data_2), \"data_1 and data_2 must have same length\"\n        dh2 = _dirhist2d(data_2, ui=ui, dir_step=dir_step)\n        assert dh.density.shape == dh2.density.shape\n\n    ri, rmax = _calc_radial_ticks(counts=dh.density, step=r_step, stop=r_max)\n\n    # Resize calm\n    # TODO this overwrites the calm value calculated above\n    if calm_size is not None:\n        calm = calm_size\n\n    cmap = _get_cmap(cmap1)\n\n    if ax is None:\n        _, ax = plt.subplots(figsize=figsize, subplot_kw=dict(projection=\"polar\"))\n\n    ax.set_title(title)\n    ax.set_theta_zero_location(\"N\")\n    ax.set_theta_direction(-1)\n\n    dir_labels = directional_labels(n_dir_labels)\n    grid = np.linspace(0, 360, n_dir_labels + 1)[:-1]\n    ax.set_thetagrids(grid, dir_labels)\n\n    # ax.tick_params(pad=-24)\n\n    ax.set_ylim(0, calm + rmax)\n    ax.set_yticks(ri + calm)\n    tick_labels = [f\"{tick * 100 :.0f}%\" for tick in ri]\n    ax.set_yticklabels(tick_labels)\n    ax.set_rlabel_position(5)\n\n    if vmin &gt; 0:\n        _add_calms_to_ax(ax, threshold=calm, text=calm_text)\n\n    # primary histogram (model)\n    p = _create_patch(\n        thetac=dh.dir_centers,\n        dir_step=dir_step,\n        calm=calm,\n        ui=ui,\n        counts=dh.density,\n        cmap=cmap,\n        vmax=vmax,\n    )\n    ax.add_collection(p)\n\n    if legend:\n        _add_legend_to_ax(\n            ax,\n            cmap=cmap,\n            vmax=vmax,\n            ui=ui,\n            calm=calm,\n            counts=dh.density,\n            label=labels[0],\n            primary=True,\n            dual=dual,\n        )\n\n    if dual:\n        # add second histogram (observation)\n        cmap = _get_cmap(cmap2)\n\n        # TODO should this be calm2?\n        p = _create_patch(\n            thetac=dh.dir_centers,\n            dir_step=dir_step,\n            calm=calm,\n            ui=ui,\n            counts=dh2.density,\n            cmap=cmap,\n            vmax=vmax,\n            dir_step_factor=secondary_dir_step_factor,\n        )\n        ax.add_collection(p)\n\n        if legend:\n            _add_legend_to_ax(\n                ax,\n                cmap=cmap,\n                vmax=vmax,\n                ui=ui,\n                calm=dh2.calm,\n                counts=dh2.density,\n                label=labels[1],\n                primary=False,\n                dual=dual,\n            )\n\n    return ax\n</code></pre>"},{"location":"api/quantity/","title":"Quantity","text":""},{"location":"api/quantity/#modelskill.quantity.Quantity","title":"<code>modelskill.quantity.Quantity</code>  <code>dataclass</code>","text":"<p>Quantity of data</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the quantity</p> required <code>unit</code> <code>str</code> <p>Unit of the quantity</p> required <code>is_directional</code> <code>bool</code> <p>Whether the quantity is directional (e.g. Wind Direction), by default False</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wl = Quantity(name=\"Water Level\", unit=\"meter\")\n&gt;&gt;&gt; wl\nQuantity(name='Water Level', unit='meter')\n&gt;&gt;&gt; wl.name\n'Water Level'\n&gt;&gt;&gt; wl.unit\n'meter'\n&gt;&gt;&gt; wl.is_compatible(wl)\nTrue\n&gt;&gt;&gt; ws = Quantity(name=\"Wind Direction\", unit=\"degree\", is_directional=True)\n&gt;&gt;&gt; ws\nQuantity(name='Wind Direction', unit='degree', is_directional=True)\n</code></pre> Source code in <code>modelskill/quantity.py</code> <pre><code>@dataclass(frozen=True)\nclass Quantity:\n    \"\"\"Quantity of data\n\n    Parameters\n    ----------\n    name : str\n        Name of the quantity\n    unit : str\n        Unit of the quantity\n    is_directional : bool, optional\n        Whether the quantity is directional (e.g. Wind Direction), by default False\n\n    Examples\n    --------\n    &gt;&gt;&gt; wl = Quantity(name=\"Water Level\", unit=\"meter\")\n    &gt;&gt;&gt; wl\n    Quantity(name='Water Level', unit='meter')\n    &gt;&gt;&gt; wl.name\n    'Water Level'\n    &gt;&gt;&gt; wl.unit\n    'meter'\n    &gt;&gt;&gt; wl.is_compatible(wl)\n    True\n    &gt;&gt;&gt; ws = Quantity(name=\"Wind Direction\", unit=\"degree\", is_directional=True)\n    &gt;&gt;&gt; ws\n    Quantity(name='Wind Direction', unit='degree', is_directional=True)\n    \"\"\"\n\n    name: str\n    unit: str\n    is_directional: bool = False\n\n    def __str__(self):\n        return f\"{self.name} [{self.unit}]\"\n\n    def __repr__(self):\n        if self.is_directional:\n            return (\n                f\"Quantity(name='{self.name}', unit='{self.unit}', is_directional=True)\"\n            )\n        else:\n            # hide is_directional if False to avoid clutter\n            return f\"Quantity(name='{self.name}', unit='{self.unit}')\"\n\n    def is_compatible(self, other) -&gt; bool:\n        \"\"\"Check if the quantity is compatible with another quantity\n\n        Examples\n        --------\n        &gt;&gt;&gt; wl = Quantity(name=\"Water Level\", unit=\"meter\")\n        &gt;&gt;&gt; ws = Quantity(name=\"Wind Speed\", unit=\"meter per second\")\n        &gt;&gt;&gt; wl.is_compatible(ws)\n        False\n        &gt;&gt;&gt; uq = Quantity(name=\"Undefined\", unit=\"Undefined\")\n        &gt;&gt;&gt; wl.is_compatible(uq)\n        True\n        \"\"\"\n\n        if self == other:\n            return True\n\n        if (self.name == \"Undefined\") or (other.name == \"Undefined\"):\n            return True\n\n        return False\n\n    @staticmethod\n    def undefined() -&gt; \"Quantity\":\n        return Quantity(name=\"\", unit=\"\")\n\n    def to_dict(self) -&gt; Dict[str, str]:\n        return {\"name\": self.name, \"unit\": self.unit}\n\n    @staticmethod\n    def from_cf_attrs(attrs: Mapping[str, str]) -&gt; \"Quantity\":\n        \"\"\"Create a Quantity from a CF compliant attributes dictionary\n\n        If units is \"degree\", \"degrees\" or \"Degree true\", the quantity is assumed\n        to be directional. Based on https://codes.ecmwf.int/grib/param-db/ and\n        https://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html\n\n        Parameters\n        ----------\n        attrs : Mapping[str, str]\n            Attributes dictionary\n\n        Examples\n        --------\n        &gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Water Level', 'units': 'meter'})\n        Quantity(name='Water Level', unit='meter')\n        &gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Wind direction', 'units': 'degree'})\n        Quantity(name='Wind direction', unit='degree', is_directional=True)\n\n        \"\"\"\n        quantity = Quantity.undefined()\n        if long_name := attrs.get(\"long_name\"):\n            if units := attrs.get(\"units\"):\n                is_directional = units in [\"degree\", \"degrees\", \"Degree true\"]\n                quantity = Quantity(\n                    name=long_name,\n                    unit=units,\n                    is_directional=is_directional,\n                )\n        return quantity\n\n    @staticmethod\n    def from_mikeio_iteminfo(iteminfo: mikeio.ItemInfo) -&gt; \"Quantity\":\n        \"\"\"Create a Quantity from mikeio ItemInfo\n\n        If the unit is \"degree\", the quantity is assumed to be directional.\n        \"\"\"\n\n        unit = iteminfo.unit.short_name\n        is_directional = unit == \"degree\"\n        return Quantity(\n            name=repr(iteminfo.type), unit=unit, is_directional=is_directional\n        )\n\n    @staticmethod\n    def from_mikeio_eum_name(type_name: str) -&gt; \"Quantity\":\n        \"\"\"Create a Quantity from a name recognized by mikeio\n\n        Parameters\n        ----------\n        type_name : str\n            Name of the quantity\n\n        Examples\n        --------\n        &gt;&gt;&gt; Quantity.from_mikeio_eum_name(\"Water Level\")\n        Quantity(name='Water Level', unit='meter')\n        \"\"\"\n        try:\n            etype = mikeio.EUMType[type_name]\n        except KeyError:\n            name_underscore = type_name.replace(\" \", \"_\")\n            try:\n                etype = mikeio.EUMType[name_underscore]\n            except KeyError:\n                raise ValueError(\n                    f\"{type_name=} is not recognized as a known type. Please create a Quantity(name='{type_name}' unit='&lt;FILL IN UNIT&gt;')\"\n                )\n        unit = etype.units[0].name\n        is_directional = unit == \"degree\"\n        warnings.warn(f\"{unit=} was automatically set for {type_name=}\")\n        return Quantity(name=type_name, unit=unit, is_directional=is_directional)\n</code></pre>"},{"location":"api/quantity/#modelskill.quantity.Quantity.from_cf_attrs","title":"<code>from_cf_attrs(attrs)</code>  <code>staticmethod</code>","text":"<p>Create a Quantity from a CF compliant attributes dictionary</p> <p>If units is \"degree\", \"degrees\" or \"Degree true\", the quantity is assumed to be directional. Based on https://codes.ecmwf.int/grib/param-db/ and https://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html</p> <p>Parameters:</p> Name Type Description Default <code>attrs</code> <code>Mapping[str, str]</code> <p>Attributes dictionary</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Water Level', 'units': 'meter'})\nQuantity(name='Water Level', unit='meter')\n&gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Wind direction', 'units': 'degree'})\nQuantity(name='Wind direction', unit='degree', is_directional=True)\n</code></pre> Source code in <code>modelskill/quantity.py</code> <pre><code>@staticmethod\ndef from_cf_attrs(attrs: Mapping[str, str]) -&gt; \"Quantity\":\n    \"\"\"Create a Quantity from a CF compliant attributes dictionary\n\n    If units is \"degree\", \"degrees\" or \"Degree true\", the quantity is assumed\n    to be directional. Based on https://codes.ecmwf.int/grib/param-db/ and\n    https://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html\n\n    Parameters\n    ----------\n    attrs : Mapping[str, str]\n        Attributes dictionary\n\n    Examples\n    --------\n    &gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Water Level', 'units': 'meter'})\n    Quantity(name='Water Level', unit='meter')\n    &gt;&gt;&gt; Quantity.from_cf_attrs({'long_name': 'Wind direction', 'units': 'degree'})\n    Quantity(name='Wind direction', unit='degree', is_directional=True)\n\n    \"\"\"\n    quantity = Quantity.undefined()\n    if long_name := attrs.get(\"long_name\"):\n        if units := attrs.get(\"units\"):\n            is_directional = units in [\"degree\", \"degrees\", \"Degree true\"]\n            quantity = Quantity(\n                name=long_name,\n                unit=units,\n                is_directional=is_directional,\n            )\n    return quantity\n</code></pre>"},{"location":"api/quantity/#modelskill.quantity.Quantity.from_mikeio_eum_name","title":"<code>from_mikeio_eum_name(type_name)</code>  <code>staticmethod</code>","text":"<p>Create a Quantity from a name recognized by mikeio</p> <p>Parameters:</p> Name Type Description Default <code>type_name</code> <code>str</code> <p>Name of the quantity</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; Quantity.from_mikeio_eum_name(\"Water Level\")\nQuantity(name='Water Level', unit='meter')\n</code></pre> Source code in <code>modelskill/quantity.py</code> <pre><code>@staticmethod\ndef from_mikeio_eum_name(type_name: str) -&gt; \"Quantity\":\n    \"\"\"Create a Quantity from a name recognized by mikeio\n\n    Parameters\n    ----------\n    type_name : str\n        Name of the quantity\n\n    Examples\n    --------\n    &gt;&gt;&gt; Quantity.from_mikeio_eum_name(\"Water Level\")\n    Quantity(name='Water Level', unit='meter')\n    \"\"\"\n    try:\n        etype = mikeio.EUMType[type_name]\n    except KeyError:\n        name_underscore = type_name.replace(\" \", \"_\")\n        try:\n            etype = mikeio.EUMType[name_underscore]\n        except KeyError:\n            raise ValueError(\n                f\"{type_name=} is not recognized as a known type. Please create a Quantity(name='{type_name}' unit='&lt;FILL IN UNIT&gt;')\"\n            )\n    unit = etype.units[0].name\n    is_directional = unit == \"degree\"\n    warnings.warn(f\"{unit=} was automatically set for {type_name=}\")\n    return Quantity(name=type_name, unit=unit, is_directional=is_directional)\n</code></pre>"},{"location":"api/quantity/#modelskill.quantity.Quantity.from_mikeio_iteminfo","title":"<code>from_mikeio_iteminfo(iteminfo)</code>  <code>staticmethod</code>","text":"<p>Create a Quantity from mikeio ItemInfo</p> <p>If the unit is \"degree\", the quantity is assumed to be directional.</p> Source code in <code>modelskill/quantity.py</code> <pre><code>@staticmethod\ndef from_mikeio_iteminfo(iteminfo: mikeio.ItemInfo) -&gt; \"Quantity\":\n    \"\"\"Create a Quantity from mikeio ItemInfo\n\n    If the unit is \"degree\", the quantity is assumed to be directional.\n    \"\"\"\n\n    unit = iteminfo.unit.short_name\n    is_directional = unit == \"degree\"\n    return Quantity(\n        name=repr(iteminfo.type), unit=unit, is_directional=is_directional\n    )\n</code></pre>"},{"location":"api/quantity/#modelskill.quantity.Quantity.is_compatible","title":"<code>is_compatible(other)</code>","text":"<p>Check if the quantity is compatible with another quantity</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wl = Quantity(name=\"Water Level\", unit=\"meter\")\n&gt;&gt;&gt; ws = Quantity(name=\"Wind Speed\", unit=\"meter per second\")\n&gt;&gt;&gt; wl.is_compatible(ws)\nFalse\n&gt;&gt;&gt; uq = Quantity(name=\"Undefined\", unit=\"Undefined\")\n&gt;&gt;&gt; wl.is_compatible(uq)\nTrue\n</code></pre> Source code in <code>modelskill/quantity.py</code> <pre><code>def is_compatible(self, other) -&gt; bool:\n    \"\"\"Check if the quantity is compatible with another quantity\n\n    Examples\n    --------\n    &gt;&gt;&gt; wl = Quantity(name=\"Water Level\", unit=\"meter\")\n    &gt;&gt;&gt; ws = Quantity(name=\"Wind Speed\", unit=\"meter per second\")\n    &gt;&gt;&gt; wl.is_compatible(ws)\n    False\n    &gt;&gt;&gt; uq = Quantity(name=\"Undefined\", unit=\"Undefined\")\n    &gt;&gt;&gt; wl.is_compatible(uq)\n    True\n    \"\"\"\n\n    if self == other:\n        return True\n\n    if (self.name == \"Undefined\") or (other.name == \"Undefined\"):\n        return True\n\n    return False\n</code></pre>"},{"location":"api/settings/","title":"Settings","text":""},{"location":"api/settings/#modelskill.settings","title":"<code>modelskill.settings</code>","text":"<p>The settings module holds package-wide configurables and provides a uniform API for working with them.</p> <p>This module is heavily inspired by pandas config module</p>"},{"location":"api/settings/#modelskill.settings--overview","title":"Overview","text":"<p>This module supports the following requirements:</p> <ul> <li>options are referenced using keys in dot.notation, e.g. \"x.y.option - z\".</li> <li>keys are case-insensitive.</li> <li>functions should accept partial/regex keys, when unambiguous.</li> <li>options can be registered by modules at import time.</li> <li>options have a default value, and (optionally) a description and   validation function associated with them.</li> <li>options can be reset to their default value.</li> <li>all option can be reset to their default value at once.</li> <li>all options in a certain sub - namespace can be reset at once.</li> <li>the user can set / get / reset or ask for the description of an option.</li> <li>a developer can register an option.</li> </ul>"},{"location":"api/settings/#modelskill.settings--implementation","title":"Implementation","text":"<ul> <li>Data is stored using nested dictionaries, and should be accessed   through the provided API.</li> <li>\"Registered options\" have metadata associated   with them, which are stored in auxiliary dictionaries keyed on the   fully-qualified key, e.g. \"x.y.z.option\".</li> </ul>"},{"location":"api/settings/#modelskill.settings.OptionError","title":"<code>OptionError</code>","text":"<p>             Bases: <code>AttributeError</code>, <code>KeyError</code></p> <p>Error in options handling, e.g. unknown option</p> Source code in <code>modelskill/settings.py</code> <pre><code>class OptionError(AttributeError, KeyError):\n    \"Error in options handling, e.g. unknown option\"\n    pass\n</code></pre>"},{"location":"api/settings/#modelskill.settings.OptionsContainer","title":"<code>OptionsContainer</code>","text":"<p>provide attribute-style access to a nested dict</p> Source code in <code>modelskill/settings.py</code> <pre><code>class OptionsContainer:\n    \"\"\"provide attribute-style access to a nested dict\"\"\"\n\n    def __init__(self, d: Dict[str, Any], prefix: str = \"\") -&gt; None:\n        object.__setattr__(self, \"d\", d)\n        object.__setattr__(self, \"prefix\", prefix)\n\n    def __setattr__(self, key: str, val: Any) -&gt; None:\n        prefix = object.__getattribute__(self, \"prefix\")\n        if prefix:\n            prefix += \".\"\n        prefix += key\n        # you can't set new keys\n        # can you can't overwrite subtrees\n        if key in self.d and not isinstance(self.d[key], dict):\n            _set_option(prefix, val)\n        else:\n            raise OptionError(\"You can only set the value of existing options\")\n\n    def __getattr__(self, key: str):\n        prefix = object.__getattribute__(self, \"prefix\")\n        if prefix:\n            prefix += \".\"\n        prefix += key\n        try:\n            v = object.__getattribute__(self, \"d\")[key]\n        except KeyError as err:\n            raise OptionError(f\"No such option: {key}\") from err\n        if isinstance(v, dict):\n            return OptionsContainer(v, prefix)\n        else:\n            return _get_option(prefix)\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"Return options as dictionary with full-name keys\"\"\"\n        return _option_to_dict(self.prefix)\n\n    # def search(self, pat: str = \"\") -&gt; List[str]:\n    #     keys = _select_options(f\"{self.prefix}*{pat}\")\n    #     return list(keys)\n\n    def __repr__(self) -&gt; str:\n        return _describe_option_short(self.prefix, False) or \"\"\n\n    def __dir__(self) -&gt; Iterable[str]:\n        return list(self.d.keys())\n</code></pre>"},{"location":"api/settings/#modelskill.settings.OptionsContainer.to_dict","title":"<code>to_dict()</code>","text":"<p>Return options as dictionary with full-name keys</p> Source code in <code>modelskill/settings.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"Return options as dictionary with full-name keys\"\"\"\n    return _option_to_dict(self.prefix)\n</code></pre>"},{"location":"api/settings/#modelskill.settings.load_style","title":"<code>load_style(name)</code>","text":"<p>Load a number of options from a named style.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the predefined style to load. Available styles are: 'MOOD': Resembling the plots of the www.metocean-on-demand.com data portal.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If a named style is not found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.load_style('MOOD')\n</code></pre> Source code in <code>modelskill/settings.py</code> <pre><code>def load_style(name: str) -&gt; None:\n    \"\"\"Load a number of options from a named style.\n\n    Parameters\n    ----------\n    name : str\n        Name of the predefined style to load. Available styles are:\n        'MOOD': Resembling the plots of the www.metocean-on-demand.com data portal.\n\n    Raises\n    ------\n    KeyError\n        If a named style is not found.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; ms.load_style('MOOD')\n    \"\"\"\n\n    lname = name.lower()\n\n    # The number of folders to search can be expanded in the future\n    path = Path(__file__).parent / \"styles\"\n    NAMED_STYLES = {x.stem: x for x in path.glob(\"*.yml\")}\n\n    if lname not in NAMED_STYLES:\n        raise KeyError(\n            f\"Style '{name}' not found. Choose from {list(NAMED_STYLES.keys())}\"\n        )\n\n    style_path = NAMED_STYLES[lname]\n\n    with open(style_path, encoding=\"utf-8\") as f:\n        contents = f.read()\n        d = yaml.load(contents, Loader=yaml.FullLoader)\n\n    set_option(d)\n</code></pre>"},{"location":"api/settings/#modelskill.settings.register_option","title":"<code>register_option(key, defval, doc='', validator=None)</code>","text":"<p>Register an option in the package-wide modelskill settingss object</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Fully-qualified key, e.g. \"x.y.option - z\".</p> required <code>defval</code> <code>object</code> <p>Default value of the option.</p> required <code>doc</code> <code>str</code> <p>Description of the option.</p> <code>''</code> <code>validator</code> <code>Callable</code> <p>Function of a single argument, should raise <code>ValueError</code> if called with a value which is not a legal value for the option.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError if `validator` is specified and `defval` is not a valid value.</code> Source code in <code>modelskill/settings.py</code> <pre><code>def register_option(\n    key: str,\n    defval: object,\n    doc: str = \"\",\n    validator: Optional[Callable[[object], Any]] = None,\n    # cb: Optional[Callable[[str], Any]] = None,\n) -&gt; None:\n    \"\"\"\n    Register an option in the package-wide modelskill settingss object\n\n    Parameters\n    ----------\n    key : str\n        Fully-qualified key, e.g. \"x.y.option - z\".\n    defval : object\n        Default value of the option.\n    doc : str\n        Description of the option.\n    validator : Callable, optional\n        Function of a single argument, should raise `ValueError` if\n        called with a value which is not a legal value for the option.\n\n    Raises\n    ------\n    ValueError if `validator` is specified and `defval` is not a valid value.\n    \"\"\"\n    import keyword\n    import tokenize\n\n    key = key.lower()\n\n    if key in _registered_options:\n        raise OptionError(f\"Option '{key}' has already been registered\")\n    # if key in _reserved_keys:\n    #     raise OptionError(f\"Option '{key}' is a reserved key\")\n\n    # the default value should be legal\n    if validator:\n        validator(defval)\n\n    # walk the nested dict, creating dicts as needed along the path\n    path = key.split(\".\")\n\n    for k in path:\n        if not re.match(\"^\" + tokenize.Name + \"$\", k):\n            raise ValueError(f\"{k} is not a valid identifier\")\n        if keyword.iskeyword(k):\n            raise ValueError(f\"{k} is a python keyword\")\n\n    cursor = _global_settings\n    msg = \"Path prefix to option '{option}' is already an option\"\n\n    for i, p in enumerate(path[:-1]):\n        if not isinstance(cursor, dict):\n            raise OptionError(msg.format(option=\".\".join(path[:i])))\n        if p not in cursor:\n            cursor[p] = {}\n        cursor = cursor[p]\n\n    if not isinstance(cursor, dict):\n        raise OptionError(msg.format(option=\".\".join(path[:-1])))\n\n    cursor[path[-1]] = defval  # initialize\n\n    # save the option metadata\n    _registered_options[key] = RegisteredOption(\n        key=key, defval=defval, doc=doc, validator=validator  # , cb=cb\n    )\n</code></pre>"},{"location":"api/skill/","title":"Skill","text":""},{"location":"api/skill/#modelskill.skill.SkillTable","title":"<code>modelskill.skill.SkillTable</code>","text":"<p>SkillTable object for visualization and analysis returned by the comparer's <code>skill</code> method. The object wraps the pd.DataFrame class which can be accessed from the attribute <code>data</code>.</p> <p>The columns are assumed to be metrics and data for a single metric can be accessed by e.g. <code>s.rmse</code> or <code>s[\"rmse\"]</code>. The resulting object can be used for plotting.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()\n&gt;&gt;&gt; s.mod_names\n['SW_1', 'SW_2']\n&gt;&gt;&gt; s.style()\n&gt;&gt;&gt; s.sel(model='SW_1').style()\n&gt;&gt;&gt; s.rmse.plot.bar()\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>class SkillTable:\n    \"\"\"\n    SkillTable object for visualization and analysis returned by\n    the comparer's `skill` method. The object wraps the pd.DataFrame\n    class which can be accessed from the attribute `data`.\n\n    The columns are assumed to be metrics and data for a single metric\n    can be accessed by e.g. `s.rmse` or `s[\"rmse\"]`. The resulting object\n    can be used for plotting.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()\n    &gt;&gt;&gt; s.mod_names\n    ['SW_1', 'SW_2']\n    &gt;&gt;&gt; s.style()\n    &gt;&gt;&gt; s.sel(model='SW_1').style()\n    &gt;&gt;&gt; s.rmse.plot.bar()\n    \"\"\"\n\n    _large_is_best_metrics = [\n        \"cc\",\n        \"corrcoef\",\n        \"r2\",\n        \"spearmanr\",\n        \"rho\",\n        \"nash_sutcliffe_efficiency\",\n        \"nse\",\n    ]\n    _small_is_best_metrics = [\n        \"mae\",\n        \"mape\",\n        \"mean_absolute_error\",\n        \"mean_absolute_percentage_error\",\n        \"rmse\",\n        \"root_mean_squared_error\",\n        \"urmse\",\n        \"scatter_index\",\n        \"si\",\n        \"mef\",\n        \"model_efficiency_factor\",\n    ]\n    _one_is_best_metrics = [\"lin_slope\"]\n    _zero_is_best_metrics = [\"bias\"]\n\n    def __init__(self, data: pd.DataFrame):\n        self.data: pd.DataFrame = (\n            data if isinstance(data, pd.DataFrame) else data.to_dataframe()\n        )\n        self.plot = DeprecatedSkillPlotter(self)  # TODO remove in v1.1\n\n    # TODO: remove?\n    # data without xy columns\n    @property\n    def _df(self) -&gt; pd.DataFrame:\n        return self.data.drop(columns=[\"x\", \"y\"], errors=\"ignore\")\n\n    @property\n    def metrics(self) -&gt; Collection[str]:\n        \"\"\"List of metrics (columns) in the SkillTable\"\"\"\n        return list(self._df.columns)\n\n    # TODO: remove?\n    def __len__(self) -&gt; int:\n        return len(self._df)\n\n    def to_dataframe(self, drop_xy=True) -&gt; pd.DataFrame:\n        if drop_xy:\n            return self.data.drop(columns=[\"x\", \"y\"], errors=\"ignore\")\n        else:\n            return self.data.copy()\n\n    def to_geodataframe(self, crs=\"EPSG:4326\") -&gt; gpd.GeoDataFrame:\n        import geopandas as gpd\n\n        assert \"x\" in self.data.columns\n        assert \"y\" in self.data.columns\n\n        df = self.to_dataframe(drop_xy=False)\n\n        gdf = gpd.GeoDataFrame(\n            df,\n            geometry=gpd.points_from_xy(df.x, df.y),\n            crs=crs,\n        )\n\n        return gdf\n\n    def __repr__(self):\n        return repr(self._df)\n\n    def _repr_html_(self):\n        return self._df._repr_html_()\n\n    @overload\n    def __getitem__(self, key: Hashable | int) -&gt; SkillArray:\n        ...\n\n    @overload\n    def __getitem__(self, key: Iterable[Hashable]) -&gt; SkillTable:\n        ...\n\n    def __getitem__(self, key) -&gt; SkillArray | SkillTable:\n        if isinstance(key, int):\n            key = list(self.data.columns)[key]\n        result = self.data[key]\n        if isinstance(result, pd.Series):\n            # I don't think this should be necessary, but in some cases the input doesn't contain x and y\n            if \"x\" in self.data.columns and \"y\" in self.data.columns:\n                cols = [\"x\", \"y\", key]\n                return SkillArray(self.data[cols])\n            else:\n                return SkillArray(result.to_frame())\n        elif isinstance(result, pd.DataFrame):\n            return SkillTable(result)\n        else:\n            return result\n\n    def __getattr__(self, item):\n        if item in self.data.columns:\n            return self[item]  # Redirects to __getitem__\n\n        # For other attributes, return them directly\n        return getattr(self.data, item)\n\n    # TODO\n    @property\n    def loc(self, *args, **kwargs):\n        return self._df.loc(*args, **kwargs)\n\n    # TODO: remove?\n    def sort_index(self, *args, **kwargs):\n        \"\"\"Wrapping pd.DataFrame.sort_index() for e.g. sorting by observation\"\"\"\n        return self.__class__(self._df.sort_index(*args, **kwargs))\n\n    # TODO: remove?\n    def swaplevel(self, *args, **kwargs):\n        \"\"\"Wrapping pd.DataFrame.swaplevel() for e.g. swapping model and observation\"\"\"\n        return self.__class__(self._df.swaplevel(*args, **kwargs))\n\n    @property\n    def mod_names(self) -&gt; list[str]:\n        \"\"\"List of model names (in index)\"\"\"\n        return self._get_index_level_by_name(\"model\")\n\n    @property\n    def obs_names(self) -&gt; list[str]:\n        \"\"\"List of observation names (in index)\"\"\"\n        return self._get_index_level_by_name(\"observation\")\n\n    @property\n    def var_names(self) -&gt; list[str]:\n        \"\"\"List of variable names (in index)\"\"\"\n        return self._get_index_level_by_name(\"variable\")\n\n    # TODO what does this method actually do?\n    def _get_index_level_by_name(self, name):\n        index = self._df.index\n        if name in index.names:\n            level = index.names.index(name)\n            return index.get_level_values(level).unique()\n        else:\n            return []\n            # raise ValueError(f\"name {name} not in index {list(self.index.names)}\")\n\n    def query(self, query: str) -&gt; SkillTable:\n        \"\"\"Select a subset of the SkillTable by a query string\n\n        wrapping pd.DataFrame.query()\n\n        Parameters\n        ----------\n        query : str\n            string supported by pd.DataFrame.query()\n\n        Returns\n        -------\n        SkillTable\n            A subset of the original SkillTable\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()\n        &gt;&gt;&gt; s_above_0p3 = s.query(\"rmse&gt;0.3\")\n        \"\"\"\n        return self.__class__(self._df.query(query))\n\n    def sel(self, query=None, reduce_index=True, **kwargs):\n        \"\"\"Select a subset of the SkillTable by a query,\n           (part of) the index, or specific columns\n\n        Parameters\n        ----------\n        reduce_index : bool, optional\n            Should unnecessary levels of the index be removed after subsetting?\n            Removed levels will stay as columns. By default True\n        **kwargs : dict, optional\n            Concrete keys depend on the index names of the SkillTable\n            (from the \"by\" argument in cc.skill() method)\n            \"model\"=... to select specific models,\n            \"observation\"=... to select specific observations\n\n        Returns\n        -------\n        SkillTable\n            A subset of the original SkillTable\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()\n        &gt;&gt;&gt; s_SW1 = s.sel(model = \"SW_1\")\n        &gt;&gt;&gt; s2 = s.sel(observation = [\"EPL\", \"HKNA\"])\n        \"\"\"\n        if query is not None:\n            warnings.warn(\n                \"s.sel(query=...) is deprecated, use s.query(...) instead\",\n                FutureWarning,\n            )\n            return self.query(query)\n\n        for key, value in kwargs.items():\n            if key == \"metrics\" or key == \"columns\":\n                warnings.warn(\n                    f\"s.sel({key}=...) is deprecated, use getitem s[...] instead\",\n                    FutureWarning,\n                )\n                return self[value]\n\n        # df = self._df\n        df = self.to_dataframe(drop_xy=False)\n\n        for key, value in kwargs.items():\n            if key in df.index.names:\n                df = self._sel_from_index(df, key, value)\n            else:\n                raise KeyError(\n                    f\"Unknown index {key}. Valid index names are {df.index.names}\"\n                )\n\n        if isinstance(df, pd.Series):\n            return SkillArray(df)\n        if reduce_index and isinstance(df.index, pd.MultiIndex):\n            df = self._reduce_index(df)\n        return self.__class__(df)\n\n    def _sel_from_index(self, df, key, value):\n        if (not isinstance(value, str)) and isinstance(value, Iterable):\n            for i, v in enumerate(value):\n                dfi = self._sel_from_index(df, key, v)\n                if i == 0:\n                    dfout = dfi\n                else:\n                    dfout = pd.concat([dfout, dfi])\n            return dfout\n\n        if isinstance(value, int):\n            value = self._idx_to_name(key, value)\n\n        if isinstance(df.index, pd.MultiIndex):\n            df = df.xs(value, level=key, drop_level=False)\n        else:\n            df = df[df.index == value]  # .copy()\n        return df\n\n    def _idx_to_name(self, index, idx) -&gt; str:\n        \"\"\"Assumes that index is valid and idx is int\"\"\"\n        names = self._get_index_level_by_name(index)\n        n = len(names)\n        if (idx &lt; 0) or (idx &gt;= n):\n            raise KeyError(f\"Id {idx} is out of bounds for index {index} (0, {n})\")\n        return names[idx]\n\n    def _reduce_index(self, df):\n        \"\"\"Remove unnecessary levels of MultiIndex\"\"\"\n        df.index = df.index.remove_unused_levels()\n        levels_to_reset = []\n        for j, level in enumerate(df.index.levels):\n            if len(level) == 1:\n                levels_to_reset.append(j)\n        return df.reset_index(level=levels_to_reset)\n\n    def round(self, decimals=3):\n        \"\"\"Round all values in SkillTable\n\n        Parameters\n        ----------\n        decimals : int, optional\n            Number of decimal places to round to (default: 3).\n            If decimals is negative, it specifies the number of\n            positions to the left of the decimal point.\n        \"\"\"\n\n        return self.__class__(self.data.round(decimals=decimals))\n\n    def style(\n        self,\n        decimals=3,\n        metrics=None,\n        cmap=\"OrRd\",\n        show_best=True,\n        **kwargs,\n    ):\n        \"\"\"Style SkillTable with colors using pandas style\n\n        Parameters\n        ----------\n        decimals : int, optional\n            Number of decimal places to round to (default: 3).\n        metrics : str or List[str], optional\n            apply background gradient color to these columns, by default all;\n            if columns is [] then no background gradient will be applied.\n        cmap : str, optional\n            colormap of background gradient, by default \"OrRd\",\n            except \"bias\" column which will always be \"coolwarm\"\n        show_best : bool, optional\n            indicate best of each column by underline, by default True\n\n        Returns\n        -------\n        pd.Styler\n            Returns a pandas Styler object.\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()\n        &gt;&gt;&gt; s.style()\n        &gt;&gt;&gt; s.style(precision=1, metrics=\"rmse\")\n        &gt;&gt;&gt; s.style(cmap=\"Blues\", show_best=False)\n        \"\"\"\n        # identity metric columns\n        float_cols = list(self._df.select_dtypes(include=\"number\").columns)\n\n        if \"precision\" in kwargs:\n            warnings.warn(\n                FutureWarning(\n                    \"precision is deprecated, it has been renamed to decimals\"\n                )\n            )\n            decimals = kwargs[\"precision\"]\n\n        # selected columns\n        if metrics is None:\n            metrics = float_cols\n        else:\n            if isinstance(metrics, str):\n                if not metrics:\n                    metrics = []\n                else:\n                    metrics = [metrics]\n            for column in metrics:\n                if column not in float_cols:\n                    raise ValueError(\n                        f\"Invalid column name {column} (must be one of {float_cols})\"\n                    )\n\n        sdf = self._df.style.format(precision=decimals)\n\n        # apply background gradient\n        bg_cols = list(set(metrics) &amp; set(float_cols))\n        if \"bias\" in bg_cols:\n            mm = self._df.bias.abs().max()\n            sdf = sdf.background_gradient(\n                subset=[\"bias\"], cmap=\"coolwarm\", vmin=-mm, vmax=mm\n            )\n            bg_cols.remove(\"bias\")\n        if \"lin_slope\" in bg_cols:\n            mm = (self._df.lin_slope - 1).abs().max()\n            sdf = sdf.background_gradient(\n                subset=[\"lin_slope\"], cmap=\"coolwarm\", vmin=(1 - mm), vmax=(1 + mm)\n            )\n            bg_cols.remove(\"lin_slope\")\n        if len(bg_cols) &gt; 0:\n            cols = list(set(self._small_is_best_metrics) &amp; set(bg_cols))\n            sdf = sdf.background_gradient(subset=cols, cmap=cmap)\n\n            cols = list(set(self._large_is_best_metrics) &amp; set(bg_cols))\n            cmap_r = self._reverse_colormap(cmap)\n            sdf = sdf.background_gradient(subset=cols, cmap=cmap_r)\n\n        if show_best:\n            cols = list(set(self._large_is_best_metrics) &amp; set(float_cols))\n            sdf = sdf.apply(self._style_max, subset=cols)\n            cols = list(set(self._small_is_best_metrics) &amp; set(float_cols))\n            sdf = sdf.apply(self._style_min, subset=cols)\n            cols = list(set(self._one_is_best_metrics) &amp; set(float_cols))\n            sdf = sdf.apply(self._style_one_best, subset=cols)\n            if \"bias\" in float_cols:\n                sdf = sdf.apply(self._style_abs_min, subset=[\"bias\"])\n\n        return sdf\n\n    def _reverse_colormap(self, cmap):\n        cmap_r = cmap\n        if isinstance(cmap, str):\n            if cmap[-2:] == \"_r\":\n                cmap_r = cmap_r[:-2]\n            else:\n                cmap_r = cmap + \"_r\"\n        else:\n            cmap_r = cmap.reversed()\n        return cmap_r\n\n    def _style_one_best(self, s):\n        \"\"\"Using underline-etc to highlight the best in a Series.\"\"\"\n        is_best = (s - 1.0).abs() == (s - 1.0).abs().min()\n        cell_style = (\n            \"text-decoration: underline; font-style: italic; font-weight: bold;\"\n        )\n        return [cell_style if v else \"\" for v in is_best]\n\n    def _style_abs_min(self, s):\n        \"\"\"Using underline-etc to highlight the best in a Series.\"\"\"\n        is_best = s.abs() == s.abs().min()\n        cell_style = (\n            \"text-decoration: underline; font-style: italic; font-weight: bold;\"\n        )\n        return [cell_style if v else \"\" for v in is_best]\n\n    def _style_min(self, s):\n        \"\"\"Using underline-etc to highlight the best in a Series.\"\"\"\n        cell_style = (\n            \"text-decoration: underline; font-style: italic; font-weight: bold;\"\n        )\n        return [cell_style if v else \"\" for v in (s == s.min())]\n\n    def _style_max(self, s):\n        \"\"\"Using underline-etc to highlight the best in a Series.\"\"\"\n        cell_style = (\n            \"text-decoration: underline; font-style: italic; font-weight: bold;\"\n        )\n        return [cell_style if v else \"\" for v in (s == s.max())]\n\n    # TODO: remove plot_* methods in v1.1; warnings are not needed\n    # as the refering method is also deprecated\n    def plot_line(self, **kwargs):\n        return self.plot.line(**kwargs)\n\n    def plot_bar(self, **kwargs):\n        return self.plot.bar(**kwargs)\n\n    def plot_barh(self, **kwargs):\n        return self.plot.barh(**kwargs)\n\n    def plot_grid(self, **kwargs):\n        return self.plot.grid(**kwargs)\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.metrics","title":"<code>metrics: Collection[str]</code>  <code>property</code>","text":"<p>List of metrics (columns) in the SkillTable</p>"},{"location":"api/skill/#modelskill.skill.SkillTable.mod_names","title":"<code>mod_names: list[str]</code>  <code>property</code>","text":"<p>List of model names (in index)</p>"},{"location":"api/skill/#modelskill.skill.SkillTable.obs_names","title":"<code>obs_names: list[str]</code>  <code>property</code>","text":"<p>List of observation names (in index)</p>"},{"location":"api/skill/#modelskill.skill.SkillTable.var_names","title":"<code>var_names: list[str]</code>  <code>property</code>","text":"<p>List of variable names (in index)</p>"},{"location":"api/skill/#modelskill.skill.SkillTable.query","title":"<code>query(query)</code>","text":"<p>Select a subset of the SkillTable by a query string</p> <p>wrapping pd.DataFrame.query()</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>string supported by pd.DataFrame.query()</p> required <p>Returns:</p> Type Description <code>SkillTable</code> <p>A subset of the original SkillTable</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()\n&gt;&gt;&gt; s_above_0p3 = s.query(\"rmse&gt;0.3\")\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def query(self, query: str) -&gt; SkillTable:\n    \"\"\"Select a subset of the SkillTable by a query string\n\n    wrapping pd.DataFrame.query()\n\n    Parameters\n    ----------\n    query : str\n        string supported by pd.DataFrame.query()\n\n    Returns\n    -------\n    SkillTable\n        A subset of the original SkillTable\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()\n    &gt;&gt;&gt; s_above_0p3 = s.query(\"rmse&gt;0.3\")\n    \"\"\"\n    return self.__class__(self._df.query(query))\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.round","title":"<code>round(decimals=3)</code>","text":"<p>Round all values in SkillTable</p> <p>Parameters:</p> Name Type Description Default <code>decimals</code> <code>int</code> <p>Number of decimal places to round to (default: 3). If decimals is negative, it specifies the number of positions to the left of the decimal point.</p> <code>3</code> Source code in <code>modelskill/skill.py</code> <pre><code>def round(self, decimals=3):\n    \"\"\"Round all values in SkillTable\n\n    Parameters\n    ----------\n    decimals : int, optional\n        Number of decimal places to round to (default: 3).\n        If decimals is negative, it specifies the number of\n        positions to the left of the decimal point.\n    \"\"\"\n\n    return self.__class__(self.data.round(decimals=decimals))\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.sel","title":"<code>sel(query=None, reduce_index=True, **kwargs)</code>","text":"<p>Select a subset of the SkillTable by a query,    (part of) the index, or specific columns</p> <p>Parameters:</p> Name Type Description Default <code>reduce_index</code> <code>bool</code> <p>Should unnecessary levels of the index be removed after subsetting? Removed levels will stay as columns. By default True</p> <code>True</code> <code>**kwargs</code> <code>dict</code> <p>Concrete keys depend on the index names of the SkillTable (from the \"by\" argument in cc.skill() method) \"model\"=... to select specific models, \"observation\"=... to select specific observations</p> <code>{}</code> <p>Returns:</p> Type Description <code>SkillTable</code> <p>A subset of the original SkillTable</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()\n&gt;&gt;&gt; s_SW1 = s.sel(model = \"SW_1\")\n&gt;&gt;&gt; s2 = s.sel(observation = [\"EPL\", \"HKNA\"])\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def sel(self, query=None, reduce_index=True, **kwargs):\n    \"\"\"Select a subset of the SkillTable by a query,\n       (part of) the index, or specific columns\n\n    Parameters\n    ----------\n    reduce_index : bool, optional\n        Should unnecessary levels of the index be removed after subsetting?\n        Removed levels will stay as columns. By default True\n    **kwargs : dict, optional\n        Concrete keys depend on the index names of the SkillTable\n        (from the \"by\" argument in cc.skill() method)\n        \"model\"=... to select specific models,\n        \"observation\"=... to select specific observations\n\n    Returns\n    -------\n    SkillTable\n        A subset of the original SkillTable\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()\n    &gt;&gt;&gt; s_SW1 = s.sel(model = \"SW_1\")\n    &gt;&gt;&gt; s2 = s.sel(observation = [\"EPL\", \"HKNA\"])\n    \"\"\"\n    if query is not None:\n        warnings.warn(\n            \"s.sel(query=...) is deprecated, use s.query(...) instead\",\n            FutureWarning,\n        )\n        return self.query(query)\n\n    for key, value in kwargs.items():\n        if key == \"metrics\" or key == \"columns\":\n            warnings.warn(\n                f\"s.sel({key}=...) is deprecated, use getitem s[...] instead\",\n                FutureWarning,\n            )\n            return self[value]\n\n    # df = self._df\n    df = self.to_dataframe(drop_xy=False)\n\n    for key, value in kwargs.items():\n        if key in df.index.names:\n            df = self._sel_from_index(df, key, value)\n        else:\n            raise KeyError(\n                f\"Unknown index {key}. Valid index names are {df.index.names}\"\n            )\n\n    if isinstance(df, pd.Series):\n        return SkillArray(df)\n    if reduce_index and isinstance(df.index, pd.MultiIndex):\n        df = self._reduce_index(df)\n    return self.__class__(df)\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.sort_index","title":"<code>sort_index(*args, **kwargs)</code>","text":"<p>Wrapping pd.DataFrame.sort_index() for e.g. sorting by observation</p> Source code in <code>modelskill/skill.py</code> <pre><code>def sort_index(self, *args, **kwargs):\n    \"\"\"Wrapping pd.DataFrame.sort_index() for e.g. sorting by observation\"\"\"\n    return self.__class__(self._df.sort_index(*args, **kwargs))\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.style","title":"<code>style(decimals=3, metrics=None, cmap='OrRd', show_best=True, **kwargs)</code>","text":"<p>Style SkillTable with colors using pandas style</p> <p>Parameters:</p> Name Type Description Default <code>decimals</code> <code>int</code> <p>Number of decimal places to round to (default: 3).</p> <code>3</code> <code>metrics</code> <code>str or List[str]</code> <p>apply background gradient color to these columns, by default all; if columns is [] then no background gradient will be applied.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>colormap of background gradient, by default \"OrRd\", except \"bias\" column which will always be \"coolwarm\"</p> <code>'OrRd'</code> <code>show_best</code> <code>bool</code> <p>indicate best of each column by underline, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>Styler</code> <p>Returns a pandas Styler object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()\n&gt;&gt;&gt; s.style()\n&gt;&gt;&gt; s.style(precision=1, metrics=\"rmse\")\n&gt;&gt;&gt; s.style(cmap=\"Blues\", show_best=False)\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def style(\n    self,\n    decimals=3,\n    metrics=None,\n    cmap=\"OrRd\",\n    show_best=True,\n    **kwargs,\n):\n    \"\"\"Style SkillTable with colors using pandas style\n\n    Parameters\n    ----------\n    decimals : int, optional\n        Number of decimal places to round to (default: 3).\n    metrics : str or List[str], optional\n        apply background gradient color to these columns, by default all;\n        if columns is [] then no background gradient will be applied.\n    cmap : str, optional\n        colormap of background gradient, by default \"OrRd\",\n        except \"bias\" column which will always be \"coolwarm\"\n    show_best : bool, optional\n        indicate best of each column by underline, by default True\n\n    Returns\n    -------\n    pd.Styler\n        Returns a pandas Styler object.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()\n    &gt;&gt;&gt; s.style()\n    &gt;&gt;&gt; s.style(precision=1, metrics=\"rmse\")\n    &gt;&gt;&gt; s.style(cmap=\"Blues\", show_best=False)\n    \"\"\"\n    # identity metric columns\n    float_cols = list(self._df.select_dtypes(include=\"number\").columns)\n\n    if \"precision\" in kwargs:\n        warnings.warn(\n            FutureWarning(\n                \"precision is deprecated, it has been renamed to decimals\"\n            )\n        )\n        decimals = kwargs[\"precision\"]\n\n    # selected columns\n    if metrics is None:\n        metrics = float_cols\n    else:\n        if isinstance(metrics, str):\n            if not metrics:\n                metrics = []\n            else:\n                metrics = [metrics]\n        for column in metrics:\n            if column not in float_cols:\n                raise ValueError(\n                    f\"Invalid column name {column} (must be one of {float_cols})\"\n                )\n\n    sdf = self._df.style.format(precision=decimals)\n\n    # apply background gradient\n    bg_cols = list(set(metrics) &amp; set(float_cols))\n    if \"bias\" in bg_cols:\n        mm = self._df.bias.abs().max()\n        sdf = sdf.background_gradient(\n            subset=[\"bias\"], cmap=\"coolwarm\", vmin=-mm, vmax=mm\n        )\n        bg_cols.remove(\"bias\")\n    if \"lin_slope\" in bg_cols:\n        mm = (self._df.lin_slope - 1).abs().max()\n        sdf = sdf.background_gradient(\n            subset=[\"lin_slope\"], cmap=\"coolwarm\", vmin=(1 - mm), vmax=(1 + mm)\n        )\n        bg_cols.remove(\"lin_slope\")\n    if len(bg_cols) &gt; 0:\n        cols = list(set(self._small_is_best_metrics) &amp; set(bg_cols))\n        sdf = sdf.background_gradient(subset=cols, cmap=cmap)\n\n        cols = list(set(self._large_is_best_metrics) &amp; set(bg_cols))\n        cmap_r = self._reverse_colormap(cmap)\n        sdf = sdf.background_gradient(subset=cols, cmap=cmap_r)\n\n    if show_best:\n        cols = list(set(self._large_is_best_metrics) &amp; set(float_cols))\n        sdf = sdf.apply(self._style_max, subset=cols)\n        cols = list(set(self._small_is_best_metrics) &amp; set(float_cols))\n        sdf = sdf.apply(self._style_min, subset=cols)\n        cols = list(set(self._one_is_best_metrics) &amp; set(float_cols))\n        sdf = sdf.apply(self._style_one_best, subset=cols)\n        if \"bias\" in float_cols:\n            sdf = sdf.apply(self._style_abs_min, subset=[\"bias\"])\n\n    return sdf\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillTable.swaplevel","title":"<code>swaplevel(*args, **kwargs)</code>","text":"<p>Wrapping pd.DataFrame.swaplevel() for e.g. swapping model and observation</p> Source code in <code>modelskill/skill.py</code> <pre><code>def swaplevel(self, *args, **kwargs):\n    \"\"\"Wrapping pd.DataFrame.swaplevel() for e.g. swapping model and observation\"\"\"\n    return self.__class__(self._df.swaplevel(*args, **kwargs))\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArray","title":"<code>modelskill.skill.SkillArray</code>","text":"<p>SkillArray object for visualization obtained by selecting a single metric from a SkillTable.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()   # SkillTable\n&gt;&gt;&gt; s.rmse           # SkillArray\n&gt;&gt;&gt; s.rmse.plot.line()\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>class SkillArray:\n    \"\"\"SkillArray object for visualization obtained by\n    selecting a single metric from a SkillTable.\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()   # SkillTable\n    &gt;&gt;&gt; s.rmse           # SkillArray\n    &gt;&gt;&gt; s.rmse.plot.line()\n    \"\"\"\n\n    def __init__(self, data: pd.DataFrame) -&gt; None:\n        self.data = data\n        self._ser = data.iloc[:, -1]  # last column is the metric\n        self.plot = SkillArrayPlotter(self)\n\n    def to_dataframe(self, drop_xy=True) -&gt; pd.DataFrame:\n        \"\"\"Output as pd.DataFrame\"\"\"\n        if drop_xy:\n            return self._ser.to_frame()\n        else:\n            return self.data.copy()\n\n    def __repr__(self):\n        return repr(self.to_dataframe())\n\n    def _repr_html_(self):\n        return self.to_dataframe()._repr_html_()\n\n    @property\n    def name(self):\n        \"\"\"Name of the metric\"\"\"\n        return self._ser.name\n\n    def to_geodataframe(self, crs=\"EPSG:4326\") -&gt; gpd.GeoDataFrame:\n        import geopandas as gpd\n\n        assert \"x\" in self.data.columns\n        assert \"y\" in self.data.columns\n\n        gdf = gpd.GeoDataFrame(\n            self._ser,\n            geometry=gpd.points_from_xy(self.data.x, self.data.y),\n            crs=crs,\n        )\n\n        return gdf\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArray.name","title":"<code>name</code>  <code>property</code>","text":"<p>Name of the metric</p>"},{"location":"api/skill/#modelskill.skill.SkillArray.to_dataframe","title":"<code>to_dataframe(drop_xy=True)</code>","text":"<p>Output as pd.DataFrame</p> Source code in <code>modelskill/skill.py</code> <pre><code>def to_dataframe(self, drop_xy=True) -&gt; pd.DataFrame:\n    \"\"\"Output as pd.DataFrame\"\"\"\n    if drop_xy:\n        return self._ser.to_frame()\n    else:\n        return self.data.copy()\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArrayPlotter","title":"<code>modelskill.skill.SkillArrayPlotter</code>","text":"<p>SkillArrayPlotter object for visualization of a single metric (SkillArray)</p> <p>plot.line() : line plot plot.bar() : bar chart plot.barh() : horizontal bar chart plot.grid() : colored grid</p> Source code in <code>modelskill/skill.py</code> <pre><code>class SkillArrayPlotter:\n    \"\"\"SkillArrayPlotter object for visualization of a single metric (SkillArray)\n\n    plot.line() : line plot\n    plot.bar() : bar chart\n    plot.barh() : horizontal bar chart\n    plot.grid() : colored grid\n    \"\"\"\n\n    def __init__(self, skillarray):\n        self.skillarray = skillarray\n\n    def _name_to_title_in_kwargs(self, kwargs):\n        if \"title\" not in kwargs:\n            if self.skillarray.name is not None:\n                kwargs[\"title\"] = self.skillarray.name\n\n    def _get_plot_df(self, level: int | str = 0) -&gt; pd.DataFrame:\n        ser = self.skillarray._ser\n        if isinstance(ser.index, pd.MultiIndex):\n            df = ser.unstack(level=level)\n        else:\n            df = ser.to_frame()\n        return df\n\n    # TODO hide this for now until we are certain about the API\n    # def map(self, **kwargs):\n    #     if \"model\" in self.skillarray.data.index.names:\n    #         n_models = len(self.skillarray.data.reset_index().model.unique())\n    #         if n_models &gt; 1:\n    #             raise ValueError(\n    #                 \"map() is only possible for single model skill. Use .sel(model=...) to select a single model.\"\n    #             )\n\n    #     gdf = self.skillarray.to_geodataframe()\n    #     column = self.skillarray.name\n    #     kwargs = {\"marker_kwds\": {\"radius\": 10}} | kwargs\n\n    #     return gdf.explore(column=column, **kwargs)\n\n    def line(\n        self,\n        level: int | str = 0,\n        **kwargs,\n    ):\n        \"\"\"Plot statistic as a lines using pd.DataFrame.plot.line()\n\n        Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n        Parameters\n        ----------\n        level : int or str, optional\n            level to unstack, by default 0\n        kwargs : dict, optional\n            key word arguments to be pased to pd.DataFrame.plot.line()\n            e.g. marker, title, figsize, ...\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n        &gt;&gt;&gt; s.plot.line()\n        &gt;&gt;&gt; s.plot.line(marker=\"o\", linestyle=':')\n        &gt;&gt;&gt; s.plot.line(color=['0.2', '0.4', '0.6'])\n        \"\"\"\n        df = self._get_plot_df(level=level)\n        self._name_to_title_in_kwargs(kwargs)\n        axes = df.plot.line(**kwargs)\n\n        xlabels = list(df.index)\n        nx = len(xlabels)\n\n        if not isinstance(axes, Iterable):\n            axes = [axes]\n        for ax in axes:\n            if not isinstance(df.index, pd.DatetimeIndex):\n                ax.set_xticks(np.arange(nx))\n                ax.set_xticklabels(xlabels, rotation=90)\n        return axes\n\n    def bar(self, level: int | str = 0, **kwargs):\n        \"\"\"Plot statistic as bar chart using pd.DataFrame.plot.bar()\n\n        Parameters\n        ----------\n        level : int or str, optional\n            level to unstack, by default 0\n        kwargs : dict, optional\n            key word arguments to be pased to pd.DataFrame.plot.bar()\n            e.g. color, title, figsize, ...\n\n        Returns\n        -------\n        AxesSubplot\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n        &gt;&gt;&gt; s.plot.bar()\n        &gt;&gt;&gt; s.plot.bar(level=\"observation\")\n        &gt;&gt;&gt; s.plot.bar(title=\"Root Mean Squared Error\")\n        &gt;&gt;&gt; s.plot.bar(color=[\"red\",\"blue\"])\n        \"\"\"\n        df = self._get_plot_df(level=level)\n        self._name_to_title_in_kwargs(kwargs)\n        return df.plot.bar(**kwargs)\n\n    def barh(self, level: int | str = 0, **kwargs):\n        \"\"\"Plot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n        Parameters\n        ----------\n        level : int or str, optional\n            level to unstack, by default 0\n        kwargs : dict, optional\n            key word arguments to be passed to pd.DataFrame.plot.barh()\n            e.g. color, title, figsize, ...\n\n        Returns\n        -------\n        AxesSubplot\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n        &gt;&gt;&gt; s.plot.barh()\n        &gt;&gt;&gt; s.plot.barh(level=\"observation\")\n        &gt;&gt;&gt; s.plot.barh(title=\"Root Mean Squared Error\")\n        \"\"\"\n        df = self._get_plot_df(level)\n        self._name_to_title_in_kwargs(kwargs)\n        return df.plot.barh(**kwargs)\n\n    def grid(\n        self,\n        show_numbers=True,\n        precision=3,\n        fmt=None,\n        ax=None,\n        figsize=None,\n        title=None,\n        cmap=None,\n    ):\n        \"\"\"Plot statistic as a colored grid, optionally with values in the cells.\n\n        Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n        Parameters\n        ----------\n        show_numbers : bool, optional\n            should values of the static be shown in the cells?, by default True\n            if False, a colorbar will be displayed instead\n        precision : int, optional\n            number of decimals if show_numbers, by default 3\n        fmt : str, optional\n            format string, e.g. \".0%\" to show value as percentage\n        ax : Axes, optional\n            matplotlib axes, by default None\n        figsize : Tuple(float, float), optional\n            figure size, by default None\n        title : str, optional\n            plot title, by default name of statistic\n        cmap : str, optional\n            colormap, by default \"OrRd\" (\"coolwarm\" if bias)\n\n        Returns\n        -------\n        AxesSubplot\n\n        Examples\n        --------\n        &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n        &gt;&gt;&gt; s.plot.grid()\n        &gt;&gt;&gt; s.plot.grid(show_numbers=False, cmap=\"magma\")\n        &gt;&gt;&gt; s.plot.grid(precision=1)\n        &gt;&gt;&gt; s.plot.grid(fmt=\".0%\", title=\"Root Mean Squared Error\")\n        \"\"\"\n\n        s = self.skillarray\n        ser = s._ser\n\n        errors = _validate_multi_index(ser.index)\n        if len(errors) &gt; 0:\n            warnings.warn(\"plot_grid: \" + \"\\n\".join(errors))\n            return None\n            # df = self.df[field]    TODO: at_least_2d...\n        df = ser.unstack()\n\n        vmin = None\n        vmax = None\n        if cmap is None:\n            cmap = \"OrRd\"\n            if s.name == \"bias\":\n                cmap = \"coolwarm\"\n                mm = ser.abs().max()\n                vmin = -mm\n                vmax = mm\n        if title is None:\n            title = s.name\n        xlabels = list(df.keys())\n        nx = len(xlabels)\n        ylabels = list(df.index)\n        ny = len(ylabels)\n\n        if (fmt is not None) and fmt[0] != \"{\":\n            fmt = \"{:\" + fmt + \"}\"\n\n        if figsize is None:\n            figsize = (nx, ny)\n        fig, ax = _get_fig_ax(ax, figsize)\n        pcm = ax.pcolormesh(df, cmap=cmap, vmin=vmin, vmax=vmax)\n        ax.set_xticks(np.arange(nx) + 0.5)\n        ax.set_xticklabels(xlabels, rotation=90)\n        ax.set_yticks(np.arange(ny) + 0.5)\n        ax.set_yticklabels(ylabels)\n        if show_numbers:\n            mean_val = df.to_numpy().mean()\n            for ii in range(ny):\n                for jj in range(nx):\n                    val = df.iloc[ii, jj].round(precision)\n                    col = \"w\" if val &gt; mean_val else \"k\"\n                    if s.name == \"bias\":\n                        col = \"w\" if np.abs(val) &gt; (0.7 * mm) else \"k\"\n                    if fmt is not None:\n                        val = fmt.format(val)\n                    ax.text(\n                        jj + 0.5,\n                        ii + 0.5,\n                        val,\n                        ha=\"center\",\n                        va=\"center\",\n                        # size=15,\n                        color=col,\n                    )\n        else:\n            fig.colorbar(pcm, ax=ax)\n        ax.set_title(title, fontsize=14)\n        return ax\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArrayPlotter.bar","title":"<code>bar(level=0, **kwargs)</code>","text":"<p>Plot statistic as bar chart using pd.DataFrame.plot.bar()</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int or str</code> <p>level to unstack, by default 0</p> <code>0</code> <code>kwargs</code> <code>dict</code> <p>key word arguments to be pased to pd.DataFrame.plot.bar() e.g. color, title, figsize, ...</p> <code>{}</code> <p>Returns:</p> Type Description <code>AxesSubplot</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; s.plot.bar()\n&gt;&gt;&gt; s.plot.bar(level=\"observation\")\n&gt;&gt;&gt; s.plot.bar(title=\"Root Mean Squared Error\")\n&gt;&gt;&gt; s.plot.bar(color=[\"red\",\"blue\"])\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def bar(self, level: int | str = 0, **kwargs):\n    \"\"\"Plot statistic as bar chart using pd.DataFrame.plot.bar()\n\n    Parameters\n    ----------\n    level : int or str, optional\n        level to unstack, by default 0\n    kwargs : dict, optional\n        key word arguments to be pased to pd.DataFrame.plot.bar()\n        e.g. color, title, figsize, ...\n\n    Returns\n    -------\n    AxesSubplot\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n    &gt;&gt;&gt; s.plot.bar()\n    &gt;&gt;&gt; s.plot.bar(level=\"observation\")\n    &gt;&gt;&gt; s.plot.bar(title=\"Root Mean Squared Error\")\n    &gt;&gt;&gt; s.plot.bar(color=[\"red\",\"blue\"])\n    \"\"\"\n    df = self._get_plot_df(level=level)\n    self._name_to_title_in_kwargs(kwargs)\n    return df.plot.bar(**kwargs)\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArrayPlotter.barh","title":"<code>barh(level=0, **kwargs)</code>","text":"<p>Plot statistic as horizontal bar chart using pd.DataFrame.plot.barh()</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int or str</code> <p>level to unstack, by default 0</p> <code>0</code> <code>kwargs</code> <code>dict</code> <p>key word arguments to be passed to pd.DataFrame.plot.barh() e.g. color, title, figsize, ...</p> <code>{}</code> <p>Returns:</p> Type Description <code>AxesSubplot</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; s.plot.barh()\n&gt;&gt;&gt; s.plot.barh(level=\"observation\")\n&gt;&gt;&gt; s.plot.barh(title=\"Root Mean Squared Error\")\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def barh(self, level: int | str = 0, **kwargs):\n    \"\"\"Plot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n    Parameters\n    ----------\n    level : int or str, optional\n        level to unstack, by default 0\n    kwargs : dict, optional\n        key word arguments to be passed to pd.DataFrame.plot.barh()\n        e.g. color, title, figsize, ...\n\n    Returns\n    -------\n    AxesSubplot\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n    &gt;&gt;&gt; s.plot.barh()\n    &gt;&gt;&gt; s.plot.barh(level=\"observation\")\n    &gt;&gt;&gt; s.plot.barh(title=\"Root Mean Squared Error\")\n    \"\"\"\n    df = self._get_plot_df(level)\n    self._name_to_title_in_kwargs(kwargs)\n    return df.plot.barh(**kwargs)\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArrayPlotter.grid","title":"<code>grid(show_numbers=True, precision=3, fmt=None, ax=None, figsize=None, title=None, cmap=None)</code>","text":"<p>Plot statistic as a colored grid, optionally with values in the cells.</p> <p>Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations</p> <p>Parameters:</p> Name Type Description Default <code>show_numbers</code> <code>bool</code> <p>should values of the static be shown in the cells?, by default True if False, a colorbar will be displayed instead</p> <code>True</code> <code>precision</code> <code>int</code> <p>number of decimals if show_numbers, by default 3</p> <code>3</code> <code>fmt</code> <code>str</code> <p>format string, e.g. \".0%\" to show value as percentage</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>matplotlib axes, by default None</p> <code>None</code> <code>figsize</code> <code>Tuple(float, float)</code> <p>figure size, by default None</p> <code>None</code> <code>title</code> <code>str</code> <p>plot title, by default name of statistic</p> <code>None</code> <code>cmap</code> <code>str</code> <p>colormap, by default \"OrRd\" (\"coolwarm\" if bias)</p> <code>None</code> <p>Returns:</p> Type Description <code>AxesSubplot</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; s.plot.grid()\n&gt;&gt;&gt; s.plot.grid(show_numbers=False, cmap=\"magma\")\n&gt;&gt;&gt; s.plot.grid(precision=1)\n&gt;&gt;&gt; s.plot.grid(fmt=\".0%\", title=\"Root Mean Squared Error\")\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def grid(\n    self,\n    show_numbers=True,\n    precision=3,\n    fmt=None,\n    ax=None,\n    figsize=None,\n    title=None,\n    cmap=None,\n):\n    \"\"\"Plot statistic as a colored grid, optionally with values in the cells.\n\n    Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n    Parameters\n    ----------\n    show_numbers : bool, optional\n        should values of the static be shown in the cells?, by default True\n        if False, a colorbar will be displayed instead\n    precision : int, optional\n        number of decimals if show_numbers, by default 3\n    fmt : str, optional\n        format string, e.g. \".0%\" to show value as percentage\n    ax : Axes, optional\n        matplotlib axes, by default None\n    figsize : Tuple(float, float), optional\n        figure size, by default None\n    title : str, optional\n        plot title, by default name of statistic\n    cmap : str, optional\n        colormap, by default \"OrRd\" (\"coolwarm\" if bias)\n\n    Returns\n    -------\n    AxesSubplot\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n    &gt;&gt;&gt; s.plot.grid()\n    &gt;&gt;&gt; s.plot.grid(show_numbers=False, cmap=\"magma\")\n    &gt;&gt;&gt; s.plot.grid(precision=1)\n    &gt;&gt;&gt; s.plot.grid(fmt=\".0%\", title=\"Root Mean Squared Error\")\n    \"\"\"\n\n    s = self.skillarray\n    ser = s._ser\n\n    errors = _validate_multi_index(ser.index)\n    if len(errors) &gt; 0:\n        warnings.warn(\"plot_grid: \" + \"\\n\".join(errors))\n        return None\n        # df = self.df[field]    TODO: at_least_2d...\n    df = ser.unstack()\n\n    vmin = None\n    vmax = None\n    if cmap is None:\n        cmap = \"OrRd\"\n        if s.name == \"bias\":\n            cmap = \"coolwarm\"\n            mm = ser.abs().max()\n            vmin = -mm\n            vmax = mm\n    if title is None:\n        title = s.name\n    xlabels = list(df.keys())\n    nx = len(xlabels)\n    ylabels = list(df.index)\n    ny = len(ylabels)\n\n    if (fmt is not None) and fmt[0] != \"{\":\n        fmt = \"{:\" + fmt + \"}\"\n\n    if figsize is None:\n        figsize = (nx, ny)\n    fig, ax = _get_fig_ax(ax, figsize)\n    pcm = ax.pcolormesh(df, cmap=cmap, vmin=vmin, vmax=vmax)\n    ax.set_xticks(np.arange(nx) + 0.5)\n    ax.set_xticklabels(xlabels, rotation=90)\n    ax.set_yticks(np.arange(ny) + 0.5)\n    ax.set_yticklabels(ylabels)\n    if show_numbers:\n        mean_val = df.to_numpy().mean()\n        for ii in range(ny):\n            for jj in range(nx):\n                val = df.iloc[ii, jj].round(precision)\n                col = \"w\" if val &gt; mean_val else \"k\"\n                if s.name == \"bias\":\n                    col = \"w\" if np.abs(val) &gt; (0.7 * mm) else \"k\"\n                if fmt is not None:\n                    val = fmt.format(val)\n                ax.text(\n                    jj + 0.5,\n                    ii + 0.5,\n                    val,\n                    ha=\"center\",\n                    va=\"center\",\n                    # size=15,\n                    color=col,\n                )\n    else:\n        fig.colorbar(pcm, ax=ax)\n    ax.set_title(title, fontsize=14)\n    return ax\n</code></pre>"},{"location":"api/skill/#modelskill.skill.SkillArrayPlotter.line","title":"<code>line(level=0, **kwargs)</code>","text":"<p>Plot statistic as a lines using pd.DataFrame.plot.line()</p> <p>Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int or str</code> <p>level to unstack, by default 0</p> <code>0</code> <code>kwargs</code> <code>dict</code> <p>key word arguments to be pased to pd.DataFrame.plot.line() e.g. marker, title, figsize, ...</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; s.plot.line()\n&gt;&gt;&gt; s.plot.line(marker=\"o\", linestyle=':')\n&gt;&gt;&gt; s.plot.line(color=['0.2', '0.4', '0.6'])\n</code></pre> Source code in <code>modelskill/skill.py</code> <pre><code>def line(\n    self,\n    level: int | str = 0,\n    **kwargs,\n):\n    \"\"\"Plot statistic as a lines using pd.DataFrame.plot.line()\n\n    Primarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n    Parameters\n    ----------\n    level : int or str, optional\n        level to unstack, by default 0\n    kwargs : dict, optional\n        key word arguments to be pased to pd.DataFrame.plot.line()\n        e.g. marker, title, figsize, ...\n\n    Examples\n    --------\n    &gt;&gt;&gt; s = cc.skill()[\"rmse\"]\n    &gt;&gt;&gt; s.plot.line()\n    &gt;&gt;&gt; s.plot.line(marker=\"o\", linestyle=':')\n    &gt;&gt;&gt; s.plot.line(color=['0.2', '0.4', '0.6'])\n    \"\"\"\n    df = self._get_plot_df(level=level)\n    self._name_to_title_in_kwargs(kwargs)\n    axes = df.plot.line(**kwargs)\n\n    xlabels = list(df.index)\n    nx = len(xlabels)\n\n    if not isinstance(axes, Iterable):\n        axes = [axes]\n    for ax in axes:\n        if not isinstance(df.index, pd.DatetimeIndex):\n            ax.set_xticks(np.arange(nx))\n            ax.set_xticklabels(xlabels, rotation=90)\n    return axes\n</code></pre>"},{"location":"api/model/","title":"Model Result","text":""},{"location":"api/model/#types-of-model-results","title":"Types of model results","text":"<p>A model result can either be a simple point/track, or spatial field (e.g. 2d dfsu file) from which data can be extracted at the observation positions by spatial interpolation. The following types are available:</p> <ul> <li>Timeseries<ul> <li><code>PointModelResult</code> - a point result from a dfs0/nc file or a DataFrame</li> <li><code>TrackModelResult</code> - a track (moving point) result from a dfs0/nc file or a DataFrame</li> </ul> </li> <li>SpatialField (extractable)<ul> <li><code>GridModelResult</code> - a spatial field from a dfs2/nc file or a Xarray Dataset</li> <li><code>DfsuModelResult</code> - a spatial field from a dfsu file</li> </ul> </li> </ul> <p>A model result can be created by explicitly invoking one of the above classes or using the <code>model_result()</code> function which will return the appropriate type based on the input data (if possible).</p>"},{"location":"api/model/#model_result","title":"model_result()","text":""},{"location":"api/model/#modelskill.model_result","title":"<code>modelskill.model_result(data, *, gtype=None, **kwargs)</code>","text":"<p>A factory function for creating an appropriate object based on the data input.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataInputType</code> <p>The data to be used for creating the ModelResult object.</p> required <code>gtype</code> <code>Optional[Literal['point', 'track', 'unstructured', 'grid']]</code> <p>The geometry type of the data. If not specified, it will be guessed from the data.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the ModelResult constructor.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.model_result(\"Oresund2D.dfsu\", item=0)\n&lt;DfsuModelResult&gt; 'Oresund2D'\n&gt;&gt;&gt; ms.model_result(\"ERA5_DutchCoast.nc\", item=\"swh\", name=\"ERA5\")\n&lt;GridModelResult&gt; 'ERA5'\n</code></pre> Source code in <code>modelskill/model/factory.py</code> <pre><code>def model_result(\n    data: DataInputType,\n    *,\n    gtype: Optional[Literal[\"point\", \"track\", \"unstructured\", \"grid\"]] = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"A factory function for creating an appropriate object based on the data input.\n\n    Parameters\n    ----------\n    data : DataInputType\n        The data to be used for creating the ModelResult object.\n    gtype : Optional[Literal[\"point\", \"track\", \"unstructured\", \"grid\"]]\n        The geometry type of the data. If not specified, it will be guessed from the data.\n    **kwargs\n        Additional keyword arguments to be passed to the ModelResult constructor.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; ms.model_result(\"Oresund2D.dfsu\", item=0)\n    &lt;DfsuModelResult&gt; 'Oresund2D'\n    &gt;&gt;&gt; ms.model_result(\"ERA5_DutchCoast.nc\", item=\"swh\", name=\"ERA5\")\n    &lt;GridModelResult&gt; 'ERA5'\n    \"\"\"\n    if gtype is None:\n        geometry = _guess_gtype(data)\n    else:\n        geometry = GeometryType.from_string(gtype)\n\n    return _modelresult_lookup[geometry](\n        data=data,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/model/dfsu/","title":"DfsuModelResult","text":""},{"location":"api/model/dfsu/#modelskill.DfsuModelResult","title":"<code>modelskill.DfsuModelResult</code>","text":"<p>             Bases: <code>SpatialField</code></p> <p>Construct a DfsuModelResult from a dfsu file or mikeio.Dataset/DataArray.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>UnstructuredType</code> <p>the input data or file path</p> required <code>name</code> <code>Optional[str]</code> <p>The name of the model result, by default None (will be set to file name or item name)</p> <code>None</code> <code>item</code> <code>str | int | None</code> <p>If multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None</p> <code>None</code> <code>quantity</code> <code>Quantity</code> <p>Model quantity, for MIKE files this is inferred from the EUM information</p> <code>None</code> <code>aux_items</code> <code>Optional[list[int | str]]</code> <p>Auxiliary items, by default None</p> <code>None</code> Source code in <code>modelskill/model/dfsu.py</code> <pre><code>class DfsuModelResult(SpatialField):\n    \"\"\"Construct a DfsuModelResult from a dfsu file or mikeio.Dataset/DataArray.\n\n    Parameters\n    ----------\n    data : types.UnstructuredType\n        the input data or file path\n    name : Optional[str], optional\n        The name of the model result,\n        by default None (will be set to file name or item name)\n    item : str | int | None, optional\n        If multiple items/arrays are present in the input an item\n        must be given (as either an index or a string), by default None\n    quantity : Quantity, optional\n        Model quantity, for MIKE files this is inferred from the EUM information\n    aux_items : Optional[list[int | str]], optional\n        Auxiliary items, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        data: UnstructuredType,\n        *,\n        name: Optional[str] = None,\n        item: str | int | None = None,\n        quantity: Optional[Quantity] = None,\n        aux_items: Optional[list[int | str]] = None,\n    ) -&gt; None:\n        assert isinstance(\n            data, get_args(UnstructuredType)\n        ), \"Could not construct DfsuModelResult from provided data\"\n\n        filename = None\n        if isinstance(data, (str, Path)):\n            assert Path(data).suffix == \".dfsu\", \"File must be a dfsu file\"\n            name = name or Path(data).stem\n            filename = str(data)\n            data = mikeio.open(data)\n\n        elif isinstance(data, (mikeio.DataArray, mikeio.Dataset)):\n            pass\n            # we could check that geometry has FM in the name, but ideally we would like to support more or all geometries\n            # if not \"FM\" in str(type(data.geometry)):\n            #    raise ValueError(f\"Geometry of {type(data.geometry)} is not supported.\")\n        else:\n            raise ValueError(\n                f\"data type must be .dfsu or dfsu-Dataset/DataArray. Not {type(data)}.\"\n            )\n\n        if isinstance(data, mikeio.DataArray):\n            if item is not None:\n                raise ValueError(\"item must be None when data is a DataArray\")\n            if aux_items is not None:\n                raise ValueError(\"aux_items must be None when data is a DataArray\")\n            item_info = data.item\n            item = data.name\n        else:\n            item_names = [i.name for i in data.items]\n            idx = _get_idx(x=item, valid_names=item_names)\n            item_info = data.items[idx]\n\n            sel_items = SelectedItems.parse(item_names, item=item, aux_items=aux_items)\n            item = sel_items.values\n            self.sel_items = sel_items\n\n        self.data: mikeio.dfsu.Dfsu2DH | mikeio.DataArray | mikeio.Dataset = data\n        self.name = name or str(item)\n        self.quantity = (\n            Quantity.from_mikeio_iteminfo(item_info) if quantity is None else quantity\n        )\n        self.filename = filename  # TODO: remove? backward compatibility\n\n    def __repr__(self) -&gt; str:\n        # TODO add item name\n        return f\"&lt;{self.__class__.__name__}&gt; '{self.name}'\"\n\n    @property\n    def time(self) -&gt; pd.DatetimeIndex:\n        return pd.DatetimeIndex(self.data.time)\n\n    def _in_domain(self, x: float, y: float) -&gt; bool:\n        return self.data.geometry.contains([x, y])  # type: ignore\n\n    def extract(self, observation: Observation) -&gt; PointModelResult | TrackModelResult:\n        \"\"\"Extract ModelResult at observation positions\n\n        Parameters\n        ----------\n        observation : &lt;PointObservation&gt; or &lt;TrackObservation&gt;\n            positions (and times) at which modelresult should be extracted\n\n        Returns\n        -------\n        PointModelResult or TrackModelResult\n            extracted modelresult\n        \"\"\"\n        _validate_overlap_in_time(self.time, observation)\n        if isinstance(observation, PointObservation):\n            return self.extract_point(observation)\n        elif isinstance(observation, TrackObservation):\n            return self.extract_track(observation)\n        else:\n            raise NotImplementedError(\n                f\"Extraction from {type(self.data)} to {type(observation)} is not implemented.\"\n            )\n\n    def extract_point(self, observation: PointObservation) -&gt; PointModelResult:\n        \"\"\"Spatially extract a PointModelResult from a DfsuModelResult (when data is a Dfsu object),\n        given a PointObservation. No time interpolation is done!\"\"\"\n\n        assert isinstance(\n            self.data, (mikeio.dfsu.Dfsu2DH, mikeio.DataArray, mikeio.Dataset)\n        )\n\n        x, y = observation.x, observation.y\n        if not self._in_domain(x, y):\n            raise ValueError(\n                f\"PointObservation '{observation.name}' ({x}, {y}) outside model domain!\"\n            )\n\n        # TODO: interp2d\n        xy = np.atleast_2d([x, y])\n        elemids = self.data.geometry.find_index(coords=xy)\n        if isinstance(self.data, mikeio.dfsu.Dfsu2DH):\n            ds_model = self.data.read(elements=elemids, items=self.sel_items.all)\n            aux_items = self.sel_items.aux\n        elif isinstance(self.data, mikeio.Dataset):\n            ds_model = self.data[self.sel_items.all].isel(element=elemids)\n            aux_items = self.sel_items.aux\n        elif isinstance(self.data, mikeio.DataArray):\n            da = self.data.isel(element=elemids)\n            ds_model = mikeio.Dataset({da.name: da})\n            aux_items = None\n\n        assert isinstance(ds_model, mikeio.Dataset)\n\n        # TODO not sure why we rename here\n        assert self.name is not None\n        ds_model.rename({ds_model.items[0].name: self.name}, inplace=True)\n\n        return PointModelResult(\n            data=ds_model,\n            item=self.name,\n            x=ds_model.geometry.x,\n            y=ds_model.geometry.y,\n            name=self.name,\n            quantity=self.quantity,\n            aux_items=aux_items,\n        )\n\n    def extract_track(self, observation: TrackObservation) -&gt; TrackModelResult:\n        \"\"\"Extract a TrackModelResult from a DfsuModelResult (when data is a Dfsu object),\n        given a TrackObservation.\"\"\"\n\n        assert isinstance(\n            self.data, (mikeio.dfsu.Dfsu2DH, mikeio.DataArray, mikeio.Dataset)\n        )\n\n        track = observation.data.to_dataframe()\n\n        if isinstance(self.data, mikeio.DataArray):\n            ds_model = self.data.extract_track(track=track)\n            ds_model.rename({self.data.name: self.name}, inplace=True)\n            aux_items = None\n        else:\n            if isinstance(self.data, mikeio.dfsu.Dfsu2DH):\n                ds_model = self.data.extract_track(\n                    track=track, items=self.sel_items.all\n                )\n            elif isinstance(self.data, mikeio.Dataset):\n                ds_model = self.data[self.sel_items.all].extract_track(track=track)\n            ds_model.rename({self.sel_items.values: self.name}, inplace=True)\n            aux_items = self.sel_items.aux\n\n        x_name = \"Longitude\" if \"Longitude\" in ds_model else \"x\"\n        y_name = \"Latitude\" if \"Latitude\" in ds_model else \"y\"\n\n        return TrackModelResult(\n            data=ds_model.dropna(),  # TODO: not on aux cols\n            item=self.name,\n            x_item=x_name,\n            y_item=y_name,\n            name=self.name,\n            quantity=self.quantity,\n            aux_items=aux_items,\n        )\n</code></pre>"},{"location":"api/model/dfsu/#modelskill.DfsuModelResult.extract","title":"<code>extract(observation)</code>","text":"<p>Extract ModelResult at observation positions</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>&lt;PointObservation&gt; or &lt;TrackObservation&gt;</code> <p>positions (and times) at which modelresult should be extracted</p> required <p>Returns:</p> Type Description <code>PointModelResult or TrackModelResult</code> <p>extracted modelresult</p> Source code in <code>modelskill/model/dfsu.py</code> <pre><code>def extract(self, observation: Observation) -&gt; PointModelResult | TrackModelResult:\n    \"\"\"Extract ModelResult at observation positions\n\n    Parameters\n    ----------\n    observation : &lt;PointObservation&gt; or &lt;TrackObservation&gt;\n        positions (and times) at which modelresult should be extracted\n\n    Returns\n    -------\n    PointModelResult or TrackModelResult\n        extracted modelresult\n    \"\"\"\n    _validate_overlap_in_time(self.time, observation)\n    if isinstance(observation, PointObservation):\n        return self.extract_point(observation)\n    elif isinstance(observation, TrackObservation):\n        return self.extract_track(observation)\n    else:\n        raise NotImplementedError(\n            f\"Extraction from {type(self.data)} to {type(observation)} is not implemented.\"\n        )\n</code></pre>"},{"location":"api/model/dfsu/#modelskill.DfsuModelResult.extract_point","title":"<code>extract_point(observation)</code>","text":"<p>Spatially extract a PointModelResult from a DfsuModelResult (when data is a Dfsu object), given a PointObservation. No time interpolation is done!</p> Source code in <code>modelskill/model/dfsu.py</code> <pre><code>def extract_point(self, observation: PointObservation) -&gt; PointModelResult:\n    \"\"\"Spatially extract a PointModelResult from a DfsuModelResult (when data is a Dfsu object),\n    given a PointObservation. No time interpolation is done!\"\"\"\n\n    assert isinstance(\n        self.data, (mikeio.dfsu.Dfsu2DH, mikeio.DataArray, mikeio.Dataset)\n    )\n\n    x, y = observation.x, observation.y\n    if not self._in_domain(x, y):\n        raise ValueError(\n            f\"PointObservation '{observation.name}' ({x}, {y}) outside model domain!\"\n        )\n\n    # TODO: interp2d\n    xy = np.atleast_2d([x, y])\n    elemids = self.data.geometry.find_index(coords=xy)\n    if isinstance(self.data, mikeio.dfsu.Dfsu2DH):\n        ds_model = self.data.read(elements=elemids, items=self.sel_items.all)\n        aux_items = self.sel_items.aux\n    elif isinstance(self.data, mikeio.Dataset):\n        ds_model = self.data[self.sel_items.all].isel(element=elemids)\n        aux_items = self.sel_items.aux\n    elif isinstance(self.data, mikeio.DataArray):\n        da = self.data.isel(element=elemids)\n        ds_model = mikeio.Dataset({da.name: da})\n        aux_items = None\n\n    assert isinstance(ds_model, mikeio.Dataset)\n\n    # TODO not sure why we rename here\n    assert self.name is not None\n    ds_model.rename({ds_model.items[0].name: self.name}, inplace=True)\n\n    return PointModelResult(\n        data=ds_model,\n        item=self.name,\n        x=ds_model.geometry.x,\n        y=ds_model.geometry.y,\n        name=self.name,\n        quantity=self.quantity,\n        aux_items=aux_items,\n    )\n</code></pre>"},{"location":"api/model/dfsu/#modelskill.DfsuModelResult.extract_track","title":"<code>extract_track(observation)</code>","text":"<p>Extract a TrackModelResult from a DfsuModelResult (when data is a Dfsu object), given a TrackObservation.</p> Source code in <code>modelskill/model/dfsu.py</code> <pre><code>def extract_track(self, observation: TrackObservation) -&gt; TrackModelResult:\n    \"\"\"Extract a TrackModelResult from a DfsuModelResult (when data is a Dfsu object),\n    given a TrackObservation.\"\"\"\n\n    assert isinstance(\n        self.data, (mikeio.dfsu.Dfsu2DH, mikeio.DataArray, mikeio.Dataset)\n    )\n\n    track = observation.data.to_dataframe()\n\n    if isinstance(self.data, mikeio.DataArray):\n        ds_model = self.data.extract_track(track=track)\n        ds_model.rename({self.data.name: self.name}, inplace=True)\n        aux_items = None\n    else:\n        if isinstance(self.data, mikeio.dfsu.Dfsu2DH):\n            ds_model = self.data.extract_track(\n                track=track, items=self.sel_items.all\n            )\n        elif isinstance(self.data, mikeio.Dataset):\n            ds_model = self.data[self.sel_items.all].extract_track(track=track)\n        ds_model.rename({self.sel_items.values: self.name}, inplace=True)\n        aux_items = self.sel_items.aux\n\n    x_name = \"Longitude\" if \"Longitude\" in ds_model else \"x\"\n    y_name = \"Latitude\" if \"Latitude\" in ds_model else \"y\"\n\n    return TrackModelResult(\n        data=ds_model.dropna(),  # TODO: not on aux cols\n        item=self.name,\n        x_item=x_name,\n        y_item=y_name,\n        name=self.name,\n        quantity=self.quantity,\n        aux_items=aux_items,\n    )\n</code></pre>"},{"location":"api/model/grid/","title":"GridModelResult","text":""},{"location":"api/model/grid/#modelskill.GridModelResult","title":"<code>modelskill.GridModelResult</code>","text":"<p>             Bases: <code>SpatialField</code></p> <p>Construct a GridModelResult from a file or xarray.Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>GridType</code> <p>the input data or file path</p> required <code>name</code> <code>str</code> <p>The name of the model result, by default None (will be set to file name or item name)</p> <code>None</code> <code>item</code> <code>str or int</code> <p>If multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None</p> <code>None</code> <code>quantity</code> <code>Quantity</code> <p>Model quantity, for MIKE files this is inferred from the EUM information</p> <code>None</code> <code>aux_items</code> <code>Optional[list[int | str]]</code> <p>Auxiliary items, by default None</p> <code>None</code> Source code in <code>modelskill/model/grid.py</code> <pre><code>class GridModelResult(SpatialField):\n    \"\"\"Construct a GridModelResult from a file or xarray.Dataset.\n\n    Parameters\n    ----------\n    data : types.GridType\n        the input data or file path\n    name : str, optional\n        The name of the model result,\n        by default None (will be set to file name or item name)\n    item : str or int, optional\n        If multiple items/arrays are present in the input an item\n        must be given (as either an index or a string), by default None\n    quantity : Quantity, optional\n        Model quantity, for MIKE files this is inferred from the EUM information\n    aux_items : Optional[list[int | str]], optional\n        Auxiliary items, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        data: GridType,\n        *,\n        name: Optional[str] = None,\n        item: str | int | None = None,\n        quantity: Optional[Quantity] = None,\n        aux_items: Optional[list[int | str]] = None,\n    ) -&gt; None:\n        assert isinstance(\n            data, get_args(GridType)\n        ), \"Could not construct GridModelResult from provided data.\"\n\n        if isinstance(data, (str, Path)):\n            if \"*\" in str(data):\n                ds = xr.open_mfdataset(data)\n            else:\n                assert Path(data).exists(), f\"{data}: File does not exist.\"\n                ds = xr.open_dataset(data)\n\n        elif isinstance(data, Sequence) and all(\n            isinstance(file, (str, Path)) for file in data\n        ):\n            ds = xr.open_mfdataset(data)\n\n        elif isinstance(data, xr.DataArray):\n            if item is not None:\n                raise ValueError(f\"item must be None when data is a {type(data)}\")\n            if aux_items is not None:\n                raise ValueError(f\"aux_items must be None when data is a {type(data)}\")\n            if data.ndim &lt; 2:\n                raise ValueError(f\"DataArray must at least 2D. Got {list(data.dims)}.\")\n            ds = data.to_dataset(name=name, promote_attrs=True)\n        elif isinstance(data, xr.Dataset):\n            assert len(data.coords) &gt;= 2, \"Dataset must have at least 2 dimensions.\"\n            ds = data\n        else:\n            raise NotImplementedError(\n                f\"Could not construct GridModelResult from {type(data)}\"\n            )\n\n        sel_items = SelectedItems.parse(\n            list(ds.data_vars), item=item, aux_items=aux_items\n        )\n        name = name or sel_items.values\n        ds = rename_coords_xr(ds)\n\n        self.data: xr.Dataset = ds[sel_items.all]\n        self.name = name\n        self.sel_items = sel_items\n\n        # use long_name and units from data if not provided\n        if quantity is None:\n            da = self.data[sel_items.values]\n            quantity = Quantity.from_cf_attrs(da.attrs)\n\n        self.quantity = quantity\n\n    def __repr__(self) -&gt; str:\n        # TODO add item name\n        return f\"&lt;GridModelResult&gt; '{self.name}'\"\n\n    @property\n    def time(self) -&gt; pd.DatetimeIndex:\n        return pd.DatetimeIndex(self.data.time)\n\n    def _in_domain(self, x: float, y: float) -&gt; bool:\n        assert hasattr(self.data, \"x\") and hasattr(\n            self.data, \"y\"\n        ), \"Data has no x and/or y coordinates.\"\n        xmin = float(self.data.x.values.min())\n        xmax = float(self.data.x.values.max())\n        ymin = float(self.data.y.values.min())\n        ymax = float(self.data.y.values.max())\n        return (x &gt;= xmin) &amp; (x &lt;= xmax) &amp; (y &gt;= ymin) &amp; (y &lt;= ymax)\n\n    def extract(\n        self, observation: PointObservation | TrackObservation\n    ) -&gt; PointModelResult | TrackModelResult:\n        \"\"\"Extract ModelResult at observation positions\n\n        Parameters\n        ----------\n        observation : &lt;PointObservation&gt; or &lt;TrackObservation&gt;\n            positions (and times) at which modelresult should be extracted\n\n        Returns\n        -------\n        PointModelResult or TrackModelResult\n            extracted modelresult\n        \"\"\"\n        _validate_overlap_in_time(self.time, observation)\n        if isinstance(observation, PointObservation):\n            return self.extract_point(observation)\n        elif isinstance(observation, TrackObservation):\n            return self.extract_track(observation)\n        else:\n            raise NotImplementedError(\n                f\"Extraction from {type(self.data)} to {type(observation)} is not implemented.\"\n            )\n\n    def extract_point(self, observation: PointObservation) -&gt; PointModelResult:\n        \"\"\"Spatially extract a PointModelResult from a GridModelResult (when data is a xarray.Dataset),\n        given a PointObservation. No time interpolation is done!\"\"\"\n\n        x, y = observation.x, observation.y\n        if (x is None) or (y is None):\n            raise ValueError(\n                f\"PointObservation '{observation.name}' cannot be used for extraction \"\n                + f\"because it has None position x={x}, y={y}. Please provide position \"\n                + \"when creating PointObservation.\"\n            )\n        if not self._in_domain(x, y):\n            raise ValueError(\n                f\"PointObservation '{observation.name}' ({x}, {y}) is outside model domain!\"\n            )\n\n        assert isinstance(self.data, xr.Dataset)\n\n        # TODO: avoid runtrip to pandas if possible (potential loss of metadata)\n        da = self.data.interp(coords=dict(x=x, y=y), method=\"nearest\")\n        df = da.to_dataframe().drop(columns=[\"x\", \"y\"])\n        df = df.rename(columns={self.sel_items.values: self.name})\n\n        return PointModelResult(\n            data=df.dropna(),\n            x=da.x.item(),\n            y=da.y.item(),\n            item=self.name,\n            name=self.name,\n            quantity=self.quantity,\n            aux_items=self.sel_items.aux,\n        )\n\n    def extract_track(self, observation: TrackObservation) -&gt; TrackModelResult:\n        \"\"\"Extract a TrackModelResult from a GridModelResult (when data is a xarray.Dataset),\n        given a TrackObservation.\"\"\"\n\n        obs_df = observation.data.to_dataframe()\n\n        renamed_obs_data = rename_coords_pd(obs_df)\n        t = xr.DataArray(renamed_obs_data.index, dims=\"track\")\n        x = xr.DataArray(renamed_obs_data.x, dims=\"track\")\n        y = xr.DataArray(renamed_obs_data.y, dims=\"track\")\n\n        assert isinstance(self.data, xr.Dataset)\n        da = self.data.interp(coords=dict(time=t, x=x, y=y), method=\"linear\")\n        df = da.to_dataframe().drop(columns=[\"time\"])\n        df = df.rename(columns={self.sel_items.values: self.name})\n\n        return TrackModelResult(\n            data=df.dropna(),\n            item=self.name,\n            x_item=\"x\",\n            y_item=\"y\",\n            name=self.name,\n            quantity=self.quantity,\n            aux_items=self.sel_items.aux,\n        )\n</code></pre>"},{"location":"api/model/grid/#modelskill.GridModelResult.extract","title":"<code>extract(observation)</code>","text":"<p>Extract ModelResult at observation positions</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>&lt;PointObservation&gt; or &lt;TrackObservation&gt;</code> <p>positions (and times) at which modelresult should be extracted</p> required <p>Returns:</p> Type Description <code>PointModelResult or TrackModelResult</code> <p>extracted modelresult</p> Source code in <code>modelskill/model/grid.py</code> <pre><code>def extract(\n    self, observation: PointObservation | TrackObservation\n) -&gt; PointModelResult | TrackModelResult:\n    \"\"\"Extract ModelResult at observation positions\n\n    Parameters\n    ----------\n    observation : &lt;PointObservation&gt; or &lt;TrackObservation&gt;\n        positions (and times) at which modelresult should be extracted\n\n    Returns\n    -------\n    PointModelResult or TrackModelResult\n        extracted modelresult\n    \"\"\"\n    _validate_overlap_in_time(self.time, observation)\n    if isinstance(observation, PointObservation):\n        return self.extract_point(observation)\n    elif isinstance(observation, TrackObservation):\n        return self.extract_track(observation)\n    else:\n        raise NotImplementedError(\n            f\"Extraction from {type(self.data)} to {type(observation)} is not implemented.\"\n        )\n</code></pre>"},{"location":"api/model/grid/#modelskill.GridModelResult.extract_point","title":"<code>extract_point(observation)</code>","text":"<p>Spatially extract a PointModelResult from a GridModelResult (when data is a xarray.Dataset), given a PointObservation. No time interpolation is done!</p> Source code in <code>modelskill/model/grid.py</code> <pre><code>def extract_point(self, observation: PointObservation) -&gt; PointModelResult:\n    \"\"\"Spatially extract a PointModelResult from a GridModelResult (when data is a xarray.Dataset),\n    given a PointObservation. No time interpolation is done!\"\"\"\n\n    x, y = observation.x, observation.y\n    if (x is None) or (y is None):\n        raise ValueError(\n            f\"PointObservation '{observation.name}' cannot be used for extraction \"\n            + f\"because it has None position x={x}, y={y}. Please provide position \"\n            + \"when creating PointObservation.\"\n        )\n    if not self._in_domain(x, y):\n        raise ValueError(\n            f\"PointObservation '{observation.name}' ({x}, {y}) is outside model domain!\"\n        )\n\n    assert isinstance(self.data, xr.Dataset)\n\n    # TODO: avoid runtrip to pandas if possible (potential loss of metadata)\n    da = self.data.interp(coords=dict(x=x, y=y), method=\"nearest\")\n    df = da.to_dataframe().drop(columns=[\"x\", \"y\"])\n    df = df.rename(columns={self.sel_items.values: self.name})\n\n    return PointModelResult(\n        data=df.dropna(),\n        x=da.x.item(),\n        y=da.y.item(),\n        item=self.name,\n        name=self.name,\n        quantity=self.quantity,\n        aux_items=self.sel_items.aux,\n    )\n</code></pre>"},{"location":"api/model/grid/#modelskill.GridModelResult.extract_track","title":"<code>extract_track(observation)</code>","text":"<p>Extract a TrackModelResult from a GridModelResult (when data is a xarray.Dataset), given a TrackObservation.</p> Source code in <code>modelskill/model/grid.py</code> <pre><code>def extract_track(self, observation: TrackObservation) -&gt; TrackModelResult:\n    \"\"\"Extract a TrackModelResult from a GridModelResult (when data is a xarray.Dataset),\n    given a TrackObservation.\"\"\"\n\n    obs_df = observation.data.to_dataframe()\n\n    renamed_obs_data = rename_coords_pd(obs_df)\n    t = xr.DataArray(renamed_obs_data.index, dims=\"track\")\n    x = xr.DataArray(renamed_obs_data.x, dims=\"track\")\n    y = xr.DataArray(renamed_obs_data.y, dims=\"track\")\n\n    assert isinstance(self.data, xr.Dataset)\n    da = self.data.interp(coords=dict(time=t, x=x, y=y), method=\"linear\")\n    df = da.to_dataframe().drop(columns=[\"time\"])\n    df = df.rename(columns={self.sel_items.values: self.name})\n\n    return TrackModelResult(\n        data=df.dropna(),\n        item=self.name,\n        x_item=\"x\",\n        y_item=\"y\",\n        name=self.name,\n        quantity=self.quantity,\n        aux_items=self.sel_items.aux,\n    )\n</code></pre>"},{"location":"api/model/point/","title":"PointModelResult","text":""},{"location":"api/model/point/#modelskill.PointModelResult","title":"<code>modelskill.PointModelResult</code>","text":"<p>             Bases: <code>TimeSeries</code></p> <p>Construct a PointModelResult from a 0d data source: dfs0 file, mikeio.Dataset/DataArray, pandas.DataFrame/Series or xarray.Dataset/DataArray</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>PointType</code> <p>the input data or file path</p> required <code>name</code> <code>Optional[str]</code> <p>The name of the model result, by default None (will be set to file name or item name)</p> <code>None</code> <code>x</code> <code>float</code> <p>first coordinate of point position, by default None</p> <code>None</code> <code>y</code> <code>float</code> <p>second coordinate of point position, by default None</p> <code>None</code> <code>item</code> <code>str | int | None</code> <p>If multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None</p> <code>None</code> <code>quantity</code> <code>Quantity</code> <p>Model quantity, for MIKE files this is inferred from the EUM information</p> <code>None</code> <code>aux_items</code> <code>Optional[list[int | str]]</code> <p>Auxiliary items, by default None</p> <code>None</code> Source code in <code>modelskill/model/point.py</code> <pre><code>class PointModelResult(TimeSeries):\n    \"\"\"Construct a PointModelResult from a 0d data source:\n    dfs0 file, mikeio.Dataset/DataArray, pandas.DataFrame/Series\n    or xarray.Dataset/DataArray\n\n    Parameters\n    ----------\n    data : types.PointType\n        the input data or file path\n    name : Optional[str], optional\n        The name of the model result,\n        by default None (will be set to file name or item name)\n    x : float, optional\n        first coordinate of point position, by default None\n    y : float, optional\n        second coordinate of point position, by default None\n    item : str | int | None, optional\n        If multiple items/arrays are present in the input an item\n        must be given (as either an index or a string), by default None\n    quantity : Quantity, optional\n        Model quantity, for MIKE files this is inferred from the EUM information\n    aux_items : Optional[list[int | str]], optional\n        Auxiliary items, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        data: PointType,\n        *,\n        name: Optional[str] = None,\n        x: Optional[float] = None,\n        y: Optional[float] = None,\n        item: str | int | None = None,\n        quantity: Optional[Quantity] = None,\n        aux_items: Optional[Sequence[int | str]] = None,\n    ) -&gt; None:\n        if not self._is_input_validated(data):\n            data = _parse_point_input(\n                data, name=name, item=item, quantity=quantity, aux_items=aux_items\n            )\n\n            data.coords[\"x\"] = x\n            data.coords[\"y\"] = y\n            data.coords[\"z\"] = None  # TODO: or np.nan?\n\n        assert isinstance(data, xr.Dataset)\n\n        data_var = str(list(data.data_vars)[0])\n        data[data_var].attrs[\"kind\"] = \"model\"\n        super().__init__(data=data)\n\n    def extract(self, obs: PointObservation) -&gt; PointModelResult:\n        if not isinstance(obs, PointObservation):\n            raise ValueError(f\"obs must be a PointObservation not {type(obs)}\")\n        # TODO check x,y,z\n        return self\n\n    def interp_time(\n        self,\n        new_time: pd.DatetimeIndex,\n        dropna: bool = True,\n        **kwargs: Any,\n    ) -&gt; PointModelResult:\n        \"\"\"Interpolate time series to new time index\n\n        Parameters\n        ----------\n        new_time : pd.DatetimeIndex\n            new time index\n        dropna : bool, optional\n            drop nan values, by default True\n        **kwargs\n            keyword arguments passed to xarray.interp()\n\n        Returns\n        -------\n        TimeSeries\n            interpolated time series\n        \"\"\"\n        if not isinstance(new_time, pd.DatetimeIndex):\n            try:\n                new_time = pd.DatetimeIndex(new_time)\n            except Exception:\n                raise ValueError(\n                    \"new_time must be a pandas DatetimeIndex (or convertible to one)\"\n                )\n\n        # TODO: is it necessary to dropna before interpolation?\n        dati = self.data.dropna(\"time\").interp(\n            time=new_time, assume_sorted=True, **kwargs\n        )\n        if dropna:\n            dati = dati.dropna(dim=\"time\")\n        return PointModelResult(dati)\n</code></pre>"},{"location":"api/model/point/#modelskill.PointModelResult.gtype","title":"<code>gtype: str</code>  <code>property</code>","text":"<p>Geometry type</p>"},{"location":"api/model/point/#modelskill.PointModelResult.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>Number of data points</p>"},{"location":"api/model/point/#modelskill.PointModelResult.name","title":"<code>name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Name of time series (value item name)</p>"},{"location":"api/model/point/#modelskill.PointModelResult.quantity","title":"<code>quantity: Quantity</code>  <code>property</code> <code>writable</code>","text":"<p>Quantity of time series</p>"},{"location":"api/model/point/#modelskill.PointModelResult.time","title":"<code>time: pd.DatetimeIndex</code>  <code>property</code>","text":"<p>Time index</p>"},{"location":"api/model/point/#modelskill.PointModelResult.values","title":"<code>values: NDArray[Any]</code>  <code>property</code>","text":"<p>Values as numpy array</p>"},{"location":"api/model/point/#modelskill.PointModelResult.x","title":"<code>x: Any</code>  <code>property</code> <code>writable</code>","text":"<p>x-coordinate</p>"},{"location":"api/model/point/#modelskill.PointModelResult.y","title":"<code>y: Any</code>  <code>property</code> <code>writable</code>","text":"<p>y-coordinate</p>"},{"location":"api/model/point/#modelskill.PointModelResult.equals","title":"<code>equals(other)</code>","text":"<p>Check if two TimeSeries are equal</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def equals(self, other: TimeSeries) -&gt; bool:\n    \"\"\"Check if two TimeSeries are equal\"\"\"\n    return self.data.equals(other.data)\n</code></pre>"},{"location":"api/model/point/#modelskill.PointModelResult.interp_time","title":"<code>interp_time(new_time, dropna=True, **kwargs)</code>","text":"<p>Interpolate time series to new time index</p> <p>Parameters:</p> Name Type Description Default <code>new_time</code> <code>DatetimeIndex</code> <p>new time index</p> required <code>dropna</code> <code>bool</code> <p>drop nan values, by default True</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>keyword arguments passed to xarray.interp()</p> <code>{}</code> <p>Returns:</p> Type Description <code>TimeSeries</code> <p>interpolated time series</p> Source code in <code>modelskill/model/point.py</code> <pre><code>def interp_time(\n    self,\n    new_time: pd.DatetimeIndex,\n    dropna: bool = True,\n    **kwargs: Any,\n) -&gt; PointModelResult:\n    \"\"\"Interpolate time series to new time index\n\n    Parameters\n    ----------\n    new_time : pd.DatetimeIndex\n        new time index\n    dropna : bool, optional\n        drop nan values, by default True\n    **kwargs\n        keyword arguments passed to xarray.interp()\n\n    Returns\n    -------\n    TimeSeries\n        interpolated time series\n    \"\"\"\n    if not isinstance(new_time, pd.DatetimeIndex):\n        try:\n            new_time = pd.DatetimeIndex(new_time)\n        except Exception:\n            raise ValueError(\n                \"new_time must be a pandas DatetimeIndex (or convertible to one)\"\n            )\n\n    # TODO: is it necessary to dropna before interpolation?\n    dati = self.data.dropna(\"time\").interp(\n        time=new_time, assume_sorted=True, **kwargs\n    )\n    if dropna:\n        dati = dati.dropna(dim=\"time\")\n    return PointModelResult(dati)\n</code></pre>"},{"location":"api/model/point/#modelskill.PointModelResult.sel","title":"<code>sel(**kwargs)</code>","text":"<p>Select data by label</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def sel(self: T, **kwargs: Any) -&gt; T:\n    \"\"\"Select data by label\"\"\"\n    return self.__class__(self.data.sel(**kwargs))\n</code></pre>"},{"location":"api/model/point/#modelskill.PointModelResult.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert to pandas DataFrame</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert to pandas DataFrame\"\"\"\n    if self.gtype == str(GeometryType.POINT):\n        # we remove the scalar coordinate variables as they\n        # will otherwise be columns in the dataframe\n        return self.data.drop_vars([\"x\", \"y\", \"z\"])[self.name].to_dataframe()\n    else:\n        return self.data.drop_vars([\"z\"])[[\"x\", \"y\", self.name]].to_dataframe()\n</code></pre>"},{"location":"api/model/point/#modelskill.PointModelResult.trim","title":"<code>trim(start_time=None, end_time=None, buffer='1s')</code>","text":"<p>Trim observation data to a given time interval</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>Timestamp</code> <p>start time</p> <code>None</code> <code>end_time</code> <code>Timestamp</code> <p>end time</p> <code>None</code> <code>buffer</code> <code>str</code> <p>buffer time around start and end time, by default \"1s\"</p> <code>'1s'</code> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def trim(\n    self: T,\n    start_time: Optional[pd.Timestamp] = None,\n    end_time: Optional[pd.Timestamp] = None,\n    buffer: str = \"1s\",\n) -&gt; T:\n    \"\"\"Trim observation data to a given time interval\n\n    Parameters\n    ----------\n    start_time : pd.Timestamp\n        start time\n    end_time : pd.Timestamp\n        end time\n    buffer : str, optional\n        buffer time around start and end time, by default \"1s\"\n    \"\"\"\n    # Expand time interval with buffer\n    start_time = pd.Timestamp(start_time) - pd.Timedelta(buffer)\n    end_time = pd.Timestamp(end_time) + pd.Timedelta(buffer)\n\n    data = self.data.sel(time=slice(start_time, end_time))\n    if len(data.time) == 0:\n        raise ValueError(\n            f\"No data left after trimming to {start_time} - {end_time}\"\n        )\n    return self.__class__(data)\n</code></pre>"},{"location":"api/model/track/","title":"TrackModelResult","text":""},{"location":"api/model/track/#modelskill.TrackModelResult","title":"<code>modelskill.TrackModelResult</code>","text":"<p>             Bases: <code>TimeSeries</code></p> <p>Construct a TrackModelResult from a dfs0 file, mikeio.Dataset, pandas.DataFrame or a xarray.Datasets</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>TrackType</code> <p>The input data or file path</p> required <code>name</code> <code>Optional[str]</code> <p>The name of the model result, by default None (will be set to file name or item name)</p> <code>None</code> <code>item</code> <code>str | int | None</code> <p>If multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None</p> <code>None</code> <code>x_item</code> <code>str | int | None</code> <p>Item of the first coordinate of positions, by default None</p> <code>0</code> <code>y_item</code> <code>str | int | None</code> <p>Item of the second coordinate of positions, by default None</p> <code>1</code> <code>quantity</code> <code>Quantity</code> <p>Model quantity, for MIKE files this is inferred from the EUM information</p> <code>None</code> <code>keep_duplicates</code> <code>(str, bool)</code> <p>Strategy for handling duplicate timestamps (wraps xarray.Dataset.drop_duplicates) \"first\" to keep first occurrence, \"last\" to keep last occurrence, False to drop all duplicates, \"offset\" to add milliseconds to consecutive duplicates, by default \"first\"</p> <code>'first'</code> <code>aux_items</code> <code>Optional[list[int | str]]</code> <p>Auxiliary items, by default None</p> <code>None</code> Source code in <code>modelskill/model/track.py</code> <pre><code>class TrackModelResult(TimeSeries):\n    \"\"\"Construct a TrackModelResult from a dfs0 file,\n    mikeio.Dataset, pandas.DataFrame or a xarray.Datasets\n\n    Parameters\n    ----------\n    data : types.TrackType\n        The input data or file path\n    name : Optional[str], optional\n        The name of the model result,\n        by default None (will be set to file name or item name)\n    item : str | int | None, optional\n        If multiple items/arrays are present in the input an item\n        must be given (as either an index or a string), by default None\n    x_item : str | int | None, optional\n        Item of the first coordinate of positions, by default None\n    y_item : str | int | None, optional\n        Item of the second coordinate of positions, by default None\n    quantity : Quantity, optional\n        Model quantity, for MIKE files this is inferred from the EUM information\n    keep_duplicates : (str, bool), optional\n        Strategy for handling duplicate timestamps (wraps xarray.Dataset.drop_duplicates)\n        \"first\" to keep first occurrence, \"last\" to keep last occurrence,\n        False to drop all duplicates, \"offset\" to add milliseconds to\n        consecutive duplicates, by default \"first\"\n    aux_items : Optional[list[int | str]], optional\n        Auxiliary items, by default None\n    \"\"\"\n\n    def __init__(\n        self,\n        data: TrackType,\n        *,\n        name: Optional[str] = None,\n        item: str | int | None = None,\n        quantity: Optional[Quantity] = None,\n        x_item: str | int = 0,\n        y_item: str | int = 1,\n        keep_duplicates: str | bool = \"first\",\n        aux_items: Optional[Sequence[int | str]] = None,\n    ) -&gt; None:\n        if not self._is_input_validated(data):\n            data = _parse_track_input(\n                data=data,\n                name=name,\n                item=item,\n                quantity=quantity,\n                x_item=x_item,\n                y_item=y_item,\n                keep_duplicates=keep_duplicates,\n                aux_items=aux_items,\n            )\n\n        assert isinstance(data, xr.Dataset)\n        data_var = str(list(data.data_vars)[0])\n        data[data_var].attrs[\"kind\"] = \"model\"\n        super().__init__(data=data)\n\n    def extract(self, obs: TrackObservation) -&gt; TrackModelResult:\n        if not isinstance(obs, TrackObservation):\n            raise ValueError(f\"obs must be a TrackObservation not {type(obs)}\")\n        # TODO check x,y,z\n        return self\n</code></pre>"},{"location":"api/model/track/#modelskill.TrackModelResult.gtype","title":"<code>gtype: str</code>  <code>property</code>","text":"<p>Geometry type</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>Number of data points</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.name","title":"<code>name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Name of time series (value item name)</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.quantity","title":"<code>quantity: Quantity</code>  <code>property</code> <code>writable</code>","text":"<p>Quantity of time series</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.time","title":"<code>time: pd.DatetimeIndex</code>  <code>property</code>","text":"<p>Time index</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.values","title":"<code>values: NDArray[Any]</code>  <code>property</code>","text":"<p>Values as numpy array</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.x","title":"<code>x: Any</code>  <code>property</code> <code>writable</code>","text":"<p>x-coordinate</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.y","title":"<code>y: Any</code>  <code>property</code> <code>writable</code>","text":"<p>y-coordinate</p>"},{"location":"api/model/track/#modelskill.TrackModelResult.equals","title":"<code>equals(other)</code>","text":"<p>Check if two TimeSeries are equal</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def equals(self, other: TimeSeries) -&gt; bool:\n    \"\"\"Check if two TimeSeries are equal\"\"\"\n    return self.data.equals(other.data)\n</code></pre>"},{"location":"api/model/track/#modelskill.TrackModelResult.sel","title":"<code>sel(**kwargs)</code>","text":"<p>Select data by label</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def sel(self: T, **kwargs: Any) -&gt; T:\n    \"\"\"Select data by label\"\"\"\n    return self.__class__(self.data.sel(**kwargs))\n</code></pre>"},{"location":"api/model/track/#modelskill.TrackModelResult.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert to pandas DataFrame</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert to pandas DataFrame\"\"\"\n    if self.gtype == str(GeometryType.POINT):\n        # we remove the scalar coordinate variables as they\n        # will otherwise be columns in the dataframe\n        return self.data.drop_vars([\"x\", \"y\", \"z\"])[self.name].to_dataframe()\n    else:\n        return self.data.drop_vars([\"z\"])[[\"x\", \"y\", self.name]].to_dataframe()\n</code></pre>"},{"location":"api/model/track/#modelskill.TrackModelResult.trim","title":"<code>trim(start_time=None, end_time=None, buffer='1s')</code>","text":"<p>Trim observation data to a given time interval</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>Timestamp</code> <p>start time</p> <code>None</code> <code>end_time</code> <code>Timestamp</code> <p>end time</p> <code>None</code> <code>buffer</code> <code>str</code> <p>buffer time around start and end time, by default \"1s\"</p> <code>'1s'</code> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def trim(\n    self: T,\n    start_time: Optional[pd.Timestamp] = None,\n    end_time: Optional[pd.Timestamp] = None,\n    buffer: str = \"1s\",\n) -&gt; T:\n    \"\"\"Trim observation data to a given time interval\n\n    Parameters\n    ----------\n    start_time : pd.Timestamp\n        start time\n    end_time : pd.Timestamp\n        end time\n    buffer : str, optional\n        buffer time around start and end time, by default \"1s\"\n    \"\"\"\n    # Expand time interval with buffer\n    start_time = pd.Timestamp(start_time) - pd.Timedelta(buffer)\n    end_time = pd.Timestamp(end_time) + pd.Timedelta(buffer)\n\n    data = self.data.sel(time=slice(start_time, end_time))\n    if len(data.time) == 0:\n        raise ValueError(\n            f\"No data left after trimming to {start_time} - {end_time}\"\n        )\n    return self.__class__(data)\n</code></pre>"},{"location":"api/observation/","title":"Observations","text":"<p>ModelSkill supports two types of observations:</p> <ul> <li><code>PointObservation</code> - a point timeseries from a dfs0/nc file or a DataFrame</li> <li><code>TrackObservation</code> - a track (moving point) timeseries from a dfs0/nc file or a DataFrame</li> </ul> <p>An observation can be created by explicitly invoking one of the above classes or using the <code>observation()</code> function which will return the appropriate type based on the input data (if possible).</p>"},{"location":"api/observation/#observation","title":"observation()","text":""},{"location":"api/observation/#modelskill.observation","title":"<code>modelskill.observation(data, *, gtype=None, **kwargs)</code>","text":"<p>A factory function for creating an appropriate observation object based on the data and args.</p> <p>If 'x' or 'y' is given, a PointObservation is created. If 'x_item' or 'y_item' is given, a TrackObservation is created.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataInputType</code> <p>The data to be used for creating the Observation object.</p> required <code>gtype</code> <code>Optional[Literal['point', 'track']]</code> <p>The geometry type of the data. If not specified, it will be guessed from the data.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the Observation constructor.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o_pt = ms.observation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o_tr = ms.observation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n</code></pre> Source code in <code>modelskill/obs.py</code> <pre><code>def observation(\n    data: DataInputType,\n    *,\n    gtype: Optional[Literal[\"point\", \"track\"]] = None,\n    **kwargs,\n):\n    \"\"\"A factory function for creating an appropriate observation object\n    based on the data and args.\n\n    If 'x' or 'y' is given, a PointObservation is created.\n    If 'x_item' or 'y_item' is given, a TrackObservation is created.\n\n    Parameters\n    ----------\n    data : DataInputType\n        The data to be used for creating the Observation object.\n    gtype : Optional[Literal[\"point\", \"track\"]]\n        The geometry type of the data. If not specified, it will be guessed from the data.\n    **kwargs\n        Additional keyword arguments to be passed to the Observation constructor.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; o_pt = ms.observation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n    &gt;&gt;&gt; o_tr = ms.observation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n    \"\"\"\n    if gtype is None:\n        geometry = _guess_gtype(**kwargs)\n    else:\n        geometry = GeometryType.from_string(gtype)\n\n    return _obs_class_lookup[geometry](\n        data=data,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/observation/point/","title":"PointObservation","text":""},{"location":"api/observation/point/#modelskill.PointObservation","title":"<code>modelskill.PointObservation</code>","text":"<p>             Bases: <code>Observation</code></p> <p>Class for observations of fixed locations</p> <p>Create a PointObservation from a dfs0 file or a pd.DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(str, Path, Dataset, DataArray, DataFrame, Series, Dataset, DataArray)</code> <p>filename or object with the data</p> required <code>item</code> <code>(int, str)</code> <p>index or name of the wanted item/column, by default None if data contains more than one item, item must be given</p> <code>None</code> <code>x</code> <code>float</code> <p>x-coordinate of the observation point, by default None</p> <code>None</code> <code>y</code> <code>float</code> <p>y-coordinate of the observation point, by default None</p> <code>None</code> <code>z</code> <code>float</code> <p>z-coordinate of the observation point, by default None</p> <code>None</code> <code>name</code> <code>str</code> <p>user-defined name for easy identification in plots etc, by default file basename</p> <code>None</code> <code>quantity</code> <code>Quantity</code> <p>The quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information</p> <code>None</code> <code>aux_items</code> <code>list</code> <p>list of names or indices of auxiliary items, by default None</p> <code>None</code> <code>attrs</code> <code>dict</code> <p>additional attributes to be added to the data, by default None</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"klagshamn.dfs0\", item=\"Water Level\", x=366844, y=6154291)\n&gt;&gt;&gt; o3 = ms.PointObservation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o4 = ms.PointObservation(df[\"Water Level\"], x=366844, y=6154291)\n</code></pre> Source code in <code>modelskill/obs.py</code> <pre><code>class PointObservation(Observation):\n    \"\"\"Class for observations of fixed locations\n\n    Create a PointObservation from a dfs0 file or a pd.DataFrame.\n\n    Parameters\n    ----------\n    data : (str, Path, mikeio.Dataset, mikeio.DataArray, pd.DataFrame, pd.Series, xr.Dataset, xr.DataArray)\n        filename or object with the data\n    item : (int, str), optional\n        index or name of the wanted item/column, by default None\n        if data contains more than one item, item must be given\n    x : float, optional\n        x-coordinate of the observation point, by default None\n    y : float, optional\n        y-coordinate of the observation point, by default None\n    z : float, optional\n        z-coordinate of the observation point, by default None\n    name : str, optional\n        user-defined name for easy identification in plots etc, by default file basename\n    quantity : Quantity, optional\n        The quantity of the observation, for validation with model results\n        For MIKE dfs files this is inferred from the EUM information\n    aux_items : list, optional\n        list of names or indices of auxiliary items, by default None\n    attrs : dict, optional\n        additional attributes to be added to the data, by default None\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n    &gt;&gt;&gt; o2 = ms.PointObservation(\"klagshamn.dfs0\", item=\"Water Level\", x=366844, y=6154291)\n    &gt;&gt;&gt; o3 = ms.PointObservation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n    &gt;&gt;&gt; o4 = ms.PointObservation(df[\"Water Level\"], x=366844, y=6154291)\n    \"\"\"\n\n    def __init__(\n        self,\n        data: PointType,\n        *,\n        item: Optional[int | str] = None,\n        x: Optional[float] = None,\n        y: Optional[float] = None,\n        z: Optional[float] = None,\n        name: Optional[str] = None,\n        weight: float = 1.0,\n        quantity: Optional[Quantity] = None,\n        aux_items: Optional[list[int | str]] = None,\n        attrs: Optional[dict] = None,\n    ) -&gt; None:\n        if not self._is_input_validated(data):\n            data = _parse_point_input(\n                data, name=name, item=item, quantity=quantity, aux_items=aux_items\n            )\n            data.coords[\"x\"] = x\n            data.coords[\"y\"] = y\n            data.coords[\"z\"] = z\n\n        assert isinstance(data, xr.Dataset)\n\n        data_var = str(list(data.data_vars)[0])\n        data[data_var].attrs[\"kind\"] = \"observation\"\n\n        # check that user-defined attrs don't overwrite existing attrs!\n        _validate_attrs(data.attrs, attrs)\n        data.attrs = {**data.attrs, **(attrs or {})}\n\n        super().__init__(data=data, weight=weight)\n\n    @property\n    def geometry(self):\n        \"\"\"Coordinates of observation (shapely.geometry.Point)\"\"\"\n        from shapely.geometry import Point\n\n        if self.z is None:\n            return Point(self.x, self.y)\n        else:\n            return Point(self.x, self.y, self.z)\n\n    @property\n    def z(self):\n        \"\"\"z-coordinate of observation point\"\"\"\n        return self._coordinate_values(\"z\")\n\n    @z.setter\n    def z(self, value):\n        self.data[\"z\"] = value\n\n    def __repr__(self):\n        out = f\"PointObservation: {self.name}, x={self.x}, y={self.y}\"\n        if len(self._aux_vars) &gt; 0:\n            out += f\", aux={self._aux_vars}\"\n        return out\n</code></pre>"},{"location":"api/observation/point/#modelskill.PointObservation.geometry","title":"<code>geometry</code>  <code>property</code>","text":"<p>Coordinates of observation (shapely.geometry.Point)</p>"},{"location":"api/observation/point/#modelskill.PointObservation.gtype","title":"<code>gtype: str</code>  <code>property</code>","text":"<p>Geometry type</p>"},{"location":"api/observation/point/#modelskill.PointObservation.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>Number of data points</p>"},{"location":"api/observation/point/#modelskill.PointObservation.name","title":"<code>name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Name of time series (value item name)</p>"},{"location":"api/observation/point/#modelskill.PointObservation.quantity","title":"<code>quantity: Quantity</code>  <code>property</code> <code>writable</code>","text":"<p>Quantity of time series</p>"},{"location":"api/observation/point/#modelskill.PointObservation.time","title":"<code>time: pd.DatetimeIndex</code>  <code>property</code>","text":"<p>Time index</p>"},{"location":"api/observation/point/#modelskill.PointObservation.values","title":"<code>values: NDArray[Any]</code>  <code>property</code>","text":"<p>Values as numpy array</p>"},{"location":"api/observation/point/#modelskill.PointObservation.weight","title":"<code>weight: float</code>  <code>property</code> <code>writable</code>","text":"<p>Weighting factor for skill scores</p>"},{"location":"api/observation/point/#modelskill.PointObservation.x","title":"<code>x: Any</code>  <code>property</code> <code>writable</code>","text":"<p>x-coordinate</p>"},{"location":"api/observation/point/#modelskill.PointObservation.y","title":"<code>y: Any</code>  <code>property</code> <code>writable</code>","text":"<p>y-coordinate</p>"},{"location":"api/observation/point/#modelskill.PointObservation.z","title":"<code>z</code>  <code>property</code> <code>writable</code>","text":"<p>z-coordinate of observation point</p>"},{"location":"api/observation/point/#modelskill.PointObservation.equals","title":"<code>equals(other)</code>","text":"<p>Check if two TimeSeries are equal</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def equals(self, other: TimeSeries) -&gt; bool:\n    \"\"\"Check if two TimeSeries are equal\"\"\"\n    return self.data.equals(other.data)\n</code></pre>"},{"location":"api/observation/point/#modelskill.PointObservation.sel","title":"<code>sel(**kwargs)</code>","text":"<p>Select data by label</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def sel(self: T, **kwargs: Any) -&gt; T:\n    \"\"\"Select data by label\"\"\"\n    return self.__class__(self.data.sel(**kwargs))\n</code></pre>"},{"location":"api/observation/point/#modelskill.PointObservation.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert to pandas DataFrame</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert to pandas DataFrame\"\"\"\n    if self.gtype == str(GeometryType.POINT):\n        # we remove the scalar coordinate variables as they\n        # will otherwise be columns in the dataframe\n        return self.data.drop_vars([\"x\", \"y\", \"z\"])[self.name].to_dataframe()\n    else:\n        return self.data.drop_vars([\"z\"])[[\"x\", \"y\", self.name]].to_dataframe()\n</code></pre>"},{"location":"api/observation/point/#modelskill.PointObservation.trim","title":"<code>trim(start_time=None, end_time=None, buffer='1s')</code>","text":"<p>Trim observation data to a given time interval</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>Timestamp</code> <p>start time</p> <code>None</code> <code>end_time</code> <code>Timestamp</code> <p>end time</p> <code>None</code> <code>buffer</code> <code>str</code> <p>buffer time around start and end time, by default \"1s\"</p> <code>'1s'</code> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def trim(\n    self: T,\n    start_time: Optional[pd.Timestamp] = None,\n    end_time: Optional[pd.Timestamp] = None,\n    buffer: str = \"1s\",\n) -&gt; T:\n    \"\"\"Trim observation data to a given time interval\n\n    Parameters\n    ----------\n    start_time : pd.Timestamp\n        start time\n    end_time : pd.Timestamp\n        end time\n    buffer : str, optional\n        buffer time around start and end time, by default \"1s\"\n    \"\"\"\n    # Expand time interval with buffer\n    start_time = pd.Timestamp(start_time) - pd.Timedelta(buffer)\n    end_time = pd.Timestamp(end_time) + pd.Timedelta(buffer)\n\n    data = self.data.sel(time=slice(start_time, end_time))\n    if len(data.time) == 0:\n        raise ValueError(\n            f\"No data left after trimming to {start_time} - {end_time}\"\n        )\n    return self.__class__(data)\n</code></pre>"},{"location":"api/observation/track/","title":"TrackObservation","text":""},{"location":"api/observation/track/#modelskill.TrackObservation","title":"<code>modelskill.TrackObservation</code>","text":"<p>             Bases: <code>Observation</code></p> <p>Class for observation with locations moving in space, e.g. satellite altimetry</p> <p>The data needs in addition to the datetime of each single observation point also, x and y coordinates.</p> <p>Create TrackObservation from dfs0 or DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(str, Path, Dataset, DataFrame, Dataset)</code> <p>path to dfs0 file or object with track data</p> required <code>item</code> <code>(str, int)</code> <p>item name or index of values, by default None if data contains more than one item, item must be given</p> <code>None</code> <code>name</code> <code>str</code> <p>user-defined name for easy identification in plots etc, by default file basename</p> <code>None</code> <code>x_item</code> <code>(str, int)</code> <p>item name or index of x-coordinate, by default 0</p> <code>0</code> <code>y_item</code> <code>(str, int)</code> <p>item name or index of y-coordinate, by default 1</p> <code>1</code> <code>keep_duplicates</code> <code>(str, bool)</code> <p>strategy for handling duplicate timestamps (xarray.Dataset.drop_duplicates): \"first\" to keep first occurrence, \"last\" to keep last occurrence, False to drop all duplicates, \"offset\" to add milliseconds to consecutive duplicates, by default \"first\"</p> <code>'first'</code> <code>offset_duplicates</code> <code>float</code> <p>DEPRECATED! in case of duplicate timestamps and keep_duplicates=\"offset\", add this many seconds to consecutive duplicate entries, by default 0.001</p> <code>0.001</code> <code>quantity</code> <code>Quantity</code> <p>The quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information</p> <code>None</code> <code>aux_items</code> <code>list</code> <p>list of names or indices of auxiliary items, by default None</p> <code>None</code> <code>attrs</code> <code>dict</code> <p>additional attributes to be added to the data, by default None</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=2, name=\"c2\")\n</code></pre> <pre><code>&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=\"wind_speed\", name=\"c2\")\n</code></pre> <pre><code>&gt;&gt;&gt; o1 = ms.TrackObservation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n</code></pre> <pre><code>&gt;&gt;&gt; o1 = ms.TrackObservation(\"track_wl.dfs0\", item=\"wl\", x_item=\"lon\", y_item=\"lat\")\n</code></pre> <pre><code>&gt;&gt;&gt; df = pd.DataFrame(\n...         {\n...             \"t\": pd.date_range(\"2010-01-01\", freq=\"10s\", periods=n),\n...             \"x\": np.linspace(0, 10, n),\n...             \"y\": np.linspace(45000, 45100, n),\n...             \"swh\": [0.1, 0.3, 0.4, 0.5, 0.3],\n...         }\n... )\n&gt;&gt;&gt; df = df.set_index(\"t\")\n&gt;&gt;&gt; df\n                    x        y  swh\nt\n2010-01-01 00:00:00   0.0  45000.0  0.1\n2010-01-01 00:00:10   2.5  45025.0  0.3\n2010-01-01 00:00:20   5.0  45050.0  0.4\n2010-01-01 00:00:30   7.5  45075.0  0.5\n2010-01-01 00:00:40  10.0  45100.0  0.3\n&gt;&gt;&gt; t1 = TrackObservation(df, name=\"fake\")\n&gt;&gt;&gt; t1.n_points\n5\n&gt;&gt;&gt; t1.values\narray([0.1, 0.3, 0.4, 0.5, 0.3])\n&gt;&gt;&gt; t1.time\nDatetimeIndex(['2010-01-01 00:00:00', '2010-01-01 00:00:10',\n           '2010-01-01 00:00:20', '2010-01-01 00:00:30',\n           '2010-01-01 00:00:40'],\n          dtype='datetime64[ns]', name='t', freq=None)\n&gt;&gt;&gt; t1.x\narray([ 0. ,  2.5,  5. ,  7.5, 10. ])\n&gt;&gt;&gt; t1.y\narray([45000., 45025., 45050., 45075., 45100.])\n</code></pre> Source code in <code>modelskill/obs.py</code> <pre><code>class TrackObservation(Observation):\n    \"\"\"Class for observation with locations moving in space, e.g. satellite altimetry\n\n    The data needs in addition to the datetime of each single observation point also, x and y coordinates.\n\n    Create TrackObservation from dfs0 or DataFrame\n\n    Parameters\n    ----------\n    data : (str, Path, mikeio.Dataset, pd.DataFrame, xr.Dataset)\n        path to dfs0 file or object with track data\n    item : (str, int), optional\n        item name or index of values, by default None\n        if data contains more than one item, item must be given\n    name : str, optional\n        user-defined name for easy identification in plots etc, by default file basename\n    x_item : (str, int), optional\n        item name or index of x-coordinate, by default 0\n    y_item : (str, int), optional\n        item name or index of y-coordinate, by default 1\n    keep_duplicates : (str, bool), optional\n        strategy for handling duplicate timestamps (xarray.Dataset.drop_duplicates):\n        \"first\" to keep first occurrence, \"last\" to keep last occurrence,\n        False to drop all duplicates, \"offset\" to add milliseconds to\n        consecutive duplicates, by default \"first\"\n    offset_duplicates : float, optional\n        DEPRECATED! in case of duplicate timestamps and keep_duplicates=\"offset\",\n        add this many seconds to consecutive duplicate entries, by default 0.001\n    quantity : Quantity, optional\n        The quantity of the observation, for validation with model results\n        For MIKE dfs files this is inferred from the EUM information\n    aux_items : list, optional\n        list of names or indices of auxiliary items, by default None\n    attrs : dict, optional\n        additional attributes to be added to the data, by default None\n\n    Examples\n    --------\n    &gt;&gt;&gt; import modelskill as ms\n    &gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=2, name=\"c2\")\n\n    &gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=\"wind_speed\", name=\"c2\")\n\n    &gt;&gt;&gt; o1 = ms.TrackObservation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n\n    &gt;&gt;&gt; o1 = ms.TrackObservation(\"track_wl.dfs0\", item=\"wl\", x_item=\"lon\", y_item=\"lat\")\n\n    &gt;&gt;&gt; df = pd.DataFrame(\n    ...         {\n    ...             \"t\": pd.date_range(\"2010-01-01\", freq=\"10s\", periods=n),\n    ...             \"x\": np.linspace(0, 10, n),\n    ...             \"y\": np.linspace(45000, 45100, n),\n    ...             \"swh\": [0.1, 0.3, 0.4, 0.5, 0.3],\n    ...         }\n    ... )\n    &gt;&gt;&gt; df = df.set_index(\"t\")\n    &gt;&gt;&gt; df\n                        x        y  swh\n    t\n    2010-01-01 00:00:00   0.0  45000.0  0.1\n    2010-01-01 00:00:10   2.5  45025.0  0.3\n    2010-01-01 00:00:20   5.0  45050.0  0.4\n    2010-01-01 00:00:30   7.5  45075.0  0.5\n    2010-01-01 00:00:40  10.0  45100.0  0.3\n    &gt;&gt;&gt; t1 = TrackObservation(df, name=\"fake\")\n    &gt;&gt;&gt; t1.n_points\n    5\n    &gt;&gt;&gt; t1.values\n    array([0.1, 0.3, 0.4, 0.5, 0.3])\n    &gt;&gt;&gt; t1.time\n    DatetimeIndex(['2010-01-01 00:00:00', '2010-01-01 00:00:10',\n               '2010-01-01 00:00:20', '2010-01-01 00:00:30',\n               '2010-01-01 00:00:40'],\n              dtype='datetime64[ns]', name='t', freq=None)\n    &gt;&gt;&gt; t1.x\n    array([ 0. ,  2.5,  5. ,  7.5, 10. ])\n    &gt;&gt;&gt; t1.y\n    array([45000., 45025., 45050., 45075., 45100.])\n\n    \"\"\"\n\n    @property\n    def geometry(self):\n        \"\"\"Coordinates of observation (shapely.geometry.MultiPoint)\"\"\"\n        from shapely.geometry import MultiPoint\n\n        return MultiPoint(np.stack([self.x, self.y]).T)\n\n    def __init__(\n        self,\n        data: TrackType,\n        *,\n        item: Optional[int | str] = None,\n        name: Optional[str] = None,\n        weight: float = 1.0,\n        x_item: Optional[int | str] = 0,\n        y_item: Optional[int | str] = 1,\n        keep_duplicates: bool | str = \"first\",\n        offset_duplicates: float = 0.001,\n        quantity: Optional[Quantity] = None,\n        aux_items: Optional[list[int | str]] = None,\n        attrs: Optional[dict] = None,\n    ) -&gt; None:\n        if not self._is_input_validated(data):\n            if offset_duplicates != 0.001:\n                warnings.warn(\n                    \"The 'offset_duplicates' argument is deprecated, use 'keep_duplicates' argument.\",\n                    FutureWarning,\n                )\n            data = _parse_track_input(\n                data=data,\n                name=name,\n                item=item,\n                quantity=quantity,\n                x_item=x_item,\n                y_item=y_item,\n                keep_duplicates=keep_duplicates,\n                offset_duplicates=offset_duplicates,\n                aux_items=aux_items,\n            )\n        assert isinstance(data, xr.Dataset)\n\n        data_var = str(list(data.data_vars)[0])\n        data[data_var].attrs[\"kind\"] = \"observation\"\n\n        # check that user-defined attrs don't overwrite existing attrs!\n        _validate_attrs(data.attrs, attrs)\n        data.attrs = {**data.attrs, **(attrs or {})}\n\n        super().__init__(data=data, weight=weight)\n\n    def __repr__(self):\n        out = f\"TrackObservation: {self.name}, n={self.n_points}\"\n        if len(self._aux_vars) &gt; 0:\n            out += f\", aux={self._aux_vars}\"\n        return out\n</code></pre>"},{"location":"api/observation/track/#modelskill.TrackObservation.geometry","title":"<code>geometry</code>  <code>property</code>","text":"<p>Coordinates of observation (shapely.geometry.MultiPoint)</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.gtype","title":"<code>gtype: str</code>  <code>property</code>","text":"<p>Geometry type</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.n_points","title":"<code>n_points: int</code>  <code>property</code>","text":"<p>Number of data points</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.name","title":"<code>name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Name of time series (value item name)</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.quantity","title":"<code>quantity: Quantity</code>  <code>property</code> <code>writable</code>","text":"<p>Quantity of time series</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.time","title":"<code>time: pd.DatetimeIndex</code>  <code>property</code>","text":"<p>Time index</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.values","title":"<code>values: NDArray[Any]</code>  <code>property</code>","text":"<p>Values as numpy array</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.weight","title":"<code>weight: float</code>  <code>property</code> <code>writable</code>","text":"<p>Weighting factor for skill scores</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.x","title":"<code>x: Any</code>  <code>property</code> <code>writable</code>","text":"<p>x-coordinate</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.y","title":"<code>y: Any</code>  <code>property</code> <code>writable</code>","text":"<p>y-coordinate</p>"},{"location":"api/observation/track/#modelskill.TrackObservation.equals","title":"<code>equals(other)</code>","text":"<p>Check if two TimeSeries are equal</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def equals(self, other: TimeSeries) -&gt; bool:\n    \"\"\"Check if two TimeSeries are equal\"\"\"\n    return self.data.equals(other.data)\n</code></pre>"},{"location":"api/observation/track/#modelskill.TrackObservation.sel","title":"<code>sel(**kwargs)</code>","text":"<p>Select data by label</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def sel(self: T, **kwargs: Any) -&gt; T:\n    \"\"\"Select data by label\"\"\"\n    return self.__class__(self.data.sel(**kwargs))\n</code></pre>"},{"location":"api/observation/track/#modelskill.TrackObservation.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert to pandas DataFrame</p> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert to pandas DataFrame\"\"\"\n    if self.gtype == str(GeometryType.POINT):\n        # we remove the scalar coordinate variables as they\n        # will otherwise be columns in the dataframe\n        return self.data.drop_vars([\"x\", \"y\", \"z\"])[self.name].to_dataframe()\n    else:\n        return self.data.drop_vars([\"z\"])[[\"x\", \"y\", self.name]].to_dataframe()\n</code></pre>"},{"location":"api/observation/track/#modelskill.TrackObservation.trim","title":"<code>trim(start_time=None, end_time=None, buffer='1s')</code>","text":"<p>Trim observation data to a given time interval</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>Timestamp</code> <p>start time</p> <code>None</code> <code>end_time</code> <code>Timestamp</code> <p>end time</p> <code>None</code> <code>buffer</code> <code>str</code> <p>buffer time around start and end time, by default \"1s\"</p> <code>'1s'</code> Source code in <code>modelskill/timeseries/_timeseries.py</code> <pre><code>def trim(\n    self: T,\n    start_time: Optional[pd.Timestamp] = None,\n    end_time: Optional[pd.Timestamp] = None,\n    buffer: str = \"1s\",\n) -&gt; T:\n    \"\"\"Trim observation data to a given time interval\n\n    Parameters\n    ----------\n    start_time : pd.Timestamp\n        start time\n    end_time : pd.Timestamp\n        end time\n    buffer : str, optional\n        buffer time around start and end time, by default \"1s\"\n    \"\"\"\n    # Expand time interval with buffer\n    start_time = pd.Timestamp(start_time) - pd.Timedelta(buffer)\n    end_time = pd.Timestamp(end_time) + pd.Timedelta(buffer)\n\n    data = self.data.sel(time=slice(start_time, end_time))\n    if len(data.time) == 0:\n        raise ValueError(\n            f\"No data left after trimming to {start_time} - {end_time}\"\n        )\n    return self.__class__(data)\n</code></pre>"}]}